# TrendRadar 架构说明

> **版本**: v2.0  
> **更新日期**: 2025-12-12

---

## 一、系统总览

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                              用户触点层                                      │
├─────────────────────┬─────────────────────┬─────────────────────────────────┤
│   React 前端        │   CLI 命令行         │   MCP Server (IDE)              │
│   frontend/         │   main.py            │   mcp_server/                   │
│   端口: 5173        │   批量爬取/定时推送   │   Windsurf/Cursor 工具          │
└─────────────────────┴─────────────────────┴─────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                         server.py (FastAPI)                                  │
│                         端口: 8000 / 5173                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│  /api/news/{category}      新闻数据          api/routes/news.py             │
│  /api/data                 大宗商品          api/routes/data.py             │
│  /api/generate-analysis    AI分析报告        api/routes/analysis.py         │
│  /api/market-analysis      市场概况          api/routes/analysis.py         │
│  /api/price-history        价格历史          api/routes/data.py             │
│  /api/reports              报告管理          api/routes/reports.py          │
│  /api/cache/status         缓存状态          api/routes/cache.py            │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
              ┌─────────────────────┼─────────────────────┐
              ▼                     ▼                     ▼
┌───────────────────────┐ ┌───────────────────────┐ ┌───────────────────────┐
│     scrapers/         │ │      pacong/          │ │       core/           │
│     国内轻量爬虫       │ │    高级浏览器爬虫      │ │      核心模块          │
├───────────────────────┤ ├───────────────────────┤ ├───────────────────────┤
│ unified.py   统一入口 │ │ browser/              │ │ config.py    配置     │
│ finance.py   财经新闻 │ │  ├─ applescript.py    │ │ analyzer.py  分析     │
│ commodity.py 大宗商品 │ │  ├─ selenium_driver   │ │ statistics.py 统计    │
│ smm.py       有色金属 │ │  └─ cdp_driver        │ │ price_history.py      │
│ plastic21cp.py 塑料  │ │ scrapers/             │ │ notifiers/   推送     │
│ plasway.py   塑料资讯 │ │  ├─ business_insider  │ │ reporters/   报告     │
│                       │ │  └─ world_bank        │ │                       │
│ 特点: requests 轻量   │ │ 特点: 浏览器渲染      │ │                       │
└───────────────────────┘ └───────────────────────┘ └───────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              数据存储层                                      │
├───────────────────────┬───────────────────────┬─────────────────────────────┤
│   Redis (缓存+历史)    │   MySQL (持久化)       │   文件系统                   │
│   端口: 49907         │   commodity_latest    │   reports/*.md              │
│   • 新闻缓存 TTL:1h   │   commodity_history   │   output/*.json             │
│   • 价格历史 Hash     │   news_items          │   logs/*.log                │
│   • 会话状态          │   change_log          │                             │
└───────────────────────┴───────────────────────┴─────────────────────────────┘
```

---

## 二、双爬虫架构

TrendRadar 包含两套独立的爬虫系统，适用于不同场景：

### 2.1 scrapers/ - 国内轻量爬虫

| 文件 | 职责 | 数据源 | 技术 |
|------|------|--------|------|
| `unified.py` | 统一入口，整合多源 | newsnow API + 自定义爬虫 | requests + 线程池 |
| `finance.py` | 财经新闻/汇率 | 新浪外汇、CoinGecko | requests |
| `commodity.py` | 大宗商品价格 | 新浪期货、Business Insider | requests |
| `smm.py` | 有色金属现货 | 上海有色网 (SMM) | requests |
| `plastic21cp.py` | 塑料价格 | 中塑在线 (21CP) | requests |
| `plasway.py` | 塑料行业资讯 | Plasway | requests |
| `factory.py` | 爬虫工厂 | - | 工厂模式 |
| `base.py` | 基类 | - | 标准化接口 |

**特点**：
- 基于 `requests` 库，轻量快速
- 适用于无反爬或弱反爬的国内站点
- 支持并发爬取（ThreadPoolExecutor）
- 数据标准化输出

### 2.2 pacong/ - 高级浏览器爬虫

| 目录/文件 | 职责 | 说明 |
|-----------|------|------|
| `browser/applescript.py` | macOS Safari/Chrome 控制 | AppleScript 自动化 |
| `browser/selenium_driver.py` | 跨平台浏览器控制 | Selenium WebDriver |
| `browser/cdp_driver.py` | Chrome DevTools 协议 | 底层浏览器控制 |
| `scrapers/business_insider.py` | 国际商品价格 | 需要 JS 渲染 |
| `scrapers/world_bank.py` | 世界银行数据 | 需要登录/反爬 |
| `core/base_scraper.py` | 基类 | WebScrapingMixin |

**特点**：
- 支持 JavaScript 渲染页面
- 绕过 WAF/验证码
- 适用于国际网站、反爬站点
- 速度慢但可靠

### 2.3 两套爬虫对比

| 特性 | scrapers/ | pacong/ |
|------|-----------|---------|
| **实现方式** | requests | 浏览器自动化 |
| **适用场景** | 国内财经、API接口 | 反爬站点、JS渲染 |
| **执行速度** | 快 (~1s/请求) | 慢 (~5s/页面) |
| **资源占用** | 低 | 高（需 Chrome） |
| **并发能力** | 高（线程池） | 低（浏览器限制） |
| **维护成本** | 低 | 高 |

---

## 三、核心数据流

### 3.1 新闻数据请求流程

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                    GET /api/news/{category}                                  │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  news.py:get_news()                                                          │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  1. 检查 Redis 缓存                                                      ││
│  │     cache_key = f"news:{category}"                                      ││
│  │     cached = cache.get(cache_key)                                       ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                    │                               │
            ┌───────┴───────┐               ┌───────┴───────┐
            ▼ 缓存命中      ▼ 缓存未命中     ▼ refresh=true
┌───────────────────┐   ┌───────────────────────────────────────────────────┐
│  直接返回缓存数据  │   │  触发后台异步刷新                                  │
│  响应时间 <50ms   │   │  _executor.submit(_background_crawl_news)         │
└───────────────────┘   └───────────────────────────────────────────────────┘
                                            │
                                            ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  _background_crawl_news() 后台任务                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  UnifiedDataSource().crawl_category(category)                           ││
│  └─────────────────────────────────────────────────────────────────────────┘│
│                                    │                                         │
│              ┌─────────────────────┼─────────────────────┐                  │
│              ▼                     ▼                     ▼                  │
│  ┌───────────────────┐ ┌───────────────────┐ ┌───────────────────┐         │
│  │ newsnow API 爬取  │ │ 自定义爬虫爬取    │ │ 供应链关键词过滤  │         │
│  │ (并发线程池)      │ │ (ScraperFactory)  │ │                   │         │
│  └───────────────────┘ └───────────────────┘ └───────────────────┘         │
│              │                     │                     │                  │
│              └─────────────────────┼─────────────────────┘                  │
│                                    ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  数据处理: 去重 → 标准化 → 排序                                          ││
│  └─────────────────────────────────────────────────────────────────────────┘│
│                                    │                                         │
│                                    ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  更新 Redis 缓存 (TTL: 1小时)                                            ││
│  │  cache.set(cache_key, result, ttl=3600)                                 ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
```

**关键代码位置**：
- API 端点: `api/routes/news.py:313`
- 缓存检查: `api/routes/news.py:321`
- 后台刷新: `api/routes/news.py:324`
- 统一数据源: `scrapers/unified.py:72`

---

### 3.2 大宗商品数据流程

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                         GET /api/data                                        │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  data.py:get_data()                                                          │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  1. 检查 Redis 缓存                                                      ││
│  │  2. 缓存命中 → 立即返回                                                  ││
│  │  3. refresh=true → 触发后台爬取                                          ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  _background_fetch_commodity_data() 后台任务                                 │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  CommodityScraper().scrape()                                            ││
│  └─────────────────────────────────────────────────────────────────────────┘│
│                                    │                                         │
│      ┌─────────────────────────────┼─────────────────────────────┐          │
│      ▼                             ▼                             ▼          │
│  ┌────────────────┐    ┌────────────────┐    ┌────────────────┐            │
│  │ 新浪期货       │    │ 上海有色网     │    │ Business       │            │
│  │ _scrape_sina   │    │ _scrape_smm    │    │ Insider        │            │
│  │ 贵金属/能源    │    │ 金属现货价     │    │ 国际商品       │            │
│  └────────────────┘    └────────────────┘    └────────────────┘            │
│      │                             │                             │          │
│      │         ┌───────────────────┼───────────────────┐         │          │
│      │         ▼                   ▼                   ▼         │          │
│      │    ┌────────────────┐  ┌────────────────┐  ┌────────────────┐       │
│      │    │ 中塑在线 21CP  │  │ 中国原油网     │  │ WTI 原油       │       │
│      │    │ 塑料价格       │  │ intercrude     │  │ 21cp           │       │
│      │    │ ABS/PP/PE/...  │  │                │  │                │       │
│      │    └────────────────┘  └────────────────┘  └────────────────┘       │
│      │                             │                             │          │
│      └─────────────────────────────┼─────────────────────────────┘          │
│                                    ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  数据合并 & 标准化                                                       ││
│  │  commodities = sina_data + smm_data + bi_data + plastics_data           ││
│  └─────────────────────────────────────────────────────────────────────────┘│
│                                    │                                         │
│              ┌─────────────────────┼─────────────────────┐                  │
│              ▼                     ▼                     ▼                  │
│  ┌───────────────────┐ ┌───────────────────┐ ┌───────────────────┐         │
│  │  更新 Redis 缓存  │ │  MySQL 持久化     │ │  价格历史存档     │         │
│  │  cache.set()      │ │  commodity_latest │ │  PriceHistory     │         │
│  └───────────────────┘ └───────────────────┘ └───────────────────┘         │
└─────────────────────────────────────────────────────────────────────────────┘
```

**关键代码位置**：
- API 端点: `api/routes/data.py:121`
- 商品爬虫: `scrapers/commodity.py:43`
- 塑料爬虫: `scrapers/plastic21cp.py`
- 价格历史: `core/price_history.py`

---

### 3.3 数据管道处理流程 (MySQL)

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                    商品数据管道 (CommodityPipeline)                           │
│                    database/mysql/pipeline.py                                │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 1: 标准化 (standardize_batch)                                          │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  raw_records → CommodityRecord 标准格式                                  ││
│  │  • name, chinese_name → 商品名称                                        ││
│  │  • price, change_percent → 价格/涨跌                                    ││
│  │  • source, category → 来源/分类                                         ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 2: 事务处理循环 (for each record)                                      │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  2.1 读取旧值并加锁                                                      ││
│  │      SELECT ... FROM commodity_latest WHERE id=? FOR UPDATE             ││
│  │                                                                          ││
│  │  2.2 列级差分 (diff_records)                                             ││
│  │      比对 price, change_percent, source 等字段                           ││
│  │      识别变化的字段                                                      ││
│  │                                                                          ││
│  │  2.3 更新快照表 (commodity_latest)                                       ││
│  │      只更新变化的字段，减少 I/O                                          ││
│  │                                                                          ││
│  │  2.4 写入历史存档 (commodity_history)                                    ││
│  │      完整记录用于趋势分析                                                ││
│  │                                                                          ││
│  │  2.5 记录变更日志 (change_log)                                           ││
│  │      审计追踪                                                            ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  输出统计                                                                    │
│  { "inserted": 5, "updated": 12, "unchanged": 3, "errors": 0 }              │
└─────────────────────────────────────────────────────────────────────────────┘
```

**关键代码位置**：
- 管道入口: `database/mysql/pipeline.py:597`
- 批量标准化: `database/mysql/pipeline.py:314`
- 差分比对: `database/mysql/pipeline.py:358`
- 更新快照: `database/mysql/pipeline.py:373`
- 历史存档: `database/mysql/pipeline.py:381`

---

### 3.4 AI 分析报告生成流程

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                   POST /api/generate-analysis                                │
│                   Request: { company_name, competitors, upstream, ... }      │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 1: 收集新闻数据                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  1.1 实时抓取 (fetch_realtime_news)                                      ││
│  │      • 供应链关键词: 竞争对手/客户/供应商/原材料                          ││
│  │      • 电源定向新闻: _fetch_power_partner_news()                         ││
│  │      • 官网公告: _fetch_power_official_announcements()                   ││
│  │                                                                          ││
│  │  1.2 缓存新闻合并                                                        ││
│  │      • 从 Redis 获取已有供应链新闻                                       ││
│  │      • 去重 (基于标题相似度)                                             ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 2: 收集商品数据                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  CommodityScraper().scrape()                                            ││
│  │  • 去重并按品类汇总                                                      ││
│  │  • 按涨跌幅排序                                                          ││
│  │  • 生成商品数据摘要 (全量，不截断)                                       ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 3: 构建分析提示词 (Prompt)                                             │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  get_analysis_prompt_v3(company_info, news, commodities, today)         ││
│  │  • 系统提示: ANALYSIS_SYSTEM_PROMPT                                     ││
│  │  • 用户提示: 公司信息 + 新闻列表 + 商品数据                              ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 4: 调用 AI API                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  优先级: 外网 (有 Key) → 内网 → 默认回退                                 ││
│  │                                                                          ││
│  │  if Gemini API:                                                         ││
│  │      call_gemini_api(thinking_level="high", timeout=300s)               ││
│  │      parse_gemini_response() → 提取 text 部分                           ││
│  │  else:                                                                  ││
│  │      call_ai_api() → OpenAI 兼容格式                                    ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 5: 保存报告 & 返回结果                                                 │
│  ┌─────────────────────────────────────────────────────────────────────────┐│
│  │  • 保存到文件: reports/report_{timestamp}_{uuid}.md                     ││
│  │  • 返回 JSON: { status, content, model, api_source, news_count }        ││
│  └─────────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────────┘
```

**关键代码位置**：
- API 端点: `api/routes/analysis.py`
- Gemini 调用: `api/routes/analysis.py:111` (call_gemini_api)
- 响应解析: `api/routes/analysis.py:143` (parse_gemini_response)
- 提示词模板: `prompts/analysis_prompts.py`

---

### 3.5 服务启动与缓存预热

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                    server.py 启动流程                                        │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  1. 创建 FastAPI 应用实例                                                    │
│     app = FastAPI(title="TrendRadar API", lifespan=lifespan)                │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  2. 配置 CORS 中间件                                                         │
│     allow_origins=["*"], allow_credentials=True                             │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  3. 注册路由模块                                                             │
│     ├─ data.router     → /api/data, /api/price-history                     │
│     ├─ news.router     → /api/news/{category}                              │
│     ├─ analysis.router → /api/generate-analysis, /api/market-analysis      │
│     ├─ reports.router  → /api/reports                                      │
│     └─ cache.router    → /api/cache/status                                 │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  4. 挂载静态文件 (前端 dist)                                                 │
│     app.mount("/js", StaticFiles(directory=FRONTEND_DIR / "js"))           │
│     app.mount("/css", StaticFiles(directory=FRONTEND_DIR / "css"))         │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  5. @app.on_event("startup") 生命周期                                        │
│     ├─ scheduler.warmup_cache()      预热缓存 (预先爬取填充 Redis)          │
│     └─ scheduler.start_scheduled_tasks()  启动定时任务                      │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  6. 服务就绪                                                                 │
│     uvicorn server:app --host 0.0.0.0 --port 5173                          │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 四、目录职责

| 目录 | 职责 | 核心文件 |
|------|------|----------|
| `scrapers/` | 国内轻量爬虫 | unified.py, commodity.py, plastic21cp.py |
| `pacong/` | 高级浏览器爬虫 | browser/, scrapers/business_insider.py |
| `api/routes/` | FastAPI 路由 | news.py, data.py, analysis.py |
| `core/` | 核心业务逻辑 | config.py, price_history.py, notifiers/ |
| `database/` | 数据库层 | mysql/pipeline.py, repositories/ |
| `config/` | 配置文件 | config.yaml, scrapers.yaml |
| `frontend/` | React 前端 | pages/Dashboard.jsx, components/ |
| `prompts/` | AI 提示词模板 | analysis_prompts.py |
| `mcp_server/` | MCP 工具服务 | server.py, tools/ |
| `reports/` | 生成的报告 | report_*.md |

---

## 五、配置文件说明

### 5.1 主配置 (`config/config.yaml`)

```yaml
# AI 配置
ai:
  internal:                    # 内网 API (优先)
    api_base: "http://10.180.116.2:6400/v1"
    model: "openai_gpt-oss-120b"
  external:                    # 外网 API (备用)
    api_key: "AIzaSy..."
    api_base: "https://generativelanguage.googleapis.com/v1beta"
    model: "gemini-3-pro-preview"
    thinking_level: "high"     # Gemini 3 思考等级

# 爬虫配置
crawler:
  request_interval: 1000       # 请求间隔 (ms)
  enable_crawler: true
  use_proxy: false

# 推送配置
notification:
  enable_notification: true
  webhooks:
    wework_url: [...]          # 企业微信
    feishu_url: ""             # 飞书
    dingtalk_url: ""           # 钉钉

# 权重配置
weight:
  rank_weight: 0.6             # 排名权重
  frequency_weight: 0.3        # 频次权重
  hotness_weight: 0.1          # 热度权重
```

### 5.2 平台配置

```yaml
platforms:
  - id: "wallstreetcn-hot"
    name: "华尔街见闻"
    category: "finance"
  - id: "cls-telegraph"
    name: "财联社电报"
    category: "finance"
  # ... 更多平台
```

---

## 六、启动方式

```bash
# 方式一：一键启动（推荐）
./start.sh

# 方式二：手动启动
# 后端 API
uv run uvicorn server:app --host 0.0.0.0 --port 5173

# 前端开发
cd frontend && npm run dev

# CLI 爬取
python main.py

# 高级爬虫
python pacong/main.py
```

---

## 七、前端功能模块

### 7.1 Dashboard 页面 (`/`)

| 功能 | 说明 |
|------|------|
| 商品分类 TAB | 金属、能源、塑料、全部 |
| 塑料子分类 TAB | ABS、PP、PE、GPPS、HIPS 等 |
| 数据来源筛选 | 国家 → 网站级联 |
| 商品卡片 | 价格、涨跌幅、趋势图 |
| 多区域折线图 | 华东/华南/华北同时展示 |
| 货币切换 | USD / CNY |
| 时间范围 | 日 / 周 / 月 |

### 7.2 塑料子分类 TAB

| 子 TAB | 说明 | 商品示例 |
|--------|------|----------|
| 全部 | 所有塑料商品 | - |
| ABS | 丙烯腈-丁二烯-苯乙烯 | ABS(华东/华南/华北) |
| PP | 聚丙烯 | PP(华东/华南/华北) |
| PE | 聚乙烯 | PE(华东/华南/华北) |
| GPPS | 通用级聚苯乙烯 | GPPS(华东/华南) |
| HIPS | 高抗冲聚苯乙烯 | HIPS(华东/华南) |

### 7.3 区域折线图颜色

| 区域 | 颜色 | Hex |
|------|------|-----|
| 华东 | 蓝色 | `#3b82f6` |
| 华南 | 绿色 | `#10b981` |
| 华北 | 橙色 | `#f59e0b` |

---

## 八、中塑在线爬虫

`scrapers/plastic21cp.py` 负责爬取塑料价格：

| 产品代码 | 产品名称 | 区域 |
|---------|---------|------|
| `abs_south` | ABS(华南) | 华南 |
| `abs_east` | ABS(华东) | 华东 |
| `abs_north` | ABS(华北) | 华北 |
| `pp_east` | PP(华东) | 华东 |
| `pp_south` | PP(华南) | 华南 |
| `pp_north` | PP(华北) | 华北 |
| `pe_east` | PE(华东) | 华东 |
| `pe_south` | PE(华南) | 华南 |
| `pe_north` | PE(华北) | 华北 |
| `gpps_east` | GPPS(华东) | 华东 |
| `gpps_south` | GPPS(华南) | 华南 |
| `hips_east` | HIPS(华东) | 华东 |
| `hips_south` | HIPS(华南) | 华南 |

**历史数据初始化**：
```bash
curl -X POST "http://localhost:5173/api/price-history/init-plastics?days=30"
```

---

**文档维护者**: TrendRadar Team  
**最后更新**: 2025-12-12
