"""
æ•°æ®ç›¸å…³ API è·¯ç”±

ä¼˜åŒ–ç­–ç•¥ï¼šç¼“å­˜ä¼˜å…ˆ + åå°å¼‚æ­¥åˆ·æ–°
"""
from fastapi import APIRouter, HTTPException
from datetime import datetime
from typing import Optional, List, Dict
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

from ..cache import cache, CACHE_TTL
from database.manager import db_manager
from database.mysql.connection import get_connection, get_cursor
import pymysql

router = APIRouter()

# åŸºç¡€ç›®å½•
BASE_DIR = Path(__file__).parent.parent.parent

# åå°ä»»åŠ¡
_executor = ThreadPoolExecutor(max_workers=5, thread_name_prefix="data-bg")
_pending_refreshes = set()
_refresh_lock = Lock()


def _transform_mysql_to_api_format(data: List[Dict]) -> List[Dict]:
    """
    å°† MySQL commodity_latest æ•°æ®è½¬æ¢ä¸º API æ ¼å¼
    
    è½¬æ¢å†…å®¹ï¼š
    1. åˆå¹¶ price_unit å’Œ weight_unit ä¸º unit
    2. æ·»åŠ  current_price å­—æ®µ
    3. ç¡®ä¿ url å­—æ®µå­˜åœ¨
    4. åˆ é™¤ MySQL ä¸“ç”¨å­—æ®µ
    """
    for item in data:
        # 1. åˆå¹¶ price_unit å’Œ weight_unit ä¸º unit
        price_unit = item.get('price_unit', '')
        weight_unit = item.get('weight_unit', '')
        if price_unit and weight_unit:
            item['unit'] = f"{price_unit}/{weight_unit}"
        elif price_unit:
            item['unit'] = price_unit
        elif weight_unit:
            item['unit'] = weight_unit
        else:
            item['unit'] = 'USD'
        
        # 2. current_price = price (å‰ç«¯å…¼å®¹)
        if 'price' in item and 'current_price' not in item:
            item['current_price'] = item['price']
        
        # 3. ç¡®ä¿ url å­—æ®µå­˜åœ¨
        if 'url' not in item or not item['url']:
            item['url'] = item.get('source_url', '')
        
        # 4. åˆ é™¤å‰ç«¯ä¸éœ€è¦çš„å­—æ®µ
        item.pop('id', None)
        item.pop('price_unit', None)
        item.pop('weight_unit', None)
        item.pop('version_ts', None)
        item.pop('source_url', None)
    
    return data


def load_config():
    """åŠ è½½é…ç½®"""
    import yaml
    config_path = BASE_DIR / "config" / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


@router.get("/api/categories")
async def get_categories():
    """è·å–æ‰€æœ‰åˆ†ç±»"""
    config = load_config()
    categories = config.get("categories", {})
    
    result = []
    for key, value in categories.items():
        result.append({
            "id": key,
            "name": value.get("name", key),
            "keywords": value.get("keywords", [])
        })
    
    return {"categories": result}


@router.get("/api/platforms")
def get_platforms():
    """è·å–æ‰€æœ‰å¹³å°"""
    config = load_config()
    platforms = config.get("platforms", [])
    
    # æŒ‰åˆ†ç±»åˆ†ç»„
    by_category = {}
    for p in platforms:
        cat = p.get("category", "other")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(p)
    
    return {
        "platforms": platforms,
        "by_category": by_category,
        "total": len(platforms)
    }


def _background_fetch_commodity_data(cache_key: str):
    """åå°çˆ¬å–å•†å“æ•°æ®å¹¶ä» MySQL commodity_latest è¯»å–å»é‡åçš„æ•°æ®å†™å…¥ Redis"""
    try:
        print(f"ğŸ”„ [åå°] å¼€å§‹çˆ¬å–å•†å“æ•°æ®...")
        from scrapers.commodity import CommodityScraper
        scraper = CommodityScraper()
        raw_data = scraper.scrape()
        print(f"âœ… [åå°] çˆ¬å–å®Œæˆ: {len(raw_data)} æ¡åŸå§‹æ•°æ®")
        
        # å†™å…¥ MySQLï¼ˆPipeline ä¼šè‡ªåŠ¨å»é‡ï¼‰ï¼ŒæŒ‰æ¥æºåˆ†ç»„
        try:
            stats_by_source = {}
            sources = set(item.get("source", "unknown") for item in raw_data)
            for src in sources:
                src_records = [item for item in raw_data if item.get("source", "unknown") == src]
                if not src_records:
                    continue
                db_stats = db_manager.write_commodity(src_records, source=src)
                if db_stats:
                    stats_by_source[src] = db_stats
            if stats_by_source:
                print(f"âœ… [åå°] MySQL å…¥åº“å®Œæˆ: {stats_by_source}")
        except Exception as e:
            print(f"âš ï¸ MySQL å…¥åº“å¤±è´¥: {e}")
        
        # ä» MySQL commodity_latest è¯»å–å»é‡åçš„æ•°æ®ï¼ˆä»¥ MySQL ä¸ºå‡†ï¼‰
        try:
            latest_data = db_manager.get_commodity_latest()
            if not latest_data:
                print("âš ï¸ MySQL commodity_latest ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                latest_data = raw_data
            else:
                print(f"âœ… [åå°] ä» MySQL commodity_latest è¯»å–: {len(latest_data)} æ¡å»é‡æ•°æ®")
                # å­—æ®µæ˜ å°„ï¼šMySQL â†’ API æ ¼å¼
                latest_data = _transform_mysql_to_api_format(latest_data)
        except Exception as e:
            print(f"âš ï¸ ä» MySQL è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            latest_data = raw_data
        
        # æ’åºå¹¶å†™å…¥ Redis
        category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
        latest_data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))
        
        result = {
            "data": latest_data,
            "source": "TrendRadar Commodity",
            "timestamp": datetime.now().isoformat(),
            "cached": False,
            "background_refresh": True,
            "from_mysql": True,
            "categories": list(set(item.get('category', 'å…¶ä»–') for item in latest_data)),
            "total": len(latest_data)
        }
        
        print(f"âœ… [åå°] å†™å…¥ Redis ç¼“å­˜: {len(latest_data)} æ¡")
        cache.set(cache_key, result, ttl=CACHE_TTL)
    except Exception as e:
        print(f"âŒ [åå°] å•†å“æ•°æ®å¤±è´¥: {e}")
    finally:
        with _refresh_lock:
            _pending_refreshes.discard(cache_key)


@router.get("/api/data")
async def get_data(refresh: bool = False, sync: bool = False):
    """
    è·å–å¤§å®—å•†å“å¸‚åœºæ•°æ®

    ä¼˜åŒ–ç­–ç•¥ï¼š
    - refresh=false: ç›´æ¥è¿”å›ç¼“å­˜ï¼ˆ<50msï¼‰
    - refresh=true: ç«‹å³è¿”å›ç¼“å­˜ + åå°å¼‚æ­¥åˆ·æ–°
    - refresh=true&sync=true: åŒæ­¥åˆ·æ–°ï¼Œç­‰å¾…æ–°æ•°æ®è¿”å›
    """
    cache_key = "data:commodity"
    cached = cache.get(cache_key)

    if refresh:
        if sync:
            # åŒæ­¥åˆ·æ–°ï¼šç›´æ¥çˆ¬å–æ–°æ•°æ®å¹¶è¿”å›
            print(f"ğŸ”„ å•†å“æ•°æ®åŒæ­¥åˆ·æ–°å¼€å§‹...")
            try:
                from scrapers.commodity import CommodityScraper
                scraper = CommodityScraper()
                raw_data = scraper.scrape()
                print(f"âœ… åŒæ­¥çˆ¬å–å®Œæˆ: {len(raw_data)} æ¡åŸå§‹æ•°æ®")

                # å†™å…¥ MySQL
                try:
                    stats_by_source = {}
                    sources = set(item.get("source", "unknown") for item in raw_data)
                    for src in sources:
                        src_records = [item for item in raw_data if item.get("source", "unknown") == src]
                        if src_records:
                            db_stats = db_manager.write_commodity(src_records, source=src)
                            if db_stats:
                                stats_by_source[src] = db_stats
                    print(f"âœ… MySQL å…¥åº“å®Œæˆ: {stats_by_source}")
                except Exception as e:
                    print(f"âš ï¸ MySQL å…¥åº“å¤±è´¥: {e}")

                # ä» MySQL è¯»å–å»é‡åçš„æ•°æ®
                latest_data = db_manager.get_commodity_latest() or raw_data
                latest_data = _transform_mysql_to_api_format(latest_data)

                # æ’åº
                category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
                latest_data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))

                result = {
                    "data": latest_data,
                    "source": "TrendRadar Commodity (Sync Refresh)",
                    "timestamp": datetime.now().isoformat(),
                    "cached": False,
                    "refreshing": False,
                    "sync_refresh": True,
                    "from_mysql": True,
                    "categories": list(set(item.get('category', 'å…¶ä»–') for item in latest_data)),
                    "total": len(latest_data)
                }

                cache.set(cache_key, result, ttl=CACHE_TTL)
                return result

            except Exception as e:
                print(f"âŒ åŒæ­¥åˆ·æ–°å¤±è´¥: {e}")
                # å¤±è´¥æ—¶è¿”å›ç¼“å­˜æ•°æ®
                if cached:
                    cached["error"] = str(e)
                    return cached
                return {"data": [], "error": str(e), "timestamp": None}

        # å¼‚æ­¥åˆ·æ–°ï¼šè§¦å‘åå°åˆ·æ–°
        triggered = False
        with _refresh_lock:
            if cache_key not in _pending_refreshes:
                _pending_refreshes.add(cache_key)
                _executor.submit(_background_fetch_commodity_data, cache_key)
                triggered = True
                print(f"ğŸ”„ å•†å“æ•°æ®åå°åˆ·æ–°å·²è§¦å‘")

        # ç«‹å³è¿”å›ç°æœ‰ç¼“å­˜
        if cached:
            cached["cached"] = True
            cached["refreshing"] = triggered
            cached["message"] = "æ•°æ®æ­£åœ¨åå°åˆ·æ–°" if triggered else "åˆ·æ–°ä»»åŠ¡å·²åœ¨è¿›è¡Œä¸­"
            return cached

        return {
            "data": [],
            "source": "TrendRadar Commodity",
            "timestamp": None,
            "cached": False,
            "refreshing": triggered,
            "categories": [],
            "message": "æ•°æ®æ­£åœ¨åå°åŠ è½½"
        }
    
    if cached:
        cached["cached"] = True
        return cached

    # ç¼“å­˜æœªå‘½ä¸­ï¼Œå°è¯•ä» MySQL å¿«ç…§ (commodity_latest) è·å–
    try:
        from database.manager import db_manager
        latest_data = db_manager.get_commodity_latest()
        
        if latest_data:
            print("ğŸ”„ [API] Redis Miss -> ä» MySQL å¿«ç…§ (commodity_latest) æ¢å¤")
            
            # å­—æ®µæ˜ å°„ï¼šMySQL â†’ API æ ¼å¼ï¼ˆä¸åå°åˆ·æ–°é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
            latest_data = _transform_mysql_to_api_format(latest_data)
            
            # æ’åº
            category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
            latest_data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))
            
            # æ„å»ºæ ‡å‡†å“åº”
            result = {
                "data": latest_data,
                "source": "TrendRadar MySQL Snapshot",
                "timestamp": datetime.now().isoformat(),
                "cached": False,
                "from_snapshot": True,
                "from_mysql": True,
                "categories": list(set(item.get('category', 'å…¶ä»–') for item in latest_data)),
                "total": len(latest_data)
            }
            cache.set(cache_key, result, ttl=CACHE_TTL)
            return result
            
    except Exception as e:
        print(f"âš ï¸ [API] MySQL å¿«ç…§æ¢å¤å¤±è´¥: {e}")

    # å¿«ç…§ç¼ºå¤±ï¼Œå°è¯•ä»å†å²å½’æ¡£ (commodity_history) è·å–å½“å¤©æ•°æ®
    try:
        from database.mysql.pipeline import get_commodities_by_date
        today_data = get_commodities_by_date(datetime.now())
        
        if today_data:
            print("ğŸ”„ [API] MySQL å¿«ç…§ç¼ºå¤± -> ä»å†å²å½’æ¡£ (commodity_history) åŠ è½½ä»Šæ—¥æ•°æ®")
            
            # å…¼å®¹å¤„ç†: å†å²è¡¨å­—æ®µè½¬ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼ (å¦‚æœå­—æ®µåæœ‰å·®å¼‚)
            # ç›®å‰ commodity_history ä¸ latest å­—æ®µåŸºæœ¬ä¸€è‡´
            
            result = {
                "data": today_data,
                "source": "TrendRadar MySQL History",
                "timestamp": datetime.now().isoformat(),
                "cached": False,
                "from_archive": True,
                "categories": list(set(item.get('category', 'å…¶ä»–') for item in today_data))
            }
            cache.set(cache_key, result, ttl=CACHE_TTL)
            return result
            
    except Exception as e:
        print(f"âš ï¸ [API] MySQL å†å²å½’æ¡£è¯»å–å¤±è´¥: {e}")
    
    # ç¼“å­˜æœªå‘½ä¸­ä¸”DBæ— æ•°æ®ï¼Œè§¦å‘åå°çˆ¬å–
    _background_fetch_commodity_data(cache_key)


@router.get("/api/price-history")
async def get_price_history(commodity: Optional[str] = None, days: int = 7):
    """
    è·å–ä»·æ ¼å†å²æ•°æ®ï¼ˆä» commodity_history è¡¨ï¼‰
    
    ä¼˜åŒ–ï¼šä½¿ç”¨ç¼“å­˜ï¼ˆä»·æ ¼å†å²ä¸å¸¸å˜ï¼‰
    """
    cache_key = f"price-history:{commodity or 'all'}:{days}"
    
    # æ£€æŸ¥ç¼“å­˜
    cached = cache.get(cache_key)
    if cached:
        cached["cached"] = True
        return cached
    
    try:
        from core.price_history import PriceHistoryManager
        history_manager = PriceHistoryManager()
        
        if commodity:
            history = history_manager.get_history(commodity, days)
            result = {
                "status": "success",
                "commodity": commodity,
                "days": days,
                "data": history,
                "cached": False
            }
        else:
            all_history = history_manager.get_all_commodities_history(days)
            result = {
                "status": "success",
                "days": days,
                "data": all_history,
                "commodities": list(all_history.keys()),
                "cached": False
            }
        
        # ç¼“å­˜ äº”åˆ†é’Ÿ
        cache.set(cache_key, result, ttl=300)
        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "message": str(e),
            "data": {},
            "cached": False
        }


@router.post("/api/price-history/init-plastics")
async def init_plastics_history(days: int = 30):
    """
    åˆå§‹åŒ–å¡‘æ–™å†å²æ•°æ®ï¼ˆä»ä¸­å¡‘åœ¨çº¿æ‹‰å–å†å²è®°å½•ï¼‰
    
    Args:
        days: æ‹‰å–æœ€è¿‘å¤šå°‘å¤©çš„å†å²æ•°æ®ï¼Œé»˜è®¤30å¤©
    """
    try:
        from scrapers.plastic21cp import Plastic21CPScraper
        from core.price_history import PriceHistoryManager
        from datetime import datetime, timedelta
        
        scraper = Plastic21CPScraper()
        history_manager = PriceHistoryManager()
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        
        total_saved = 0
        products_processed = []
        
        for product_key in scraper.list_products():
            try:
                # è·å–å†å²æ•°æ®
                records = scraper.fetch(product_key, start_date=start_date, end_date=end_date)
                
                # ä¿å­˜åˆ°å†å²è®°å½•
                for record in records:
                    name = record.get("chinese_name") or record.get("name")
                    price = record.get("price")
                    change = record.get("change_percent", 0)
                    source = record.get("source", "ä¸­å¡‘åœ¨çº¿")
                    date = record.get("price_date")
                    
                    if name and price and date:
                        history_manager.save_daily_price(name, price, change, source, date)
                        total_saved += 1
                
                products_processed.append({
                    "product": product_key,
                    "records": len(records)
                })
                
            except Exception as e:
                products_processed.append({
                    "product": product_key,
                    "error": str(e)
                })
        
        return {
            "status": "success",
            "message": f"å·²åˆå§‹åŒ– {total_saved} æ¡å¡‘æ–™å†å²æ•°æ®",
            "date_range": {"start": start_date, "end": end_date},
            "products": products_processed
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }


@router.get("/api/data/sources")
async def get_data_sources():
    """
    è·å–å•†å“æ•°æ®æ¥æºä¿¡æ¯ï¼ˆå›½å®¶ã€ç½‘ç«™çº§è”ï¼‰
    """
    # æ•°æ®æºå®šä¹‰
    sources = {
        "US": {
            "name": "ç¾å›½",
            "name_en": "United States",
            "flag": "ğŸ‡ºğŸ‡¸",
            "websites": [
                {
                    "id": "business_insider",
                    "name": "Business Insider",
                    "url": "https://markets.businessinsider.com",
                    "commodities": ["Gold", "Silver", "Platinum", "Palladium", "WTI Crude Oil", "Brent Crude", "Natural Gas", "Copper"]
                },
                {
                    "id": "comex",
                    "name": "COMEX",
                    "url": "https://www.cmegroup.com",
                    "commodities": ["COMEXé»„é‡‘", "COMEXç™½é“¶", "COMEXé“œ"]
                }
            ]
        },
        "CN": {
            "name": "ä¸­å›½",
            "name_en": "China",
            "flag": "ğŸ‡¨ğŸ‡³",
            "websites": [
                {
                    "id": "sina_futures",
                    "name": "æ–°æµªæœŸè´§",
                    "url": "https://finance.sina.com.cn/futures",
                    "commodities": ["æ²ªé‡‘", "æ²ªé“¶", "æ²ªé“œ", "æ²ªé“", "æ²ªé”Œ", "æ²ªé•", "èºçº¹é’¢", "é“çŸ¿çŸ³"]
                },
                {
                    "id": "smm",
                    "name": "ä¸Šæµ·æœ‰è‰²ç½‘",
                    "url": "https://www.smm.cn",
                    "commodities": ["SMMé“œ", "SMMé“", "SMMé”Œ", "SMMé•", "SMMé”¡", "SMMé“…"]
                },
                {
                    "id": "shfe",
                    "name": "ä¸Šæµ·æœŸè´§äº¤æ˜“æ‰€",
                    "url": "https://www.shfe.com.cn",
                    "commodities": ["æ²ªé‡‘", "æ²ªé“¶", "æ²ªé“œ", "æ²ªé“", "æ²ªé”Œ", "å¤©ç„¶æ©¡èƒ¶"]
                },
                {
                    "id": "21cp",
                    "name": "ä¸­å¡‘åœ¨çº¿",
                    "url": "https://quote.21cp.com",
                    "commodities": [
                        "ABS(åå—)", "ABS(åä¸œ)", "ABS(ååŒ—)",
                        "PP(åä¸œ)", "PP(åå—)", "PP(ååŒ—)",
                        "PE(åä¸œ)", "PE(åå—)", "PE(ååŒ—)",
                        "GPPS(åä¸œ)", "GPPS(åå—)", "GPPSä½ç«¯(åä¸œ)", "GPPSä½ç«¯(åå—)",
                        "HIPS(åä¸œ)", "HIPS(åå—)", "HIPSä½ç«¯(åä¸œ)", "HIPSä½ç«¯(åå—)",
                        "WTIåŸæ²¹"
                    ]
                }
            ]
        },
        "UK": {
            "name": "è‹±å›½",
            "name_en": "United Kingdom",
            "flag": "ğŸ‡¬ğŸ‡§",
            "websites": [
                {
                    "id": "lme",
                    "name": "ä¼¦æ•¦é‡‘å±äº¤æ˜“æ‰€",
                    "url": "https://www.lme.com",
                    "commodities": ["LMEé“œ", "LMEé“", "LMEé”Œ", "LMEé•", "LMEé”¡", "LMEé“…"]
                }
            ]
        },
        "JP": {
            "name": "æ—¥æœ¬",
            "name_en": "Japan",
            "flag": "ğŸ‡¯ğŸ‡µ",
            "websites": [
                {
                    "id": "tocom",
                    "name": "ä¸œäº¬å•†å“äº¤æ˜“æ‰€",
                    "url": "https://www.tocom.or.jp",
                    "commodities": ["ä¸œäº¬é»„é‡‘", "ä¸œäº¬ç™½é“¶", "ä¸œäº¬é“‚é‡‘"]
                }
            ]
        }
    }
    
    # æ„å»ºçº§è”ç»“æ„
    cascade = []
    for country_code, country_info in sources.items():
        country_data = {
            "code": country_code,
            "name": country_info["name"],
            "name_en": country_info["name_en"],
            "flag": country_info["flag"],
            "websites": country_info["websites"],
            "commodity_count": sum(len(w["commodities"]) for w in country_info["websites"])
        }
        cascade.append(country_data)
    
    return {
        "status": "success",
        "sources": sources,
        "cascade": cascade,
        "total_countries": len(sources),
        "total_websites": sum(len(c["websites"]) for c in sources.values())
    }


@router.get("/api/config")
async def get_config():
    """è·å–é…ç½®"""
    config = load_config()
    
    # éšè—æ•æ„Ÿä¿¡æ¯
    if "notification" in config and "webhooks" in config["notification"]:
        webhooks = config["notification"]["webhooks"]
        for key in webhooks:
            val = webhooks[key]
            if isinstance(val, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼ˆå¦‚ wework_urlï¼‰ï¼Œå¤„ç†æ¯ä¸ªå…ƒç´ 
                masked_list = []
                for item in val:
                    if item and isinstance(item, str) and len(item) > 10:
                        masked_list.append(item[:10] + "***")
                    else:
                        masked_list.append(item)
                webhooks[key] = masked_list
            elif val and isinstance(val, str) and len(val) > 10:
                webhooks[key] = val[:10] + "***"
    
    return config


@router.get("/api/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return {
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "cache": cache.get_status(),
        "version": "2.0.0"
    }



def _create_exchange_rate_table():
    sql = """
    CREATE TABLE IF NOT EXISTS exchange_rates (
        id BIGINT AUTO_INCREMENT PRIMARY KEY,
        base_currency VARCHAR(3) NOT NULL COMMENT 'åŸºç¡€è´§å¸ (å¦‚ USD)',
        target_currency VARCHAR(3) NOT NULL COMMENT 'ç›®æ ‡è´§å¸ (å¦‚ CNY)',
        rate DECIMAL(10, 6) NOT NULL COMMENT 'æ±‡ç‡å€¼',
        source VARCHAR(64) COMMENT 'æ•°æ®æ¥æº (å¦‚ api.exchangerate-api.com)',
        timestamp DATETIME(3) COMMENT 'æ•°æ®æ—¶é—´æˆ³ (æ¥æºæä¾›çš„æ—¶é—´)',
        created_at DATETIME(3) DEFAULT CURRENT_TIMESTAMP(3),
        INDEX idx_currency_pair (base_currency, target_currency),
        INDEX idx_created_at (created_at DESC)
    ) ENGINE=InnoDB COMMENT='æ±‡ç‡å†å²è¡¨';
    """
    try:
        conn = get_connection()
        with conn.cursor() as cursor:
            cursor.execute(sql)
            conn.commit()
            print("âœ… Created exchange_rates table")
    except Exception as e:
        print(f"âŒ Failed to create exchange_rates table: {e}")
    finally:
        if 'conn' in locals():
            conn.close()

def _save_exchange_rate_to_mysql(data: dict):
    sql = """
        INSERT INTO exchange_rates 
        (base_currency, target_currency, rate, source, timestamp)
        VALUES (%s, %s, %s, %s, %s)
    """
    # å¤„ç† timestamp æ ¼å¼ï¼Œç¡®ä¿ MySQL èƒ½è¯†åˆ«
    ts = data['timestamp']
    if 'T' in ts:
        ts = ts.replace('T', ' ')
        
    params = (
        data['base'],
        data['target'],
        data['rate'],
        data['source'],
        ts
    )
    
    conn = None
    try:
        conn = get_connection()
        with conn.cursor() as cursor:
            cursor.execute(sql, params)
            conn.commit()
            print(f"âœ… Exchange rate saved to MySQL: {data['rate']}")
    except pymysql.err.ProgrammingError as e:
        if e.args[0] == 1146: # Table doesn't exist
            print("âš ï¸ Table exchange_rates does not exist, creating...")
            _create_exchange_rate_table()
            # Retry once
            if conn: conn.close()
            conn = get_connection()
            with conn.cursor() as cursor:
                cursor.execute(sql, params)
                conn.commit()
                print(f"âœ… Exchange rate saved to MySQL (after create): {data['rate']}")
        else:
            raise
    except Exception as e:
        print(f"âŒ MySQL Error: {e}")
    finally:
        if conn:
            conn.close()

@router.get("/api/exchange-rate")

def get_exchange_rate(refresh: bool = False):
    """
    è·å–å®æ—¶æ±‡ç‡ï¼ˆUSD/CNYï¼‰
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    - ç¼“å­˜ä¼˜å…ˆï¼šé»˜è®¤ä» Redis è·å–ç¼“å­˜æ•°æ®
    - ç¼“å­˜æœ‰æ•ˆæœŸï¼š20åˆ†é’Ÿ (1200ç§’)
    - refresh=true: å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    cache_key = "data:exchange_rate:usd_cny"
    
    # 1. å°è¯•è¯»å–ç¼“å­˜
    if not refresh:
        cached_data = cache.get(cache_key)
        if cached_data:
            cached_data["cached"] = True
            return cached_data
    
    import requests
    
    # å°è¯•å¤šä¸ªæ±‡ç‡æº
    sources = [
        # ExchangeRate-API (å…è´¹)
        ("https://api.exchangerate-api.com/v4/latest/USD", lambda d: d.get("rates", {}).get("CNY")),
        # Open Exchange Rates (å¤‡ç”¨)
        ("https://open.er-api.com/v6/latest/USD", lambda d: d.get("rates", {}).get("CNY")),
    ]
    
    for url, extractor in sources:
        try:
            resp = requests.get(url, timeout=5)
            if resp.status_code == 200:
                data = resp.json()
                rate = extractor(data)
                if rate:
                    result = {
                        "status": "success",
                        "base": "USD",
                        "target": "CNY",
                        "rate": round(float(rate), 4),
                        "timestamp": datetime.now().isoformat(),
                        "source": url.split("/")[2],
                        "cached": False
                    }
                    
                    # å†™å…¥ MySQL (ç¼“å­˜å‰)
                    _save_exchange_rate_to_mysql(result)
                    
                    # å†™å…¥ç¼“å­˜ (20åˆ†é’Ÿ = 1200ç§’)
                    cache.set(cache_key, result, ttl=1200)
                    return result
        except Exception:
            continue
    
    # é»˜è®¤å¤‡ç”¨æ±‡ç‡
    fallback_result = {
        "status": "fallback",
        "base": "USD",
        "target": "CNY",
        "rate": 7.2,
        "timestamp": datetime.now().isoformat(),
        "source": "default",
        "cached": False
    }
    
    # å†™å…¥ MySQL (ç¼“å­˜å‰)
    _save_exchange_rate_to_mysql(fallback_result)

    # å¤‡ç”¨æ•°æ®ä¹Ÿç¼“å­˜è¾ƒçŸ­æ—¶é—´ (5åˆ†é’Ÿ)
    cache.set(cache_key, fallback_result, ttl=300)
    return fallback_result
