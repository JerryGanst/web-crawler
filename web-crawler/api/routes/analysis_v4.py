"""
æ¨¡å—åŒ–åˆ†æ API V4 - åŠ¨æ€å…³ç¨åˆ†ç±» + åŸææ–™åˆ†ç¦»åˆ†æ

æ ¸å¿ƒæ”¹è¿›ï¼ˆåŸºäºé¢†å¯¼åé¦ˆï¼‰ï¼š
1. å…³ç¨æ”¿ç­–ï¼šAI å…ˆåˆ†ç±»ï¼Œç„¶åé€ä¸€å•ç‹¬åˆ†æ
2. åŸææ–™ï¼šæ•°æ®ç›´æ¥åµŒå…¥ + æˆæœ¬åˆ†æå•ç‹¬èµ°å¤§æ¨¡å‹
3. æ¨¡å—å®Œå…¨ç‹¬ç«‹ï¼Œæœ€åæ‹¼è£…æ•´åˆ

æµç¨‹ï¼š
    ç¬¬ä¸€è½®ï¼ˆå¹¶è¡Œï¼‰ï¼šå®¢æˆ·åˆ†æã€å‹å•†åˆ†æã€å…³ç¨åˆ†ç±»
    ç¬¬äºŒè½®ï¼ˆå¹¶è¡Œï¼‰ï¼šå…³ç¨å„åˆ†ç±»å•ç‹¬åˆ†æã€åŸææ–™æˆæœ¬åˆ†æ
    ç¬¬ä¸‰è½®ï¼šæ‰§è¡Œæ‘˜è¦æ•´åˆ
    æœ€ç»ˆï¼šæ‹¼è£…æŠ¥å‘Š
"""
import asyncio
import aiohttp
import json
import re
from datetime import datetime
from typing import Dict, List, Optional
from pathlib import Path
from fastapi import APIRouter, HTTPException
from fastapi.concurrency import run_in_threadpool
import yaml
import os

from ..cache import cache
from ..models import AnalysisRequest

from prompts.analysis_prompts_v4 import (
    CUSTOMER_MODULE,
    COMPETITOR_MODULE,
    TARIFF_CLASSIFIER_MODULE,
    MATERIAL_ANALYSIS_MODULE,
    SUMMARY_MODULE,
    get_module_prompt,
    get_tariff_analysis_prompt,
    build_material_section,
    fetch_news_full_content,
    filter_tariff_news,
    filter_news_by_category,
    precheck_news_quality,
    assemble_final_report_v4
)

router = APIRouter()
BASE_DIR = Path(__file__).parent.parent.parent


def get_ai_config():
    """è·å– AI é…ç½®"""
    config_path = BASE_DIR / "config" / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    ai_config = config.get("ai", {})
    external = ai_config.get("external", {})
    return {
        "api_key": external.get("api_key", "") or os.environ.get("AI_API_KEY", ""),
        "api_base": external.get("api_base", "https://generativelanguage.googleapis.com/v1beta"),
        "model": external.get("model", "gemini-3-pro-preview"),
    }


async def call_ai_async(
    session: aiohttp.ClientSession,
    api_base: str, api_key: str, model: str,
    system_prompt: str, user_prompt: str,
    max_tokens: int = 1500, timeout: int = 90
) -> str:
    """å¼‚æ­¥è°ƒç”¨ AI API"""
    is_google_api = "generativelanguage.googleapis.com" in api_base
    
    if is_google_api:
        headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}
        payload = {
            "system_instruction": {"parts": [{"text": system_prompt}]},
            "contents": [{"role": "user", "parts": [{"text": user_prompt}]}],
            "generation_config": {"temperature": 1.0, "max_output_tokens": max_tokens}
        }
        url = f"{api_base.rstrip('/')}/models/{model}:generateContent?key={api_key}"
    else:
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7,
            "max_tokens": max_tokens
        }
        url = f"{api_base.rstrip('/')}/chat/completions"
    
    async with session.post(url, headers=headers, json=payload, 
                           timeout=aiohttp.ClientTimeout(total=timeout)) as response:
        if response.status != 200:
            text = await response.text()
            raise Exception(f"API error {response.status}: {text[:200]}")
        
        result = await response.json()
        
        if is_google_api:
            candidates = result.get("candidates", [])
            for c in candidates:
                parts = c.get("content", {}).get("parts", [])
                texts = [p.get("text", "") for p in parts if isinstance(p, dict)]
                if texts:
                    return "".join(texts).strip()
            raise Exception("No response from Gemini")
        else:
            if "choices" in result and result["choices"]:
                return result["choices"][0]["message"]["content"]
            raise Exception("No response")


def parse_tariff_categories(response: str) -> List[str]:
    """
    è§£æå…³ç¨åˆ†ç±»ç»“æœ
    
    Args:
        response: AI è¿”å›çš„ JSON æ•°ç»„å­—ç¬¦ä¸²
    
    Returns:
        åˆ†ç±»åˆ—è¡¨
    """
    # å°è¯•ç›´æ¥è§£æ JSON
    try:
        # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—
        cleaned = response.strip()
        if cleaned.startswith("```"):
            # å»æ‰ä»£ç å—æ ‡è®°
            cleaned = re.sub(r'^```json?\s*', '', cleaned)
            cleaned = re.sub(r'\s*```$', '', cleaned)
        
        categories = json.loads(cleaned)
        if isinstance(categories, list):
            return [str(c) for c in categories if c]
        return []
    except json.JSONDecodeError:
        pass
    
    # å°è¯•ç”¨æ­£åˆ™æå–
    try:
        # æ‰¾åˆ°ç±»ä¼¼ ["xxx", "yyy"] çš„æ¨¡å¼
        match = re.search(r'\[([^\]]*)\]', response)
        if match:
            content = match.group(1)
            # æå–å¼•å·å†…çš„å†…å®¹
            items = re.findall(r'"([^"]+)"', content)
            if items:
                return items
    except Exception:
        pass
    
    # æœ€åå°è¯•æŒ‰è¡Œåˆ†å‰²
    lines = response.strip().split('\n')
    categories = []
    for line in lines:
        line = line.strip().strip('-').strip('â€¢').strip()
        if line and not line.startswith('[') and not line.startswith('{'):
            categories.append(line)
    
    return categories[:10]  # æœ€å¤šè¿”å›10ä¸ªåˆ†ç±»


async def run_first_round(
    news_summary: str,
    news_with_content: str,
    ai_config: dict
) -> Dict[str, any]:
    """
    ç¬¬ä¸€è½®ï¼šå¹¶è¡Œè¿è¡Œå®¢æˆ·ã€å‹å•†ã€å…³ç¨åˆ†ç±»æ¨¡å—
    
    Returns:
        {
            "customer": "å®¢æˆ·åˆ†æç»“æœ",
            "competitor": "å‹å•†åˆ†æç»“æœ", 
            "tariff_categories": ["ä¸­ç¾", "ä¸­æ¬§", ...]
        }
    """
    results = {}
    
    async with aiohttp.ClientSession() as session:
        # å‡†å¤‡ä»»åŠ¡
        tasks = []
        task_names = []
        
        # å®¢æˆ·æ¨¡å—
        customer_prompt = get_module_prompt(CUSTOMER_MODULE, news_summary=news_summary)
        tasks.append(call_ai_async(
            session, ai_config["api_base"], ai_config["api_key"], ai_config["model"],
            customer_prompt["system"], customer_prompt["user"], customer_prompt["max_tokens"]
        ))
        task_names.append("customer")
        
        # å‹å•†æ¨¡å—
        competitor_prompt = get_module_prompt(COMPETITOR_MODULE, news_summary=news_summary)
        tasks.append(call_ai_async(
            session, ai_config["api_base"], ai_config["api_key"], ai_config["model"],
            competitor_prompt["system"], competitor_prompt["user"], competitor_prompt["max_tokens"]
        ))
        task_names.append("competitor")
        
        # å…³ç¨åˆ†ç±»æ¨¡å—
        classifier_prompt = get_module_prompt(TARIFF_CLASSIFIER_MODULE, news_with_content=news_with_content)
        tasks.append(call_ai_async(
            session, ai_config["api_base"], ai_config["api_key"], ai_config["model"],
            classifier_prompt["system"], classifier_prompt["user"], classifier_prompt["max_tokens"]
        ))
        task_names.append("tariff_classifier")
        
        print(f"ğŸš€ [V4] ç¬¬ä¸€è½®ï¼šå¹¶è¡Œè°ƒç”¨ {len(tasks)} ä¸ªæ¨¡å—...")
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        for name, resp in zip(task_names, responses):
            if isinstance(resp, Exception):
                print(f"âš ï¸ æ¨¡å— {name} å¤±è´¥: {resp}")
                if name == "tariff_classifier":
                    results["tariff_categories"] = []
                else:
                    results[name] = f"*{name} æ¨¡å—åˆ†æå¤±è´¥*"
            else:
                print(f"âœ… æ¨¡å— {name} å®Œæˆ")
                if name == "tariff_classifier":
                    categories = parse_tariff_categories(resp)
                    results["tariff_categories"] = categories
                    print(f"   ğŸ“‚ è¯†åˆ«åˆ° {len(categories)} ä¸ªå…³ç¨åˆ†ç±»: {categories}")
                else:
                    results[name] = resp
    
    return results


async def run_second_round(
    tariff_categories: List[str],
    tariff_news: List[Dict],
    material_data_section: str,
    ai_config: dict
) -> Dict[str, any]:
    """
    ç¬¬äºŒè½®ï¼šå¹¶è¡Œè¿è¡Œå„å…³ç¨åˆ†ç±»åˆ†æ + åŸææ–™æˆæœ¬åˆ†æ
    
    Returns:
        {
            "tariff_sections": {"ä¸­ç¾": "åˆ†æå†…å®¹", "ä¸­æ¬§": "åˆ†æå†…å®¹"},
            "material_analysis": "æˆæœ¬åˆ†æå†…å®¹"
        }
    """
    results = {
        "tariff_sections": {},
        "material_analysis": ""
    }
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        task_info = []  # (type, name)
        
        # ä¸ºæ¯ä¸ªå…³ç¨åˆ†ç±»åˆ›å»ºåˆ†æä»»åŠ¡
        for category in tariff_categories:
            # ç­›é€‰è¯¥åˆ†ç±»ç›¸å…³çš„æ–°é—»
            category_news = filter_news_by_category(tariff_news, category)
            
            if not category_news:
                print(f"   â­ï¸ åˆ†ç±» [{category}] æ— ç›¸å…³æ–°é—»ï¼Œè·³è¿‡")
                continue
            
            # æ„å»ºæ–°é—»å†…å®¹
            news_content = "\n\n".join([
                f"### {n.get('title', '')}\n**æ¥æº**: {n.get('source', '')} | [é“¾æ¥]({n.get('url', '')})\n**å†…å®¹**: {n.get('content', 'æ— å…¨æ–‡')[:800]}"
                for n in category_news[:5]
            ])
            
            prompt = get_tariff_analysis_prompt(category, news_content)
            tasks.append(call_ai_async(
                session, ai_config["api_base"], ai_config["api_key"], ai_config["model"],
                prompt["system"], prompt["user"], prompt["max_tokens"]
            ))
            task_info.append(("tariff", category))
        
        # åŸææ–™æˆæœ¬åˆ†æä»»åŠ¡
        material_prompt = get_module_prompt(MATERIAL_ANALYSIS_MODULE, material_data=material_data_section)
        tasks.append(call_ai_async(
            session, ai_config["api_base"], ai_config["api_key"], ai_config["model"],
            material_prompt["system"], material_prompt["user"], material_prompt["max_tokens"]
        ))
        task_info.append(("material", "analysis"))
        
        if tasks:
            print(f"ğŸš€ [V4] ç¬¬äºŒè½®ï¼šå¹¶è¡Œè°ƒç”¨ {len(tasks)} ä¸ªæ¨¡å—ï¼ˆ{len(tariff_categories)} ä¸ªå…³ç¨åˆ†ç±» + 1 ä¸ªåŸææ–™åˆ†æï¼‰...")
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            for (task_type, name), resp in zip(task_info, responses):
                if isinstance(resp, Exception):
                    print(f"âš ï¸ {task_type}/{name} å¤±è´¥: {resp}")
                    if task_type == "tariff":
                        results["tariff_sections"][name] = f"*{name} åˆ†æå¤±è´¥*"
                    else:
                        results["material_analysis"] = "*åŸææ–™æˆæœ¬åˆ†æå¤±è´¥*"
                else:
                    print(f"âœ… {task_type}/{name} å®Œæˆ")
                    if task_type == "tariff":
                        results["tariff_sections"][name] = resp
                    else:
                        results["material_analysis"] = resp
    
    return results


async def run_third_round(
    today: str,
    customer_analysis: str,
    competitor_analysis: str,
    tariff_sections: Dict[str, str],
    material_analysis: str,
    ai_config: dict
) -> str:
    """
    ç¬¬ä¸‰è½®ï¼šç”Ÿæˆæ‰§è¡Œæ‘˜è¦
    """
    # æ±‡æ€»å…³ç¨åˆ†æ
    tariff_summary = ""
    if tariff_sections:
        for category, analysis in tariff_sections.items():
            tariff_summary += f"### {category}\n{analysis}\n\n"
    else:
        tariff_summary = "æœ¬å‘¨æš‚æ— é‡å¤§å…³ç¨æ”¿ç­–å˜åŒ–ã€‚"
    
    summary_prompt = get_module_prompt(
        SUMMARY_MODULE,
        today=today,
        customer_analysis=customer_analysis,
        competitor_analysis=competitor_analysis,
        tariff_analysis=tariff_summary,
        material_analysis=material_analysis
    )
    
    async with aiohttp.ClientSession() as session:
        print("ğŸ”„ [V4] ç¬¬ä¸‰è½®ï¼šç”Ÿæˆæ‰§è¡Œæ‘˜è¦...")
        result = await call_ai_async(
            session, ai_config["api_base"], ai_config["api_key"], ai_config["model"],
            summary_prompt["system"], summary_prompt["user"], summary_prompt["max_tokens"], 120
        )
        print("âœ… æ‰§è¡Œæ‘˜è¦å®Œæˆ")
        return result


def fetch_realtime_news(keywords: list, max_news: int = 30) -> list:
    """è·å–å®æ—¶æ–°é—»"""
    import requests as req
    all_news = []
    
    # åŒèŠ±é¡º
    try:
        url = "https://news.10jqka.com.cn/tapp/news/push/stock/?page=1&tag=&track=website&pagesize=50"
        resp = req.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        if resp.status_code == 200:
            data = resp.json()
            for item in data.get("data", {}).get("list", [])[:30]:
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", ""),
                        "source": "åŒèŠ±é¡º"
                    })
    except Exception as e:
        print(f"âš ï¸ åŒèŠ±é¡ºå¤±è´¥: {e}")
    
    return all_news[:max_news]


def get_price_history() -> Dict[str, List[Dict]]:
    """è·å–ä»·æ ¼å†å²æ•°æ®"""
    try:
        from core.price_history import price_history
        return price_history.get_all_commodities_history(days=395)
    except Exception as e:
        print(f"âš ï¸ è·å–ä»·æ ¼å†å²å¤±è´¥: {e}")
        return {}


@router.post("/api/generate-analysis-v4")
async def generate_analysis_v4(request: AnalysisRequest):
    """
    V4 æ¨¡å—åŒ–åˆ†æ APIï¼ˆå‡çº§ç‰ˆï¼‰
    
    æµç¨‹ï¼š
    1. æ•°æ®å‡†å¤‡ï¼ˆæ–°é—»ã€åŸææ–™ï¼‰
    2. ç¬¬ä¸€è½®ï¼šå®¢æˆ·ã€å‹å•†ã€å…³ç¨åˆ†ç±»ï¼ˆå¹¶è¡Œï¼‰
    3. ç¬¬äºŒè½®ï¼šå…³ç¨å„åˆ†ç±»åˆ†æã€åŸææ–™æˆæœ¬åˆ†æï¼ˆå¹¶è¡Œï¼‰
    4. ç¬¬ä¸‰è½®ï¼šæ‰§è¡Œæ‘˜è¦æ•´åˆ
    5. æ‹¼è£…æœ€ç»ˆæŠ¥å‘Š
    """
    ai_config = get_ai_config()
    if request.model:
        ai_config["model"] = request.model.strip()
    if not ai_config["api_key"]:
        raise HTTPException(status_code=400, detail="æœªé…ç½® AI API Key")
    
    print("=" * 60)
    print("ğŸ“¡ [V4] å¼€å§‹æ¨¡å—åŒ–åˆ†æï¼ˆåŠ¨æ€å…³ç¨åˆ†ç±» + åŸææ–™åˆ†ç¦»åˆ†æï¼‰")
    print("=" * 60)
    
    # ========== æ•°æ®å‡†å¤‡ ==========
    print("\nğŸ“¦ [æ•°æ®å‡†å¤‡]")
    
    # è·å–æ–°é—»
    keywords = ["ç«‹è®¯", "è‹¹æœ", "åä¸º", "å…³ç¨", "è´¸æ˜“", "ä¸­ç¾", "ä¸­æ¬§", "è¶Šå—", "å°åº¦", "é“œ", "å¡‘æ–™", "ABS"]
    # å¼‚æ­¥æ‰§è¡ŒåŒæ­¥çš„çˆ¬è™«å‡½æ•°
    realtime_news = await run_in_threadpool(fetch_realtime_news, keywords)
    all_news = list(request.news) if request.news else []
    all_news.extend(realtime_news)
    
    # ä»ç¼“å­˜è·å–
    cached = cache.get("news:supply-chain")
    if cached:
        all_news.extend(cached.get("data", []))
    
    # å»é‡
    seen = set()
    unique_news = [n for n in all_news if n.get("title") and n.get("title") not in seen and not seen.add(n.get("title"))]
    print(f"   ğŸ“° æ–°é—»æ€»æ•°: {len(unique_news)} æ¡")
    
    # æ–°é—»è´¨é‡é¢„æ£€
    quality = await run_in_threadpool(precheck_news_quality, unique_news)
    print(f"   ğŸ“Š æ–°é—»è´¨é‡: {quality['quality_score']}/100")
    if quality['suggestions']:
        print(f"   ğŸ’¡ å»ºè®®: {', '.join(quality['suggestions'])}")
    
    # ç­›é€‰å…³ç¨æ–°é—»å¹¶è·å–å…¨æ–‡
    tariff_news = await run_in_threadpool(filter_tariff_news, unique_news)
    print(f"   ğŸŒ å…³ç¨ç›¸å…³: {len(tariff_news)} æ¡")
    
    if tariff_news:
        print("   ğŸ“„ è·å–æ–°é—»å…¨æ–‡...")
        tariff_news = await run_in_threadpool(fetch_news_full_content, tariff_news, max_items=20)
        content_count = len([n for n in tariff_news if n.get('content')])
        print(f"   âœ… æˆåŠŸè·å– {content_count} æ¡å…¨æ–‡")
    
    # è·å–åŸææ–™æ•°æ®
    commodity_data = []
    try:
        from scrapers.commodity import CommodityScraper
        scraper = CommodityScraper()
        # å¼‚æ­¥æ‰§è¡ŒåŒæ­¥çš„å•†å“çˆ¬å–
        commodity_data = await run_in_threadpool(scraper.scrape)
        print(f"   ğŸ“ˆ åŸææ–™æ•°æ®: {len(commodity_data)} æ¡")
    except Exception as e:
        print(f"   âš ï¸ åŸææ–™è·å–å¤±è´¥: {e}")
    
    # è·å–ä»·æ ¼å†å²
    price_history_data = await run_in_threadpool(get_price_history)
    print(f"   ğŸ“œ å†å²æ•°æ®: {len(price_history_data)} ä¸ªå“ç§")
    
    # æ„å»ºæ–°é—»æ‘˜è¦
    news_summary = "\n".join([
        f"- [{n.get('title', '')}]({n.get('url', '')}) ã€{n.get('source', '')}ã€‘"
        for n in unique_news[:50]
    ])
    
    # æ„å»ºå…³ç¨æ–°é—»å…¨æ–‡
    news_with_content = "\n\n".join([
        f"### {n.get('title', '')}\n**æ¥æº**: {n.get('source', '')} | [é“¾æ¥]({n.get('url', '')})\n**å†…å®¹**: {n.get('content', 'æ— å…¨æ–‡')[:800]}"
        for n in tariff_news[:15]
    ]) if tariff_news else "æš‚æ— å…³ç¨ç›¸å…³æ–°é—»"
    
    # æ„å»ºåŸææ–™æ•°æ®éƒ¨åˆ†ï¼ˆä¸èµ°å¤§æ¨¡å‹ï¼‰
    material_data_section = await run_in_threadpool(build_material_section, commodity_data, price_history_data)
    
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    
    try:
        # ========== ç¬¬ä¸€è½® ==========
        print("\nğŸ”„ [ç¬¬ä¸€è½®] å®¢æˆ·ã€å‹å•†ã€å…³ç¨åˆ†ç±»")
        first_round = await run_first_round(news_summary, news_with_content, ai_config)
        
        tariff_categories = first_round.get("tariff_categories", [])
        
        # ========== ç¬¬äºŒè½® ==========
        print(f"\nğŸ”„ [ç¬¬äºŒè½®] å…³ç¨åˆ†ç±»åˆ†æ({len(tariff_categories)}ä¸ª) + åŸææ–™æˆæœ¬åˆ†æ")
        second_round = await run_second_round(
            tariff_categories,
            tariff_news,
            material_data_section,
            ai_config
        )
        
        # ========== ç¬¬ä¸‰è½® ==========
        print("\nğŸ”„ [ç¬¬ä¸‰è½®] æ‰§è¡Œæ‘˜è¦æ•´åˆ")
        summary = await run_third_round(
            today,
            first_round.get("customer", ""),
            first_round.get("competitor", ""),
            second_round.get("tariff_sections", {}),
            second_round.get("material_analysis", ""),
            ai_config
        )
        
        # ========== æ‹¼è£…æŠ¥å‘Š ==========
        print("\nğŸ“ [æ‹¼è£…] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        final_report = assemble_final_report_v4(
            summary,
            first_round.get("customer", ""),
            first_round.get("competitor", ""),
            material_data_section,
            second_round.get("material_analysis", ""),
            second_round.get("tariff_sections", {}),
            today
        )
        
        print("\n" + "=" * 60)
        print("âœ… [V4] åˆ†æå®Œæˆ!")
        print("=" * 60)
        
        return {
            "status": "success",
            "content": final_report,
            "model": ai_config["model"],
            "version": "V4-modular-upgraded",
            "stats": {
                "news_count": len(unique_news),
                "tariff_news_count": len(tariff_news),
                "tariff_categories": tariff_categories,
                "commodity_count": len(commodity_data),
                "news_quality_score": quality["quality_score"]
            },
            "modules_completed": {
                "first_round": ["customer", "competitor", "tariff_classifier"],
                "second_round": list(second_round.get("tariff_sections", {}).keys()) + ["material_analysis"],
                "third_round": ["summary"]
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")


@router.get("/api/analysis-v4/status")
async def get_v4_status():
    """è·å– V4 API çŠ¶æ€"""
    ai_config = get_ai_config()
    return {
        "version": "V4-upgraded",
        "features": [
            "åŠ¨æ€å…³ç¨åˆ†ç±»ï¼ˆAIè‡ªåŠ¨è¯†åˆ«å›½å®¶/åœ°åŒºç»„åˆï¼‰",
            "å…³ç¨åˆ†ç±»å•ç‹¬åˆ†æï¼ˆæ¯ä¸ªåˆ†ç±»ç‹¬ç«‹è°ƒç”¨ï¼‰",
            "åŸææ–™æ•°æ®ç›´æ¥åµŒå…¥ï¼ˆä¸èµ°å¤§æ¨¡å‹ï¼‰",
            "åŸææ–™æˆæœ¬åˆ†æï¼ˆå•ç‹¬èµ°å¤§æ¨¡å‹ï¼‰",
            "ä¸‰è½®æ¨¡å—åŒ–è°ƒç”¨æ¶æ„"
        ],
        "model": ai_config.get("model", "æœªé…ç½®"),
        "api_configured": bool(ai_config.get("api_key"))
    }
