"""
TrendRadar Web API æœåŠ¡
æä¾›æ–°é—»æ•°æ®ã€çˆ¬è™«é…ç½®å’Œè§¦å‘çˆ¬å–çš„ REST API
"""
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import yaml
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import time
import threading
import redis

# ==================== Redis ç¼“å­˜ ====================
import os

# Redis é…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
REDIS_HOST = os.environ.get("REDIS_HOST", "localhost")
REDIS_PORT = int(os.environ.get("REDIS_PORT", "49907"))  # Docker åŠ¨æ€æ˜ å°„ç«¯å£
REDIS_DB = int(os.environ.get("REDIS_DB", "0"))
REDIS_PREFIX = "trendradar:"

# ç¼“å­˜ TTL é…ç½®ï¼ˆç§’ï¼‰
CACHE_TTL = 3600  # 1å°æ—¶ï¼Œç”¨æˆ·æ‰‹åŠ¨åˆ·æ–°æ‰æ›´æ–°

class RedisCache:
    """Redis ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = None
        self._connect()
    
    def _connect(self):
        """è¿æ¥ Redis"""
        try:
            self.client = redis.Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                db=REDIS_DB,
                decode_responses=True,
                socket_connect_timeout=5
            )
            self.client.ping()
            print(f"âœ… Redis è¿æ¥æˆåŠŸ: {REDIS_HOST}:{REDIS_PORT}")
        except Exception as e:
            print(f"âš ï¸ Redis è¿æ¥å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å†…å­˜ç¼“å­˜ä½œä¸ºå¤‡ç”¨")
            self.client = None
    
    def get(self, key: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜"""
        if not self.client:
            return None
        try:
            full_key = f"{REDIS_PREFIX}{key}"
            data = self.client.get(full_key)
            if data:
                return json.loads(data)
        except Exception as e:
            print(f"Redis GET é”™è¯¯: {e}")
        return None
    
    def set(self, key: str, value: Dict, ttl: int = CACHE_TTL):
        """è®¾ç½®ç¼“å­˜"""
        if not self.client:
            return False
        try:
            full_key = f"{REDIS_PREFIX}{key}"
            self.client.setex(full_key, ttl, json.dumps(value, ensure_ascii=False))
            return True
        except Exception as e:
            print(f"Redis SET é”™è¯¯: {e}")
            return False
    
    def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        if not self.client:
            return
        try:
            full_key = f"{REDIS_PREFIX}{key}"
            self.client.delete(full_key)
        except Exception as e:
            print(f"Redis DELETE é”™è¯¯: {e}")
    
    def exists(self, key: str) -> bool:
        """æ£€æŸ¥ key æ˜¯å¦å­˜åœ¨"""
        if not self.client:
            return False
        try:
            full_key = f"{REDIS_PREFIX}{key}"
            return self.client.exists(full_key) > 0
        except:
            return False
    
    def get_ttl(self, key: str) -> int:
        """è·å–å‰©ä½™ TTLï¼ˆç§’ï¼‰"""
        if not self.client:
            return -1
        try:
            full_key = f"{REDIS_PREFIX}{key}"
            return self.client.ttl(full_key)
        except:
            return -1
    
    def clear_all(self):
        """æ¸…é™¤æ‰€æœ‰ TrendRadar ç¼“å­˜"""
        if not self.client:
            return
        try:
            keys = self.client.keys(f"{REDIS_PREFIX}*")
            if keys:
                self.client.delete(*keys)
                print(f"âœ… å·²æ¸…é™¤ {len(keys)} ä¸ªç¼“å­˜ key")
        except Exception as e:
            print(f"Redis CLEAR é”™è¯¯: {e}")

# å…¨å±€ Redis ç¼“å­˜å®ä¾‹
cache = RedisCache()

# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title="TrendRadar API",
    description="çƒ­ç‚¹æ–°é—»èšåˆä¸æ¨é€æœåŠ¡",
    version="1.0.0"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è·¯å¾„é…ç½®
BASE_DIR = Path(__file__).parent
CONFIG_PATH = BASE_DIR / "config" / "config.yaml"
SCRAPERS_CONFIG_PATH = BASE_DIR / "config" / "scrapers.yaml"
OUTPUT_DIR = BASE_DIR / "output"


def load_config() -> Dict:
    """åŠ è½½é…ç½®"""
    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


# ==================== æ•°æ®æ¨¡å‹ ====================

class CrawlRequest(BaseModel):
    category: str
    include_custom: bool = True

class PushRequest(BaseModel):
    category: str
    data: List[Dict]

class ReportPushRequest(BaseModel):
    title: str
    content: str

class AnalysisRequest(BaseModel):
    company_name: str = "ç«‹è®¯ç²¾å¯†"
    competitors: List[str] = []
    upstream: List[str] = []
    downstream: List[str] = []
    news: List[Dict] = []


# ==================== API è·¯ç”± ====================

@app.get("/")
async def root():
    """API æ ¹è·¯å¾„"""
    return {
        "name": "TrendRadar API",
        "version": "1.0.0",
        "endpoints": {
            "/api/categories": "è·å–æ‰€æœ‰åˆ†ç±»",
            "/api/platforms": "è·å–æ‰€æœ‰å¹³å°",
            "/api/news/{category}": "è·å–æŒ‡å®šåˆ†ç±»çš„æ–°é—»",
            "/api/crawl": "è§¦å‘çˆ¬å–",
            "/api/config": "è·å–/æ›´æ–°é…ç½®",
        }
    }


@app.get("/api/categories")
async def get_categories():
    """è·å–æ‰€æœ‰åˆ†ç±»"""
    config = load_config()
    categories = config.get("categories", {})
    
    result = []
    for key, value in categories.items():
        result.append({
            "id": key,
            "name": value.get("name", key),
            "keywords": value.get("keywords", [])
        })
    
    return {"categories": result}


@app.get("/api/platforms")
async def get_platforms():
    """è·å–æ‰€æœ‰å¹³å°"""
    config = load_config()
    platforms = config.get("platforms", [])
    
    # æŒ‰åˆ†ç±»åˆ†ç»„
    by_category = {}
    for p in platforms:
        cat = p.get("category", "other")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(p)
    
    return {
        "platforms": platforms,
        "by_category": by_category,
        "total": len(platforms)
    }


@app.get("/api/data")
async def get_data(refresh: bool = False):
    """
    è·å–å¤§å®—å•†å“å¸‚åœºæ•°æ®ï¼ˆRedis ç¼“å­˜ï¼‰
    
    Args:
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆç”¨æˆ·ç‚¹å‡»åˆ·æ–°æŒ‰é’®æ—¶ä¼  trueï¼‰
    """
    cache_key = "data:commodity"
    
    if refresh:
        try:
            print(f"ğŸ”„ ç”¨æˆ·è¯·æ±‚åˆ·æ–° commodity data...")
            from scrapers.commodity import CommodityScraper
            from core.price_history import price_history
            
            scraper = CommodityScraper()
            data = scraper.scrape()
            
            # ä¿å­˜åˆ°å†å²è®°å½•ï¼ˆä»¥å‘¨ä¸ºå•ä½çš„æ•°æ®ç§¯ç´¯ï¼‰
            price_history.save_current_prices(data)
            
            category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
            data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))
            
            result = {
                "data": data,
                "source": "TrendRadar Commodity",
                "timestamp": datetime.now().isoformat(),
                "cached": False,
                "categories": list(set(item.get('category', 'å…¶ä»–') for item in data))
            }
            cache.set(cache_key, result, ttl=CACHE_TTL)
            print(f"âœ… commodity data åˆ·æ–°å®Œæˆ: {len(data)} æ¡")
            return result
        except Exception as e:
            print(f"âŒ commodity data åˆ·æ–°å¤±è´¥: {e}")
            cached = cache.get(cache_key)
            if cached:
                cached["cached"] = True
                cached["error"] = str(e)
                return cached
            raise HTTPException(status_code=500, detail=f"çˆ¬å–å¤±è´¥: {str(e)}")
    
    cached = cache.get(cache_key)
    if cached:
        cached["cached"] = True
        cached["cache_ttl"] = cache.get_ttl(cache_key)
        return cached
    
    return {
        "data": [],
        "source": "TrendRadar Commodity",
        "timestamp": None,
        "cached": False,
        "categories": [],
        "message": "æš‚æ— ç¼“å­˜æ•°æ®ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æœ€æ–°æ•°æ®"
    }


@app.get("/api/price-history")
async def get_price_history(commodity: str = None, days: int = 7):
    """
    è·å–ä»·æ ¼å†å²æ•°æ®ï¼ˆä»¥å‘¨ä¸ºå•ä½ï¼‰
    
    Args:
        commodity: å•†å“åç§°ï¼ˆå¯é€‰ï¼Œä¸å¡«åˆ™è¿”å›æ‰€æœ‰å•†å“ï¼‰
        days: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼ˆé»˜è®¤7å¤©/1å‘¨ï¼‰
    """
    from core.price_history import price_history
    
    if commodity:
        history = price_history.get_history(commodity, days)
        return {
            "commodity": commodity,
            "days": days,
            "data": history,
            "count": len(history)
        }
    else:
        all_history = price_history.get_all_commodities_history(days)
        return {
            "days": days,
            "commodities": all_history,
            "count": len(all_history)
        }


_COMMODITY_KEYWORDS = [
    'é»„é‡‘', 'ç™½é“¶', 'åŸæ²¹', 'çŸ³æ²¹', 'å¤©ç„¶æ°”', 'é“œ', 'é“', 'é”Œ',
    'ç‰ç±³', 'å°éº¦', 'å¤§è±†', 'æœŸè´§', 'å¤§å®—å•†å“', 'è´µé‡‘å±', 'æœ‰è‰²é‡‘å±',
    'gold', 'silver', 'oil', 'copper', 'commodit', 'futures',
    'å¸ƒä¼¦ç‰¹', 'WTI', 'COMEX', 'LME', 'çº½çº¦', 'ä¼¦æ•¦é‡‘å±'
]


@app.get("/api/commodity-news")
async def get_commodity_news(refresh: bool = False):
    """
    è·å–å¤§å®—å•†å“ç›¸å…³æ–°é—»ï¼ˆRedis ç¼“å­˜ï¼‰
    
    Args:
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆç”¨æˆ·ç‚¹å‡»åˆ·æ–°æŒ‰é’®æ—¶ä¼  trueï¼‰
    """
    cache_key = "news:commodity"
    
    if refresh:
        try:
            print(f"ğŸ”„ ç”¨æˆ·è¯·æ±‚åˆ·æ–° commodity news...")
            from scrapers.unified import UnifiedDataSource
            ds = UnifiedDataSource()
            data = ds.crawl_category("finance", include_custom=False)
            
            commodity_news = []
            for item in data:
                title = (item.get('title', '') or '').lower()
                if any(kw.lower() in title for kw in _COMMODITY_KEYWORDS):
                    commodity_news.append(item)
            
            if len(commodity_news) < 5:
                commodity_news = data[:10]
            
            result = {
                "data": commodity_news[:15],
                "total": len(commodity_news),
                "timestamp": datetime.now().isoformat(),
                "cached": False
            }
            cache.set(cache_key, result, ttl=CACHE_TTL)
            print(f"âœ… commodity news åˆ·æ–°å®Œæˆ: {len(commodity_news)} æ¡")
            return result
        except Exception as e:
            print(f"âŒ commodity news åˆ·æ–°å¤±è´¥: {e}")
            cached = cache.get(cache_key)
            if cached:
                cached["cached"] = True
                cached["error"] = str(e)
                return cached
            raise HTTPException(status_code=500, detail=f"çˆ¬å–å¤±è´¥: {str(e)}")
    
    cached = cache.get(cache_key)
    if cached:
        cached["cached"] = True
        cached["cache_ttl"] = cache.get_ttl(cache_key)
        return cached
    
    return {
        "data": [],
        "total": 0,
        "timestamp": None,
        "cached": False,
        "message": "æš‚æ— ç¼“å­˜æ•°æ®ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æœ€æ–°æ•°æ®"
    }


_SUPPLY_CHAIN_KEYWORDS = [
    # æ ¸å¿ƒå…¬å¸
    "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹", "BOE",
    "æ¬£æ—ºè¾¾", "å¾·èµ›", "èˆœå®‡", "é¹é¼", "ä¸œå±±ç²¾å¯†", "é¢†ç›Š", "ç‘å£°",
    # å®¢æˆ·
    "è‹¹æœ", "Apple", "iPhone", "AirPods", "Vision Pro", "iPad", "Mac",
    "åä¸º", "Huawei", "é¸¿è’™", "Mate", "è£è€€",
    "å°ç±³", "OPPO", "vivo", "ä¸‰æ˜Ÿ", "Samsung",
    # è¡Œä¸šå…³é”®è¯
    "æ¶ˆè´¹ç”µå­", "æœé“¾", "ä»£å·¥", "ä¾›åº”é“¾", "èŠ¯ç‰‡", "åŠå¯¼ä½“",
    "æ™ºèƒ½æ‰‹æœº", "ç©¿æˆ´", "è€³æœº", "VR", "AR", "XR",
    "æ–°èƒ½æºæ±½è½¦", "ç”µåŠ¨æ±½è½¦", "åŠ¨åŠ›ç”µæ± ", "é”‚ç”µ",
    "AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "GPU", "è‹±ä¼Ÿè¾¾"
]


@app.get("/api/news/supply-chain")
async def get_supply_chain_news(refresh: bool = False):
    """
    è·å–ä¾›åº”é“¾ç›¸å…³æ–°é—»ï¼ˆRedis ç¼“å­˜ï¼‰
    
    Args:
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆç”¨æˆ·ç‚¹å‡»åˆ·æ–°æŒ‰é’®æ—¶ä¼  trueï¼‰
    """
    cache_key = "news:supply-chain"
    
    # ç”¨æˆ·ç‚¹å‡»åˆ·æ–°æŒ‰é’®
    if refresh:
        try:
            print(f"ğŸ”„ ç”¨æˆ·è¯·æ±‚åˆ·æ–° supply-chain...")
            news = fetch_realtime_news(_SUPPLY_CHAIN_KEYWORDS)
            result = {
                "status": "success",
                "data": news,
                "count": len(news),
                "timestamp": datetime.now().isoformat(),
                "cached": False
            }
            cache.set(cache_key, result, ttl=CACHE_TTL)
            print(f"âœ… supply-chain åˆ·æ–°å®Œæˆ: {len(news)} æ¡")
            return result
        except Exception as e:
            print(f"âŒ supply-chain åˆ·æ–°å¤±è´¥: {e}")
            cached = cache.get(cache_key)
            if cached:
                cached["cached"] = True
                cached["error"] = str(e)
                return cached
            raise HTTPException(status_code=500, detail=f"çˆ¬å–å¤±è´¥: {str(e)}")
    
    # ä» Redis è·å–ç¼“å­˜
    cached = cache.get(cache_key)
    if cached:
        cached["cached"] = True
        cached["cache_ttl"] = cache.get_ttl(cache_key)
        return cached
    
    # æ— ç¼“å­˜ï¼Œè¿”å›ç©ºæ•°æ®
    return {
        "status": "empty",
        "data": [],
        "count": 0,
        "timestamp": None,
        "cached": False,
        "message": "æš‚æ— ç¼“å­˜æ•°æ®ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æœ€æ–°æ•°æ®"
    }


def _crawl_news(category: str, include_custom: bool = True) -> Dict:
    """çˆ¬å–æ–°é—»æ•°æ®ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰"""
    from scrapers.unified import UnifiedDataSource
    ds = UnifiedDataSource()
    data = ds.crawl_category(category, include_custom=include_custom)
    
    sources = {}
    for item in data:
        src = item.get("platform_name", item.get("platform", "unknown"))
        sources[src] = sources.get(src, 0) + 1
    
    return {
        "category": category,
        "total": len(data),
        "sources": sources,
        "data": data,
        "timestamp": datetime.now().isoformat(),
        "cached": False
    }


@app.get("/api/news/{category}")
async def get_news(category: str, include_custom: bool = True, refresh: bool = False):
    """
    è·å–æŒ‡å®šåˆ†ç±»çš„æ–°é—»ï¼ˆRedis ç¼“å­˜ï¼‰
    
    Args:
        category: åˆ†ç±»åç§° (finance, news, social, tech, all)
        include_custom: æ˜¯å¦åŒ…å«è‡ªå®šä¹‰çˆ¬è™«æ•°æ®
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆç”¨æˆ·ç‚¹å‡»åˆ·æ–°æŒ‰é’®æ—¶ä¼  trueï¼‰
    
    ç¼“å­˜ç­–ç•¥ï¼š
        - é»˜è®¤è¿”å› Redis ç¼“å­˜ï¼ˆ1å°æ—¶ TTLï¼‰
        - åªæœ‰ refresh=true æ—¶æ‰é‡æ–°çˆ¬å–
        - æ— ç¼“å­˜æ—¶è¿”å›ç©ºæ•°æ®ï¼Œæç¤ºç”¨æˆ·ç‚¹å‡»åˆ·æ–°
    """
    cache_key = f"news:{category}:{include_custom}"
    
    # ç”¨æˆ·ç‚¹å‡»åˆ·æ–°æŒ‰é’®ï¼Œå¼ºåˆ¶é‡æ–°çˆ¬å–
    if refresh:
        try:
            print(f"ğŸ”„ ç”¨æˆ·è¯·æ±‚åˆ·æ–° {category}...")
            result = _crawl_news(category, include_custom)
            cache.set(cache_key, result, ttl=CACHE_TTL)
            print(f"âœ… {category} åˆ·æ–°å®Œæˆ: {result['total']} æ¡")
            return result
        except Exception as e:
            print(f"âŒ {category} åˆ·æ–°å¤±è´¥: {e}")
            # åˆ·æ–°å¤±è´¥æ—¶å°è¯•è¿”å›æ—§ç¼“å­˜
            cached = cache.get(cache_key)
            if cached:
                cached["cached"] = True
                cached["error"] = str(e)
                return cached
            raise HTTPException(status_code=500, detail=f"çˆ¬å–å¤±è´¥: {str(e)}")
    
    # ä» Redis è·å–ç¼“å­˜
    cached = cache.get(cache_key)
    if cached:
        cached["cached"] = True
        ttl = cache.get_ttl(cache_key)
        cached["cache_ttl"] = ttl
        return cached
    
    # æ— ç¼“å­˜ï¼Œè¿”å›ç©ºæ•°æ®æç¤ºç”¨æˆ·åˆ·æ–°
    return {
        "category": category,
        "total": 0,
        "sources": {},
        "data": [],
        "timestamp": None,
        "cached": False,
        "message": "æš‚æ— ç¼“å­˜æ•°æ®ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æœ€æ–°æ•°æ®"
    }


@app.post("/api/crawl")
async def trigger_crawl(request: CrawlRequest, background_tasks: BackgroundTasks):
    """
    è§¦å‘çˆ¬å–ä»»åŠ¡
    
    Args:
        category: è¦çˆ¬å–çš„åˆ†ç±»
        include_custom: æ˜¯å¦åŒ…å«è‡ªå®šä¹‰çˆ¬è™«
    """
    try:
        # ä¾›åº”é“¾åˆ†ç±»ç‰¹æ®Šå¤„ç†ï¼ˆåŒæ—¶æ”¯æŒ supply-chain å’Œ supply_chainï¼‰
        if request.category in ["supply-chain", "supply_chain"]:
            keywords = [
                "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹", "BOE",
                "æ¬£æ—ºè¾¾", "å¾·èµ›", "èˆœå®‡", "é¹é¼", "ä¸œå±±ç²¾å¯†", "é¢†ç›Š", "ç‘å£°",
                "è‹¹æœ", "Apple", "iPhone", "AirPods", "Vision Pro", "iPad", "Mac",
                "åä¸º", "Huawei", "é¸¿è’™", "Mate", "è£è€€",
                "å°ç±³", "OPPO", "vivo", "ä¸‰æ˜Ÿ", "Samsung",
                "æ¶ˆè´¹ç”µå­", "æœé“¾", "ä»£å·¥", "ä¾›åº”é“¾", "èŠ¯ç‰‡", "åŠå¯¼ä½“",
                "AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "GPU", "è‹±ä¼Ÿè¾¾"
            ]
            data = fetch_realtime_news(keywords)
            
            # æ›´æ–°ç¼“å­˜
            _supply_chain_news_cache["data"] = data
            _supply_chain_news_cache["timestamp"] = datetime.now()
            
            return {
                "status": "success",
                "category": request.category,
                "total": len(data),
                "message": f"å·²çˆ¬å– {len(data)} æ¡ä¾›åº”é“¾ç›¸å…³æ–°é—»"
            }
        
        from scrapers.unified import UnifiedDataSource
        ds = UnifiedDataSource()
        
        # çˆ¬å–æ•°æ®
        data = ds.crawl_category(request.category, include_custom=request.include_custom)
        
        # è·å– webhook URL
        config = load_config()
        webhook_url = config.get("notification", {}).get("webhooks", {}).get("wework_url", "")
        
        # å¼‚æ­¥æ¨é€
        if webhook_url and data:
            background_tasks.add_task(ds.push_to_wework, data, request.category, webhook_url)
        
        return {
            "status": "success",
            "category": request.category,
            "total": len(data),
            "message": f"å·²çˆ¬å– {len(data)} æ¡æ•°æ®" + ("ï¼Œæ­£åœ¨æ¨é€..." if webhook_url else "")
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/config")
async def get_config():
    """è·å–é…ç½®"""
    config = load_config()
    
    # éšè—æ•æ„Ÿä¿¡æ¯
    if "notification" in config and "webhooks" in config["notification"]:
        webhooks = config["notification"]["webhooks"]
        for key in webhooks:
            if webhooks[key] and len(str(webhooks[key])) > 10:
                webhooks[key] = webhooks[key][:10] + "***"
    
    return config


# æŠ¥å‘Šå­˜å‚¨ç›®å½•
REPORTS_DIR = BASE_DIR / "reports"
REPORTS_DIR.mkdir(exist_ok=True)

# ==================== å¸‚åœºåˆ†æ API ====================

# å¸‚åœºåˆ†æç¼“å­˜
_market_analysis_cache = {
    "content": None,
    "timestamp": None,
    "ttl": 1800  # 30åˆ†é’Ÿç¼“å­˜
}

@app.get("/api/market-analysis")
async def get_market_analysis(refresh: bool = False):
    """
    è·å– AI ç”Ÿæˆçš„å¸‚åœºåˆ†ææŠ¥å‘Š
    
    Args:
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
    """
    import os
    import requests as req
    
    # æ£€æŸ¥ç¼“å­˜
    if not refresh and _market_analysis_cache["content"]:
        cache_age = (datetime.now() - _market_analysis_cache["timestamp"]).total_seconds()
        if cache_age < _market_analysis_cache["ttl"]:
            return {
                "status": "success",
                "content": _market_analysis_cache["content"],
                "cached": True,
                "cache_age": int(cache_age),
                "timestamp": _market_analysis_cache["timestamp"].isoformat()
            }
    
    config = load_config()
    ai_config = config.get("ai", {})
    
    # æ”¯æŒå†…å¤–ç½‘åŒ API é…ç½®
    internal_config = ai_config.get("internal", {})
    external_config = ai_config.get("external", {})
    
    # å†…ç½‘é…ç½®
    internal_api_key = internal_config.get("api_key", "")
    internal_api_base = internal_config.get("api_base", "http://10.180.116.5:6410/v1")
    internal_model = internal_config.get("model", "Qwen_Qwen3-VL-235B-A22B-Instruct-FP8")
    
    # å¤–ç½‘é…ç½®
    external_api_key = external_config.get("api_key", "") or os.environ.get("AI_API_KEY", "")
    external_api_base = external_config.get("api_base", "http://10.180.116.5:6410/v1")
    external_model = external_config.get("model", "Qwen_Qwen3-VL-235B-A22B-Instruct-FP8")
    
    # å…¼å®¹æ—§é…ç½®
    if not internal_config and not external_config:
        internal_api_key = ai_config.get("api_key", "")
        internal_api_base = ai_config.get("api_base", "http://10.180.116.5:6410/v1")
        internal_model = ai_config.get("model", "Qwen/Qwen2.5-7B-Instruct")
    
    # è·å–å®æ—¶å¸‚åœºæ•°æ®
    from scrapers.commodity import CommodityScraper
    scraper = CommodityScraper()
    commodity_data = scraper.scrape()
    
    # æ„å»ºå•†å“æ•°æ®æ‘˜è¦
    commodity_summary = []
    for item in commodity_data[:20]:
        name = item.get('chinese_name') or item.get('name', '')
        price = item.get('price', 0)
        change = item.get('change_percent', 0)
        unit = item.get('unit', '')
        commodity_summary.append(f"- {name}: ${price} ({'+' if change >= 0 else ''}{change}%) {unit}")
    
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    
    prompt = f"""# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¤§å®—å•†å“å¸‚åœºåˆ†æå¸ˆï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„è´µé‡‘å±ã€èƒ½æºå’Œå·¥ä¸šé‡‘å±å¸‚åœºç ”ç©¶ç»éªŒã€‚

# ä»»åŠ¡ç›®æ ‡
åŸºäºä»¥ä¸‹å®æ—¶å¸‚åœºæ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„å¸‚åœºåˆ†ææŠ¥å‘Šã€‚

# åˆ†ææ—¶é—´
{today}

# å®æ—¶å¸‚åœºæ•°æ®
{chr(10).join(commodity_summary)}

# è¾“å‡ºè¦æ±‚
è¯·ç”Ÿæˆä¸€ä»½ç®€æ´çš„å¸‚åœºåˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š

**å¸‚åœºæ¦‚å†µ**
ç”¨2-3å¥è¯æ¦‚è¿°ä»Šæ—¥å¸‚åœºæ•´ä½“è¡¨ç°ã€‚

**é‡ç‚¹å…³æ³¨**
åˆ—å‡º3-4ä¸ªå€¼å¾—å…³æ³¨çš„å¸‚åœºåŠ¨æ€æˆ–å“ç§ï¼ˆä½¿ç”¨è¦ç‚¹åˆ—è¡¨ï¼‰ã€‚

**æ“ä½œå»ºè®®**
ç»™å‡º1-2æ¡ç®€çŸ­çš„æ“ä½œå»ºè®®ã€‚

# æ ¼å¼è¦æ±‚
1. ä½¿ç”¨Markdownæ ¼å¼
2. æ€»é•¿åº¦æ§åˆ¶åœ¨200å­—ä»¥å†…
3. è¯­è¨€ç®€æ´ä¸“ä¸š
4. ä¸è¦ä½¿ç”¨ä»£ç å—
5. æ ‡é¢˜ä½¿ç”¨ **åŠ ç²—** æ ¼å¼"""

    def call_ai_api(api_base, api_key, model, timeout=60):
        headers = {"Content-Type": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        
        response = req.post(
            f"{api_base.rstrip('/')}/chat/completions",
            headers=headers,
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å¤§å®—å•†å“å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿ç®€æ´å‡†ç¡®åœ°åˆ†æå¸‚åœºåŠ¨æ€ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1000
            },
            timeout=timeout
        )
        return response
    
    used_model = ""
    used_api = ""
    
    try:
        # ä¼˜å…ˆå°è¯•å†…ç½‘ API
        print(f"ğŸ”„ å¸‚åœºåˆ†æ: å°è¯•å†…ç½‘ API...")
        response = call_ai_api(internal_api_base, internal_api_key, internal_model, timeout=30)
        
        if response.status_code == 200:
            used_model = internal_model
            used_api = "å†…ç½‘"
            print(f"âœ… å†…ç½‘ API è°ƒç”¨æˆåŠŸ")
        else:
            raise Exception(f"å†…ç½‘ API è¿”å› {response.status_code}")
            
    except Exception as e:
        print(f"âš ï¸ å†…ç½‘ API ä¸å¯ç”¨: {e}")
        print(f"ğŸ”„ åˆ‡æ¢åˆ°å¤–ç½‘ API...")
        
        if not external_api_key:
            # è¿”å›é»˜è®¤åˆ†æ
            default_content = f"""**å¸‚åœºæ¦‚å†µ**
ä»Šæ—¥å¤§å®—å•†å“å¸‚åœºæ•´ä½“è¡¨ç°å¹³ç¨³ï¼Œè´µé‡‘å±æ¿å—å°å¹…æ³¢åŠ¨ï¼Œèƒ½æºä»·æ ¼ç»´æŒéœ‡è¡æ ¼å±€ã€‚

**é‡ç‚¹å…³æ³¨**
* é»„é‡‘ä»·æ ¼ç»´æŒé«˜ä½ï¼Œå…³æ³¨ç¾è”å‚¨æ”¿ç­–åŠ¨å‘
* åŸæ²¹ä»·æ ¼å—ä¾›éœ€å½±å“éœ‡è¡
* å·¥ä¸šé‡‘å±å—ç»æµæ•°æ®å½±å“

**æ“ä½œå»ºè®®**
ä¿æŒè§‚æœ›ï¼Œç­‰å¾…æ›´æ˜ç¡®çš„å¸‚åœºä¿¡å·ã€‚

---
*æ•°æ®æ›´æ–°: {today}*"""
            return {
                "status": "success",
                "content": default_content,
                "cached": False,
                "model": "fallback",
                "api_source": "é»˜è®¤",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            response = call_ai_api(external_api_base, external_api_key, external_model, timeout=60)
            used_model = external_model
            used_api = "å¤–ç½‘"
            print(f"âœ… å¤–ç½‘ API è°ƒç”¨æˆåŠŸ")
        except Exception as e2:
            raise HTTPException(status_code=500, detail=f"AI API ä¸å¯ç”¨: {e2}")
    
    try:
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail=f"AI APIè°ƒç”¨å¤±è´¥")
        
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
        else:
            raise HTTPException(status_code=500, detail="æ— æ³•è§£æAIå“åº”")
        
        # æ›´æ–°ç¼“å­˜
        _market_analysis_cache["content"] = content
        _market_analysis_cache["timestamp"] = datetime.now()
        
        return {
            "status": "success",
            "content": content,
            "cached": False,
            "model": used_model,
            "api_source": used_api,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆåˆ†æå¤±è´¥: {str(e)}")


@app.post("/api/push-report")
async def push_report(request: ReportPushRequest):
    """æ¨é€åˆ†ææŠ¥å‘Šåˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ¸²æŸ“ä¸ºå›¾ç‰‡ç›´æ¥å‘é€ï¼‰"""
    import requests
    import urllib3
    import hashlib
    import base64
    import markdown
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    config = load_config()
    webhook_urls = config.get("notification", {}).get("webhooks", {}).get("wework_url", "")
    
    # æ”¯æŒå•ä¸ªURLæˆ–URLåˆ—è¡¨
    if isinstance(webhook_urls, str):
        webhook_urls = [webhook_urls] if webhook_urls else []
    elif not webhook_urls:
        webhook_urls = []
    
    if not webhook_urls:
        return {"status": "error", "message": "æœªé…ç½®ä¼ä¸šå¾®ä¿¡ Webhookï¼Œè¯·åœ¨ config/config.yaml ä¸­è®¾ç½® wework_url"}
    
    try:
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_id = hashlib.md5(f"{request.title}{timestamp}".encode()).hexdigest()[:8]
        filename = f"report_{timestamp}_{report_id}.md"
        filepath = REPORTS_DIR / filename
        
        # å†™å…¥ Markdown æ–‡ä»¶
        full_report = f"""# {request.title}

> ğŸ“… ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
> ğŸ¤– æ¥æºï¼šç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†æåŠ©æ‰‹

---

{request.content}

---
*æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚*
"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(full_report)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {filepath}")
        
        # æ¸²æŸ“æŠ¥å‘Šä¸ºå›¾ç‰‡
        image_data = await render_report_to_image(request.title, request.content, timestamp)
        
        if image_data:
            # è®¡ç®—å›¾ç‰‡MD5
            image_md5 = hashlib.md5(image_data).hexdigest()
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # å‘é€å›¾ç‰‡åˆ°ä¼ä¸šå¾®ä¿¡
            payload = {
                "msgtype": "image",
                "image": {
                    "base64": image_base64,
                    "md5": image_md5
                }
            }
            
            success_count = 0
            errors = []
            for webhook_url in webhook_urls:
                try:
                    resp = requests.post(webhook_url, json=payload, timeout=60, verify=False)
                    if resp.status_code == 200 and resp.json().get("errcode") == 0:
                        success_count += 1
                        print(f"âœ… å›¾ç‰‡æ¨é€æˆåŠŸ: {webhook_url[:50]}...")
                    else:
                        errors.append(f"{webhook_url[:30]}: {resp.json().get('errmsg', 'HTTP ' + str(resp.status_code))}")
                except Exception as e:
                    errors.append(f"{webhook_url[:30]}: {str(e)[:50]}")
            
            if success_count > 0:
                print(f"âœ… æ¨é€å®Œæˆ: {success_count}/{len(webhook_urls)} ä¸ªç¾¤æˆåŠŸ")
                return {
                    "status": "success",
                    "message": f"æŠ¥å‘Šå›¾ç‰‡å·²æ¨é€åˆ° {success_count}/{len(webhook_urls)} ä¸ªç¾¤",
                    "filename": filename,
                    "errors": errors if errors else None
                }
            else:
                return {"status": "error", "message": f"æ‰€æœ‰æ¨é€å‡å¤±è´¥: {'; '.join(errors)}"}
        else:
            # å›¾ç‰‡æ¸²æŸ“å¤±è´¥ï¼Œé™çº§ä¸ºMarkdownæ‘˜è¦
            print("âš ï¸ å›¾ç‰‡æ¸²æŸ“å¤±è´¥ï¼Œé™çº§ä¸ºMarkdownæ‘˜è¦å‘é€")
            summary = request.content[:3500]
            if len(request.content) > 3500:
                last_newline = summary.rfind('\n')
                if last_newline > 2000:
                    summary = summary[:last_newline]
                summary += "\n\n... *(æŠ¥å‘Šè¾ƒé•¿ï¼Œå·²æˆªæ–­)*"
            
            message = f"""ğŸ“Š **{request.title}**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“… ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{summary}"""
            
            payload = {"msgtype": "markdown", "markdown": {"content": message}}
            
            success_count = 0
            errors = []
            for webhook_url in webhook_urls:
                try:
                    resp = requests.post(webhook_url, json=payload, timeout=30, verify=False)
                    if resp.status_code == 200 and resp.json().get("errcode") == 0:
                        success_count += 1
                except Exception as e:
                    errors.append(str(e)[:50])
            
            return {
                "status": "partial",
                "message": f"å›¾ç‰‡æ¸²æŸ“å¤±è´¥ï¼Œå·²å‘é€æ–‡å­—æ‘˜è¦åˆ° {success_count}/{len(webhook_urls)} ä¸ªç¾¤",
                "errors": errors if errors else None
            }
        
    except Exception as e:
        error_msg = str(e)
        if "SSL" in error_msg or "ssl" in error_msg:
            return {"status": "error", "message": "SSLè¿æ¥å¤±è´¥ï¼Œå¯èƒ½æ˜¯ä»£ç†/VPNå¯¼è‡´ã€‚è¯·å°è¯•å…³é—­ä»£ç†åé‡è¯•ã€‚"}
        return {"status": "error", "message": error_msg}


async def render_report_to_image(title: str, content: str, timestamp: str) -> bytes:
    """ä½¿ç”¨ Playwright å°†æŠ¥å‘Šæ¸²æŸ“ä¸ºå›¾ç‰‡ï¼ˆå‹ç¼©è‡³2MBä»¥å†…ï¼‰"""
    import markdown
    from io import BytesIO
    
    try:
        from playwright.async_api import async_playwright
        from PIL import Image
        
        # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œæˆªæ–­ï¼ˆé¿å…å›¾ç‰‡è¿‡å¤§ï¼‰
        max_content_length = 8000
        if len(content) > max_content_length:
            content = content[:max_content_length] + "\n\n... *(æŠ¥å‘Šè¾ƒé•¿ï¼Œå·²æˆªæ–­æ˜¾ç¤º)*"
        
        # è½¬æ¢ Markdown ä¸º HTML
        html_content = markdown.markdown(
            content,
            extensions=['tables', 'fenced_code', 'nl2br']
        )
        
        # ç”Ÿæˆå®Œæ•´çš„ HTML é¡µé¢
        full_html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            padding: 40px;
            min-width: 800px;
            max-width: 1000px;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            border-radius: 16px;
            margin-bottom: 30px;
            box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
        }}
        .header h1 {{
            font-size: 28px;
            margin-bottom: 10px;
            color: white;
        }}
        .header .meta {{
            font-size: 14px;
            opacity: 0.9;
            color: rgba(255,255,255,0.9);
        }}
        .content {{
            background: rgba(255,255,255,0.05);
            padding: 30px;
            border-radius: 16px;
            line-height: 1.8;
        }}
        h1, h2, h3, h4 {{
            color: #a5b4fc;
            margin: 20px 0 15px 0;
        }}
        h2 {{ font-size: 22px; border-bottom: 2px solid #4f46e5; padding-bottom: 10px; }}
        h3 {{ font-size: 18px; }}
        p {{ margin: 12px 0; }}
        ul, ol {{ margin: 12px 0; padding-left: 24px; }}
        li {{ margin: 6px 0; }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: rgba(0,0,0,0.2);
            border-radius: 8px;
            overflow: hidden;
        }}
        th {{
            background: rgba(79, 70, 229, 0.3);
            padding: 12px;
            text-align: left;
            font-weight: 600;
        }}
        td {{
            padding: 12px;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }}
        tr:last-child td {{ border-bottom: none; }}
        code {{
            background: rgba(0,0,0,0.3);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Fira Code', monospace;
        }}
        pre {{
            background: rgba(0,0,0,0.3);
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
        }}
        blockquote {{
            border-left: 4px solid #4f46e5;
            padding-left: 16px;
            margin: 16px 0;
            color: #a0a0b0;
        }}
        .footer {{
            margin-top: 30px;
            text-align: center;
            font-size: 12px;
            color: #6b7280;
        }}
        strong {{ color: #fbbf24; }}
        em {{ color: #a5b4fc; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“Š {title}</h1>
        <div class="meta">ğŸ“… ç”Ÿæˆæ—¶é—´ï¼š{timestamp} | ğŸ¤– ç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†æåŠ©æ‰‹</div>
    </div>
    <div class="content">
        {html_content}
    </div>
    <div class="footer">
        æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
    </div>
</body>
</html>"""
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page(viewport={'width': 800, 'height': 600})
            await page.set_content(full_html, wait_until='networkidle')
            
            # è·å–å†…å®¹é«˜åº¦å¹¶æˆªå›¾ï¼ˆé™åˆ¶æœ€å¤§é«˜åº¦ï¼‰
            height = await page.evaluate('document.body.scrollHeight')
            max_height = 4000  # é™åˆ¶æœ€å¤§é«˜åº¦
            await page.set_viewport_size({'width': 800, 'height': min(height + 50, max_height)})
            
            screenshot = await page.screenshot(full_page=True, type='jpeg', quality=85)
            await browser.close()
            
            # å¦‚æœå›¾ç‰‡ä»ç„¶å¤ªå¤§ï¼ˆ>1.8MBï¼‰ï¼Œè¿›ä¸€æ­¥å‹ç¼©
            if len(screenshot) > 1800000:
                img = Image.open(BytesIO(screenshot))
                # ç¼©å°å°ºå¯¸
                new_width = int(img.width * 0.7)
                new_height = int(img.height * 0.7)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                output = BytesIO()
                img.save(output, format='JPEG', quality=75, optimize=True)
                screenshot = output.getvalue()
            
            print(f"ğŸ“¸ æŠ¥å‘Šå›¾ç‰‡ç”ŸæˆæˆåŠŸ: {len(screenshot) / 1024:.1f} KB")
            return screenshot
            
    except Exception as e:
        print(f"âŒ å›¾ç‰‡æ¸²æŸ“å¤±è´¥: {e}")
        return None


@app.get("/api/reports/{filename}")
async def download_report(filename: str, format: str = "html"):
    """
    ä¸‹è½½æŠ¥å‘Šæ–‡ä»¶
    
    Args:
        filename: æŠ¥å‘Šæ–‡ä»¶å
        format: è¾“å‡ºæ ¼å¼ - html(é»˜è®¤ï¼Œæµè§ˆå™¨æ¸²æŸ“) æˆ– md(åŸå§‹Markdownä¸‹è½½)
    """
    from fastapi.responses import FileResponse, HTMLResponse
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†
    if ".." in filename or "/" in filename:
        raise HTTPException(status_code=400, detail="éæ³•æ–‡ä»¶å")
    
    filepath = REPORTS_DIR / filename
    if not filepath.exists():
        raise HTTPException(status_code=404, detail="æŠ¥å‘Šä¸å­˜åœ¨")
    
    # è¯»å– Markdown å†…å®¹
    with open(filepath, 'r', encoding='utf-8') as f:
        md_content = f.read()
    
    # å¦‚æœè¯·æ±‚åŸå§‹ Markdown ä¸‹è½½
    if format == "md":
        return FileResponse(
            path=str(filepath),
            filename=filename,
            media_type="text/markdown"
        )
    
    # é»˜è®¤è¿”å› HTML æ¸²æŸ“ç‰ˆæœ¬
    import markdown
    import re
    
    # é¢„å¤„ç† Markdownï¼šä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
    def preprocess_markdown(text):
        lines = text.split('\n')
        result = []
        in_table = False
        table_has_separator = False
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # æ£€æµ‹è¡¨æ ¼è¡Œï¼ˆä»¥ | å¼€å¤´å’Œç»“å°¾ï¼‰
            is_table_row = stripped.startswith('|') and stripped.endswith('|')
            is_separator = bool(re.match(r'^\|[\s\-:|]+\|$', stripped))
            
            if is_table_row:
                if not in_table:
                    in_table = True
                    table_has_separator = False
                
                # å¦‚æœæ˜¯åˆ†éš”ç¬¦è¡Œï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                if is_separator:
                    parts = stripped.split('|')
                    normalized = '|' + '|'.join([' --- ' if p.strip().replace('-', '').replace(':', '') == '' else p for p in parts[1:-1]]) + '|'
                    result.append(normalized)
                    table_has_separator = True
                else:
                    if in_table and not table_has_separator and len(result) > 0:
                        prev_line = result[-1].strip()
                        if prev_line.startswith('|') and prev_line.endswith('|'):
                            cols = prev_line.count('|') - 1
                            separator = '|' + ' --- |' * cols
                            result.append(separator)
                            table_has_separator = True
                    result.append(line)
            else:
                if in_table and stripped == '':
                    in_table = False
                    table_has_separator = False
                result.append(line)
        
        return '\n'.join(result)
    
    # é¢„å¤„ç†
    processed_content = preprocess_markdown(md_content)
    
    # è½¬æ¢ Markdown ä¸º HTML
    html_content = markdown.markdown(
        processed_content,
        extensions=['tables', 'fenced_code', 'codehilite', 'toc', 'nl2br']
    )
    
    # åå¤„ç†ï¼šä¸ºè¡¨æ ¼æ·»åŠ å®¹å™¨ä»¥æ”¯æŒæ¨ªå‘æ»šåŠ¨
    html_content = re.sub(
        r'<table>',
        '<div class="table-wrapper"><table>',
        html_content
    )
    html_content = re.sub(
        r'</table>',
        '</table></div>',
        html_content
    )
    
    # åå¤„ç†ï¼šæ£€æµ‹å¹¶è½¬æ¢JSONé›·è¾¾å›¾ä¸ºçœŸå®å›¾è¡¨
    import json
    radar_charts = []
    chart_id = 0
    
    def replace_radar_chart(match):
        nonlocal chart_id
        json_str = match.group(1)
        try:
            data = json.loads(json_str)
            if data.get('type') == 'radar' or 'dimensions' in data:
                chart_id += 1
                radar_charts.append({'id': f'radar-chart-{chart_id}', 'data': data})
                title = data.get('title', 'ç«äº‰åŠ›å¯¹æ¯”é›·è¾¾å›¾')
                return f'<div class="chart-container"><h4 class="chart-title">{title}</h4><canvas id="radar-chart-{chart_id}"></canvas></div>'
        except:
            pass
        return match.group(0)
    
    # åŒ¹é… JSON ä»£ç å—ï¼ˆåŒ…æ‹¬ json:radar-chart å’Œæ™®é€š jsonï¼‰
    html_content = re.sub(
        r'<code class="[^"]*">(\{[\s\S]*?"dimensions"[\s\S]*?\})</code>',
        replace_radar_chart,
        html_content
    )
    # ä¹ŸåŒ¹é… pre > code ç»“æ„
    html_content = re.sub(
        r'<pre><code[^>]*>(\{[\s\S]*?"dimensions"[\s\S]*?\})</code></pre>',
        replace_radar_chart,
        html_content
    )
    
    # ç”Ÿæˆé›·è¾¾å›¾åˆå§‹åŒ–JSä»£ç 
    radar_init_js = ""
    colors = [
        ('rgba(99, 102, 241, 0.8)', 'rgba(99, 102, 241, 0.2)'),   # ç´«è‰²
        ('rgba(34, 197, 94, 0.8)', 'rgba(34, 197, 94, 0.2)'),     # ç»¿è‰²
        ('rgba(245, 158, 11, 0.8)', 'rgba(245, 158, 11, 0.2)'),   # æ©™è‰²
        ('rgba(239, 68, 68, 0.8)', 'rgba(239, 68, 68, 0.2)'),     # çº¢è‰²
        ('rgba(59, 130, 246, 0.8)', 'rgba(59, 130, 246, 0.2)'),   # è“è‰²
        ('rgba(168, 85, 247, 0.8)', 'rgba(168, 85, 247, 0.2)'),   # ç´«çº¢
    ]
    
    for chart in radar_charts:
        chart_data = chart['data']
        dimensions = chart_data.get('dimensions', [])
        companies = chart_data.get('companies', {})
        
        datasets_js = []
        for i, (company, scores) in enumerate(companies.items()):
            color_border, color_bg = colors[i % len(colors)]
            datasets_js.append(f'''{{
                label: '{company}',
                data: {scores},
                borderColor: '{color_border}',
                backgroundColor: '{color_bg}',
                borderWidth: 2,
                pointBackgroundColor: '{color_border}',
                pointRadius: 4
            }}''')
        
        radar_init_js += f'''
        new Chart(document.getElementById('{chart['id']}'), {{
            type: 'radar',
            data: {{
                labels: {json.dumps(dimensions, ensure_ascii=False)},
                datasets: [{','.join(datasets_js)}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: true,
                scales: {{
                    r: {{
                        min: 0,
                        max: 10,
                        ticks: {{ stepSize: 2, color: '#6b6b7a', backdropColor: 'transparent' }},
                        grid: {{ color: 'rgba(255,255,255,0.1)' }},
                        angleLines: {{ color: 'rgba(255,255,255,0.1)' }},
                        pointLabels: {{ color: '#a0a0b0', font: {{ size: 12 }} }}
                    }}
                }},
                plugins: {{
                    legend: {{
                        position: 'bottom',
                        labels: {{ color: '#a0a0b0', padding: 20, font: {{ size: 12 }} }}
                    }}
                }}
            }}
        }});
        '''
    
    # ç”Ÿæˆå®Œæ•´ HTML é¡µé¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    html_page = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç«‹è®¯æŠ€æœ¯æ–°é—»ä¸“ä¸šåˆ†æåŠ©æ‰‹</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Noto+Sans+SC:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {{
            --bg-primary: #0a0a0f;
            --bg-secondary: #12121a;
            --bg-card: #1a1a24;
            --bg-hover: #22222e;
            --text-primary: #f0f0f5;
            --text-secondary: #a0a0b0;
            --text-muted: #6b6b7a;
            --accent: #6366f1;
            --accent-light: #818cf8;
            --accent-dim: rgba(99, 102, 241, 0.15);
            --success: #22c55e;
            --success-dim: rgba(34, 197, 94, 0.15);
            --warning: #f59e0b;
            --warning-dim: rgba(245, 158, 11, 0.15);
            --danger: #ef4444;
            --danger-dim: rgba(239, 68, 68, 0.15);
            --border: #2a2a3a;
            --border-light: #3a3a4a;
            --gradient-1: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
            --gradient-2: linear-gradient(135deg, #0a0a0f 0%, #1a1a24 100%);
            --shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
        }}
        
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        
        html {{ scroll-behavior: smooth; }}
        
        body {{
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.75;
            font-size: 15px;
            min-height: 100vh;
        }}
        
        /* é¡¶éƒ¨å¯¼èˆªæ  */
        .navbar {{
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 60px;
            background: rgba(10, 10, 15, 0.85);
            backdrop-filter: blur(20px);
            border-bottom: 1px solid var(--border);
            z-index: 1000;
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 0 2rem;
        }}
        
        .navbar-brand {{
            display: flex;
            align-items: center;
            gap: 0.75rem;
            font-weight: 700;
            font-size: 1.25rem;
            color: var(--text-primary);
        }}
        
        .navbar-brand svg {{
            width: 28px;
            height: 28px;
        }}
        
        .navbar-actions {{
            display: flex;
            gap: 0.75rem;
        }}
        
        .btn {{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: 8px;
            font-size: 0.875rem;
            font-weight: 500;
            text-decoration: none;
            transition: all 0.2s ease;
            cursor: pointer;
            border: none;
        }}
        
        .btn-primary {{
            background: var(--gradient-1);
            color: white;
        }}
        
        .btn-primary:hover {{
            transform: translateY(-1px);
            box-shadow: 0 4px 20px rgba(99, 102, 241, 0.4);
        }}
        
        .btn-ghost {{
            background: transparent;
            color: var(--text-secondary);
            border: 1px solid var(--border);
        }}
        
        .btn-ghost:hover {{
            background: var(--bg-hover);
            color: var(--text-primary);
            border-color: var(--border-light);
        }}
        
        /* ä¸»å†…å®¹åŒº */
        .main {{
            max-width: 900px;
            margin: 0 auto;
            padding: 100px 2rem 4rem;
        }}
        
        /* æŠ¥å‘Šå¤´éƒ¨ */
        .report-header {{
            margin-bottom: 3rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid var(--border);
        }}
        
        .report-meta {{
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin-bottom: 1.5rem;
        }}
        
        .meta-badge {{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.375rem 0.875rem;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 20px;
            font-size: 0.8rem;
            color: var(--text-secondary);
        }}
        
        /* æ–‡ç« å†…å®¹ */
        article {{
            color: var(--text-secondary);
        }}
        
        article h1 {{
            font-size: 2.25rem;
            font-weight: 700;
            color: var(--text-primary);
            margin: 2.5rem 0 1.5rem;
            letter-spacing: -0.02em;
            line-height: 1.3;
        }}
        
        article h1:first-child {{
            margin-top: 0;
        }}
        
        article h2 {{
            font-size: 1.5rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 3rem 0 1.25rem;
            padding-bottom: 0.75rem;
            border-bottom: 2px solid var(--accent);
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }}
        
        article h2::before {{
            content: '';
            width: 4px;
            height: 24px;
            background: var(--gradient-1);
            border-radius: 2px;
        }}
        
        article h3 {{
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 2rem 0 1rem;
        }}
        
        article h4 {{
            font-size: 1.05rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 1.5rem 0 0.75rem;
        }}
        
        article p {{
            margin-bottom: 1.25rem;
            color: var(--text-secondary);
        }}
        
        article strong {{
            color: var(--text-primary);
            font-weight: 600;
        }}
        
        /* å¼•ç”¨å— */
        article blockquote {{
            background: var(--accent-dim);
            border-left: 4px solid var(--accent);
            border-radius: 0 12px 12px 0;
            padding: 1.25rem 1.5rem;
            margin: 1.5rem 0;
        }}
        
        article blockquote p {{
            margin: 0;
            color: var(--text-primary);
        }}
        
        article blockquote strong {{
            color: var(--accent-light);
        }}
        
        /* è¡¨æ ¼ */
        .table-wrapper {{
            overflow-x: auto;
            margin: 1.5rem 0;
            border-radius: 12px;
            border: 1px solid var(--border);
            background: var(--bg-card);
        }}
        
        article table {{
            width: 100%;
            border-collapse: collapse;
            font-size: 0.875rem;
        }}
        
        article th {{
            background: var(--bg-secondary);
            color: var(--accent-light);
            font-weight: 600;
            text-align: left;
            padding: 1rem;
            white-space: nowrap;
            border-bottom: 1px solid var(--border);
        }}
        
        article td {{
            padding: 0.875rem 1rem;
            border-bottom: 1px solid var(--border);
            color: var(--text-secondary);
            vertical-align: top;
        }}
        
        article tr:last-child td {{
            border-bottom: none;
        }}
        
        article tr:hover td {{
            background: var(--bg-hover);
        }}
        
        article td strong {{
            color: var(--text-primary);
        }}
        
        /* è¡¨æ ¼å†…çš„æ ‡è®° */
        article td:first-child {{
            font-weight: 500;
        }}
        
        /* åˆ—è¡¨ */
        article ul, article ol {{
            margin: 1rem 0 1.5rem;
            padding-left: 1.75rem;
        }}
        
        article li {{
            margin-bottom: 0.625rem;
            color: var(--text-secondary);
        }}
        
        article li::marker {{
            color: var(--accent);
        }}
        
        article li strong {{
            color: var(--text-primary);
        }}
        
        /* ä»£ç  */
        article code {{
            background: var(--bg-secondary);
            padding: 0.2rem 0.5rem;
            border-radius: 6px;
            font-family: 'SF Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.85em;
            color: var(--success);
            border: 1px solid var(--border);
        }}
        
        article pre {{
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.25rem;
            overflow-x: auto;
            margin: 1.5rem 0;
        }}
        
        article pre code {{
            background: none;
            padding: 0;
            border: none;
            color: var(--text-secondary);
            font-size: 0.875rem;
        }}
        
        /* åˆ†éš”çº¿ */
        article hr {{
            border: none;
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--border-light), transparent);
            margin: 3rem 0;
        }}
        
        /* é›·è¾¾å›¾å®¹å™¨ */
        .chart-container {{
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.5rem;
            margin: 2rem 0;
            max-width: 600px;
        }}
        
        .chart-title {{
            color: var(--accent-light);
            font-size: 1rem;
            font-weight: 600;
            margin-bottom: 1rem;
            text-align: center;
        }}
        
        .chart-container canvas {{
            max-height: 400px;
        }}
        
        /* ç‰¹æ®Šæ ‡è®°æ ·å¼ */
        article em {{
            color: var(--text-muted);
            font-style: italic;
        }}
        
        /* é¡µè„š */
        .footer {{
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-muted);
            font-size: 0.875rem;
        }}
        
        .footer-logo {{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 0.5rem;
            color: var(--text-secondary);
            font-weight: 500;
        }}
        
        /* è¿”å›é¡¶éƒ¨æŒ‰é’® */
        .back-to-top {{
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 44px;
            height: 44px;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--text-secondary);
            cursor: pointer;
            transition: all 0.2s;
            opacity: 0;
            visibility: hidden;
        }}
        
        .back-to-top.visible {{
            opacity: 1;
            visibility: visible;
        }}
        
        .back-to-top:hover {{
            background: var(--accent);
            border-color: var(--accent);
            color: white;
            transform: translateY(-2px);
        }}
        
        /* å“åº”å¼ */
        @media (max-width: 768px) {{
            .navbar {{
                padding: 0 1rem;
            }}
            .main {{
                padding: 80px 1rem 2rem;
            }}
            article h1 {{
                font-size: 1.75rem;
            }}
            article h2 {{
                font-size: 1.25rem;
            }}
            .table-wrapper {{
                margin-left: -1rem;
                margin-right: -1rem;
                border-radius: 0;
                border-left: none;
                border-right: none;
            }}
            article th, article td {{
                padding: 0.625rem 0.75rem;
                font-size: 0.8rem;
            }}
        }}
        
        /* æ‰“å°æ ·å¼ */
        @media print {{
            .navbar, .back-to-top, .navbar-actions {{
                display: none !important;
            }}
            body {{
                background: white;
                color: #1a1a1a;
            }}
            .main {{
                padding-top: 0;
                max-width: 100%;
            }}
            article h1, article h2, article h3, article strong {{
                color: #1a1a1a;
            }}
            article p, article li, article td {{
                color: #333;
            }}
            .table-wrapper {{
                border-color: #ddd;
            }}
        }}
    </style>
</head>
<body>
    <!-- é¡¶éƒ¨å¯¼èˆª -->
    <nav class="navbar">
        <div class="navbar-brand">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <circle cx="12" cy="12" r="10"/>
                <path d="M12 6v6l4 2"/>
            </svg>
            ç«‹è®¯æŠ€æœ¯
        </div>
        <div class="navbar-actions">
            <a href="/api/reports/{filename}?format=md" download="{filename}" class="btn btn-ghost">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/>
                    <polyline points="7,10 12,15 17,10"/>
                    <line x1="12" y1="15" x2="12" y2="3"/>
                </svg>
                ä¸‹è½½ MD
            </a>
            <button onclick="window.print()" class="btn btn-primary">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M6 9V2h12v7"/>
                    <path d="M6 18H4a2 2 0 0 1-2-2v-5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2v5a2 2 0 0 1-2 2h-2"/>
                    <rect x="6" y="14" width="12" height="8"/>
                </svg>
                æ‰“å°
            </button>
        </div>
    </nav>
    
    <!-- ä¸»å†…å®¹ -->
    <main class="main">
        <article>
            {html_content}
        </article>
        
        <footer class="footer">
            <div class="footer-logo">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <path d="M12 6v6l4 2"/>
                </svg>
                ç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†æåŠ©æ‰‹
            </div>
            <p>Powered by AI Â· ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®</p>
        </footer>
    </main>
    
    <!-- è¿”å›é¡¶éƒ¨ -->
    <button class="back-to-top" onclick="window.scrollTo({{top:0,behavior:'smooth'}})">
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <polyline points="18,15 12,9 6,15"/>
        </svg>
    </button>
    
    <script>
        // è¿”å›é¡¶éƒ¨æŒ‰é’®æ˜¾ç¤ºé€»è¾‘
        const backToTop = document.querySelector('.back-to-top');
        window.addEventListener('scroll', () => {{
            if (window.scrollY > 300) {{
                backToTop.classList.add('visible');
            }} else {{
                backToTop.classList.remove('visible');
            }}
        }});
        
        // åˆå§‹åŒ–é›·è¾¾å›¾
        document.addEventListener('DOMContentLoaded', function() {{
            {radar_init_js}
        }});
    </script>
</body>
</html>"""
    
    return HTMLResponse(content=html_page)


@app.get("/api/reports")
async def list_reports():
    """åˆ—å‡ºæ‰€æœ‰æŠ¥å‘Š"""
    reports = []
    for f in sorted(REPORTS_DIR.glob("*.md"), reverse=True):
        stat = f.stat()
        reports.append({
            "filename": f.name,
            "size": stat.st_size,
            "created": datetime.fromtimestamp(stat.st_mtime).isoformat(),
            "download_url": f"http://localhost:8000/api/reports/{f.name}"
        })
    return {"reports": reports[:20]}  # æœ€è¿‘20ä»½


@app.get("/api/custom-scrapers")
async def get_custom_scrapers():
    """è·å–è‡ªå®šä¹‰çˆ¬è™«é…ç½®"""
    try:
        if SCRAPERS_CONFIG_PATH.exists():
            with open(SCRAPERS_CONFIG_PATH, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                return config.get("custom_scrapers", {})
        return {}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    config = load_config()
    
    # æ£€æŸ¥ webhook é…ç½®
    webhooks = config.get("notification", {}).get("webhooks", {})
    wework_configured = bool(webhooks.get("wework_url"))
    
    return {
        "status": "running",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "config": {
            "platforms_count": len(config.get("platforms", [])),
            "categories_count": len(config.get("categories", {})),
            "wework_configured": wework_configured,
        }
    }


def fetch_realtime_news(keywords: list) -> list:
    """
    å®æ—¶æŠ“å–ä¾›åº”é“¾ç›¸å…³æ–°é—»
    æ•°æ®æºï¼šä¸œæ–¹è´¢å¯Œã€åŒèŠ±é¡ºã€æ–°æµªè´¢ç»ç­‰è¯åˆ¸ç½‘ç«™
    """
    import requests as req
    from urllib.parse import quote
    
    all_news = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://www.eastmoney.com/"
    }
    
    # ä¸Šå¸‚å…¬å¸è‚¡ç¥¨ä»£ç æ˜ å°„ï¼ˆç”¨äºç²¾å‡†æŠ“å–ä¸ªè‚¡æ–°é—»ï¼‰
    stock_codes = {
        "ç«‹è®¯ç²¾å¯†": "002475",
        "æ­Œå°”è‚¡ä»½": "002241",
        "è“æ€ç§‘æŠ€": "300433",
        "å·¥ä¸šå¯Œè”": "601138",
        "äº¬ä¸œæ–¹A": "000725",
        "äº¬ä¸œæ–¹": "000725",
        "èˆœå®‡å…‰å­¦": "02382",
        "æ¬£æ—ºè¾¾": "300207",
        "å¾·èµ›ç”µæ± ": "000049",
        "é¹é¼æ§è‚¡": "002938",
        "ä¸œå±±ç²¾å¯†": "002384",
        "é¢†ç›Šæ™ºé€ ": "002600",
        "ç‘å£°ç§‘æŠ€": "02018",
        "ä¿¡ç»´é€šä¿¡": "300136",
        "é•¿ç›ˆç²¾å¯†": "300115",
        "æ¯”äºšè¿ª": "002594",
        "å®å¾·æ—¶ä»£": "300750",
    }
    
    # ==================== 1. ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—» ====================
    for company, code in stock_codes.items():
        if not any(kw in company for kw in keywords):
            continue
        try:
            # ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—»API
            url = f"https://search-api-web.eastmoney.com/search/jsonp?cb=jQuery&param=%7B%22uid%22%3A%22%22%2C%22keyword%22%3A%22{code}%22%2C%22type%22%3A%5B%22cmsArticleWebOld%22%5D%2C%22client%22%3A%22web%22%2C%22clientType%22%3A%22web%22%2C%22clientVersion%22%3A%22curr%22%2C%22param%22%3A%7B%22cmsArticleWebOld%22%3A%7B%22searchScope%22%3A%22default%22%2C%22sort%22%3A%22default%22%2C%22pageIndex%22%3A1%2C%22pageSize%22%3A10%2C%22preTag%22%3A%22%22%2C%22postTag%22%3A%22%22%7D%7D%7D"
            resp = req.get(url, headers=headers, timeout=8)
            text = resp.text
            # è§£æJSONP
            if "jQuery" in text:
                import json
                json_str = text[text.index("(")+1:text.rindex(")")]
                data = json.loads(json_str)
                articles = data.get("result", {}).get("cmsArticleWebOld", [])
                for item in articles:
                    title = item.get("title", "").replace("<em>", "").replace("</em>", "")
                    if title:
                        all_news.append({
                            "title": f"[{company}] {title}",
                            "url": item.get("url", ""),
                            "source": "ä¸œæ–¹è´¢å¯Œ",
                            "stock_code": code
                        })
        except Exception as e:
            print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œä¸ªè‚¡({company})æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 2. ä¸œæ–¹è´¢å¯Œå¿«è®¯ ====================
    try:
        url = "https://np-listapi.eastmoney.com/comm/web/getNewsByKeyword?keyword=&fields=title,url&pageSize=50&pageNo=1&type=0"
        resp = req.get(url, headers=headers, timeout=10)
        data = resp.json()
        if data.get("success") and data.get("data"):
            for item in data["data"].get("list", []):
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", f"https://finance.eastmoney.com/a/{item.get('code', '')}.html"),
                        "source": "ä¸œæ–¹è´¢å¯Œå¿«è®¯"
                    })
    except Exception as e:
        print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œå¿«è®¯æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 3. ä¸œæ–¹è´¢å¯Œ7x24å¿«è®¯ ====================
    try:
        url = "https://np-listapi.eastmoney.com/comm/web/getLivingList?pageSize=50&pageNo=1&type=0"
        resp = req.get(url, headers=headers, timeout=10)
        data = resp.json()
        if data.get("success") and data.get("data"):
            for item in data["data"].get("list", []):
                title = item.get("title", "") or item.get("digest", "")
                if title and any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": f"https://kuaixun.eastmoney.com/",
                        "source": "ä¸œæ–¹è´¢å¯Œ7x24"
                    })
    except Exception as e:
        print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œ7x24æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 4. åŒèŠ±é¡ºä¸ªè‚¡æ–°é—» ====================
    for company, code in stock_codes.items():
        if not any(kw in company for kw in keywords):
            continue
        try:
            # åŒèŠ±é¡ºä¸ªè‚¡æ–°é—»
            url = f"https://stockpage.10jqka.com.cn/ajax/code/{code}/type/news/"
            ths_headers = {**headers, "Referer": "https://stockpage.10jqka.com.cn/"}
            resp = req.get(url, headers=ths_headers, timeout=8)
            data = resp.json()
            if data.get("data"):
                for item in data["data"][:5]:
                    title = item.get("title", "")
                    if title:
                        all_news.append({
                            "title": f"[{company}] {title}",
                            "url": item.get("url", ""),
                            "source": "åŒèŠ±é¡º",
                            "stock_code": code
                        })
        except Exception as e:
            pass  # åŒèŠ±é¡ºåçˆ¬ä¸¥æ ¼ï¼Œé™é»˜å¤±è´¥
    
    # ==================== 5. æ–°æµªè´¢ç»æ»šåŠ¨æ–°é—» ====================
    try:
        resp = req.get(
            "https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2516&k=&num=50",
            headers={"User-Agent": "Mozilla/5.0"},
            timeout=10
        )
        data = resp.json()
        if "result" in data and "data" in data["result"]:
            for item in data["result"]["data"]:
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", ""),
                        "source": "æ–°æµªè´¢ç»"
                    })
    except Exception as e:
        print(f"âš ï¸ æ–°æµªè´¢ç»æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 6. æ–°æµªè‚¡ç¥¨æ–°é—» ====================
    try:
        resp = req.get(
            "https://feed.mix.sina.com.cn/api/roll/get?pageid=155&lid=2520&k=&num=50",
            headers={"User-Agent": "Mozilla/5.0"},
            timeout=10
        )
        data = resp.json()
        if "result" in data and "data" in data["result"]:
            for item in data["result"]["data"]:
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", ""),
                        "source": "æ–°æµªè‚¡ç¥¨"
                    })
    except Exception as e:
        print(f"âš ï¸ æ–°æµªè‚¡ç¥¨æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 7. é›ªçƒçƒ­å¸– ====================
    try:
        url = "https://xueqiu.com/statuses/hot/listV2.json?since_id=-1&max_id=-1&size=30"
        xq_headers = {**headers, "Referer": "https://xueqiu.com/", "Cookie": "xq_a_token=test"}
        resp = req.get(url, headers=xq_headers, timeout=10)
        data = resp.json()
        if data.get("data"):
            for item in data["data"].get("items", []):
                title = item.get("original_status", {}).get("title", "") or item.get("original_status", {}).get("text", "")[:80]
                if title and any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": f"https://xueqiu.com{item.get('target', '')}",
                        "source": "é›ªçƒ"
                    })
    except Exception as e:
        print(f"âš ï¸ é›ªçƒæŠ“å–å¤±è´¥: {e}")
    
    # å»é‡
    seen = set()
    unique_news = []
    for n in all_news:
        title = n["title"]
        if title not in seen and len(title) > 5:
            seen.add(title)
            unique_news.append(n)
    
    # æŒ‰æ¥æºä¼˜å…ˆçº§æ’åºï¼ˆè¯åˆ¸ç½‘ç«™ä¼˜å…ˆï¼‰
    source_priority = {"ä¸œæ–¹è´¢å¯Œ": 0, "åŒèŠ±é¡º": 1, "ä¸œæ–¹è´¢å¯Œå¿«è®¯": 2, "ä¸œæ–¹è´¢å¯Œ7x24": 3, "é›ªçƒ": 4, "æ–°æµªè‚¡ç¥¨": 5, "æ–°æµªè´¢ç»": 6}
    unique_news.sort(key=lambda x: source_priority.get(x["source"], 10))
    
    return unique_news[:50]


@app.post("/api/generate-analysis")
async def generate_analysis(request: AnalysisRequest):
    """
    ä½¿ç”¨ AI ç”Ÿæˆä¾›åº”é“¾åˆ†ææŠ¥å‘Š (OpenAI å…¼å®¹æ ¼å¼)
    
    Args:
        company_name: ä¸»ä½“å…¬å¸åç§°
        competitors: ç«äº‰å¯¹æ‰‹åˆ—è¡¨
        upstream: ä¸Šæ¸¸ä¾›åº”å•†åˆ—è¡¨
        downstream: ä¸‹æ¸¸å®¢æˆ·åˆ—è¡¨
        news: ç›¸å…³æ–°é—»åˆ—è¡¨
    """
    import os
    import requests as req
    from datetime import datetime
    
    config = load_config()
    ai_config = config.get("ai", {})
    
    # æ”¯æŒå†…å¤–ç½‘åŒ API é…ç½®
    internal_config = ai_config.get("internal", {})
    external_config = ai_config.get("external", {})
    
    # å†…ç½‘é…ç½®
    internal_api_key = internal_config.get("api_key", "")
    internal_api_base = internal_config.get("api_base", "http://10.180.116.5:6410/v1")
    internal_model = internal_config.get("model", "Qwen_Qwen3-VL-235B-A22B-Instruct-FP8")
    
    # å¤–ç½‘é…ç½®
    external_api_key = external_config.get("api_key", "") or os.environ.get("AI_API_KEY", "")
    external_api_base = external_config.get("api_base", "http://10.180.116.5:6410/v1")
    external_model = external_config.get("model", "Qwen_Qwen3-VL-235B-A22B-Instruct-FP8")
    
    # å…¼å®¹æ—§é…ç½®æ ¼å¼
    if not internal_config and not external_config:
        internal_api_key = ai_config.get("api_key", "")
        internal_api_base = ai_config.get("api_base", "http://10.180.116.5:6410/v1")
        internal_model = ai_config.get("model", "Qwen/Qwen2.5-7B-Instruct")
    
    # å®æ—¶æŠ“å–ä¾›åº”é“¾ç›¸å…³æ–°é—» - æ‰©å¤§å…³é”®è¯èŒƒå›´
    keywords = [
        # æ ¸å¿ƒå…¬å¸
        "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹", "BOE",
        "æ¬£æ—ºè¾¾", "å¾·èµ›", "èˆœå®‡", "é¹é¼", "ä¸œå±±ç²¾å¯†", "é¢†ç›Š", "ç‘å£°",
        # å®¢æˆ·
        "è‹¹æœ", "Apple", "iPhone", "AirPods", "Vision Pro", "iPad", "Mac",
        "åä¸º", "Huawei", "é¸¿è’™", "Mate", "è£è€€",
        "å°ç±³", "OPPO", "vivo", "ä¸‰æ˜Ÿ", "Samsung",
        # è¡Œä¸šå…³é”®è¯
        "æ¶ˆè´¹ç”µå­", "æœé“¾", "ä»£å·¥", "ä¾›åº”é“¾", "èŠ¯ç‰‡", "åŠå¯¼ä½“",
        "æ™ºèƒ½æ‰‹æœº", "ç©¿æˆ´", "è€³æœº", "VR", "AR", "XR",
        "æ–°èƒ½æºæ±½è½¦", "ç”µåŠ¨æ±½è½¦", "åŠ¨åŠ›ç”µæ± ", "é”‚ç”µ",
        "AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "GPU", "è‹±ä¼Ÿè¾¾"
    ]
    
    print(f"ğŸ“¡ æ­£åœ¨å®æ—¶æŠ“å–ä¾›åº”é“¾ç›¸å…³æ–°é—»...")
    realtime_news = fetch_realtime_news(keywords)
    print(f"âœ… æŠ“å–åˆ° {len(realtime_news)} æ¡ç›¸å…³æ–°é—»")
    
    # åˆå¹¶ä¼ å…¥çš„æ–°é—»å’Œå®æ—¶æŠ“å–çš„æ–°é—»
    all_news = list(request.news) if request.news else []
    all_news.extend(realtime_news)
    
    # å»é‡
    seen_titles = set()
    unique_news = []
    for n in all_news:
        title = n.get("title", "")
        if title and title not in seen_titles:
            seen_titles.add(title)
            unique_news.append(n)
    
    # æ„å»ºæ–°é—»æ‘˜è¦ï¼ˆåŒ…å«é“¾æ¥ï¼‰
    news_summary = ""
    if unique_news:
        news_items = []
        for n in unique_news[:30]:
            title = n.get('title', '')
            url = n.get('url', '')
            source = n.get('source', '')
            if url:
                news_items.append(f"- [{title}]({url}) ã€{source}ã€‘")
            else:
                news_items.append(f"- {title} ã€{source}ã€‘")
        news_summary = "\n".join(news_items)
    
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    # ç«äº‰å¯¹æ‰‹åˆ—è¡¨
    competitors = request.competitors if request.competitors else ['æ­Œå°”è‚¡ä»½', 'è“æ€ç§‘æŠ€', 'å·¥ä¸šå¯Œè”', 'é¹é¼æ§è‚¡', 'ä¸œå±±ç²¾å¯†', 'é¢†ç›Šæ™ºé€ ', 'ç‘å£°ç§‘æŠ€']
    upstream = request.upstream if request.upstream else ['äº¬ä¸œæ–¹A', 'èˆœå®‡å…‰å­¦', 'æ¬£æ—ºè¾¾', 'å¾·èµ›ç”µæ± ', 'ä¿¡ç»´é€šä¿¡', 'é•¿ç›ˆç²¾å¯†']
    downstream = request.downstream if request.downstream else ['è‹¹æœ', 'åä¸º', 'Meta', 'å¥‡ç‘æ±½è½¦', 'å°ç±³', 'OPPO/vivo']
    
    prompt = f"""# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä½é¡¶çº§æŠ•è¡Œçš„TMTè¡Œä¸šé¦–å¸­åˆ†æå¸ˆï¼Œæ‹¥æœ‰15å¹´æ¶ˆè´¹ç”µå­äº§ä¸šé“¾ç ”ç©¶ç»éªŒã€‚ä½ çš„åˆ†æä»¥æ•°æ®é©±åŠ¨ã€é€»è¾‘ä¸¥è°¨ã€ç»“è®ºæ˜ç¡®è‘—ç§°ã€‚

# ä»»åŠ¡ç›®æ ‡
ä¸º **{request.company_name}**ï¼ˆ002475.SZï¼‰ç”Ÿæˆä¸€ä»½æœºæ„çº§åˆ«çš„**ç«äº‰æ ¼å±€ä¸ä¾›åº”é“¾æ·±åº¦åˆ†ææŠ¥å‘Š**ã€‚
**åˆ†æä¸»ä½“**ï¼šç«‹è®¯ç²¾å¯†
**åˆ†æé‡ç‚¹**ï¼šå®¢æˆ·åŠ¨æ€ã€å‹å•†ç«äº‰ã€ä¾›åº”å•†é£é™©ã€ç‰©æ–™å“ç±»ï¼ˆè¿æ¥å™¨ã€çº¿æã€ç”µæºï¼‰

# åˆ†ææ—¥æœŸ
{today}

# å…¬å¸ç”»åƒ
| ç»´åº¦ | ä¿¡æ¯ |
|------|------|
| å…¬å¸åç§° | {request.company_name} |
| è‚¡ç¥¨ä»£ç  | 002475.SZ |
| æ‰€å±è¡Œä¸š | æ¶ˆè´¹ç”µå­ç²¾å¯†åˆ¶é€  |
| æ ¸å¿ƒç‰©æ–™å“ç±» | **è¿æ¥å™¨ã€çº¿æã€ç”µæºæ¨¡ç»„**ã€å£°å­¦æ¨¡ç»„ã€æ•£çƒ­æ¨¡ç»„ |
| ä¸»è¦å®¢æˆ· | è‹¹æœï¼ˆiPhone/AirPods/Apple Watch/Vision Proï¼‰ã€åä¸ºã€Metaã€æ±½è½¦å®¢æˆ· |
| å¸‚å€¼è§„æ¨¡ | çº¦2000äº¿äººæ°‘å¸ï¼ˆAè‚¡æ¶ˆè´¹ç”µå­é¾™å¤´ï¼‰ |

# ç«äº‰å¯¹æ‰‹ï¼ˆå‹å•†ï¼‰
{chr(10).join([f'- **{c}**' for c in competitors])}

# ä¸ç«‹è®¯ç›¸å…³çš„ä¸Šæ¸¸ä¾›åº”å•†ï¼ˆä¾§é‡ç‰©æ–™å“ç±»ï¼‰
{', '.join(upstream)}
**é‡ç‚¹å…³æ³¨ç‰©æ–™**ï¼šè¿æ¥å™¨ã€çº¿æã€ç”µæºæ¨¡ç»„ã€æ•£çƒ­æ¨¡ç»„

# å…³é”®å®¢æˆ·
{', '.join(downstream)}

# å®æ—¶æ–°é—»æƒ…æŠ¥ï¼ˆå…±{len(unique_news)}æ¡ï¼ŒæŠ“å–æ—¶é—´ï¼š{today}ï¼‰
**è¯·æŒ‰ç…§å®¢æˆ·ã€å‹å•†ã€ç‰©æ–™å“ç±»ä¸‰ä¸ªå±‚æ¬¡åˆ†æä»¥ä¸‹æ–°é—»**ï¼š
{news_summary if news_summary else 'âš ï¸ å½“å‰æ—¶æ®µæœªæŠ“å–åˆ°ç›´æ¥ç›¸å…³æ–°é—»'}

---

# è¾“å‡ºè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºæŠ¥å‘Šï¼Œ**ä¾§é‡å®¢æˆ·åŠ¨æ€å’Œå‹å•†åˆ†æ**ï¼š

## ä¸€ã€æ‰§è¡Œæ‘˜è¦ï¼ˆExecutive Summaryï¼‰
ç”¨4-6ä¸ªè¦ç‚¹æ¦‚æ‹¬æ ¸å¿ƒå‘ç°ï¼ŒæŒ‰ä»¥ä¸‹ç»´åº¦åˆ†ç±»ï¼š
- ğŸ“± **å®¢æˆ·åŠ¨æ€**ï¼šè‹¹æœ/åä¸º/Metaç­‰å®¢æˆ·çš„æœ€æ–°åŠ¨å‘
- ğŸ­ **å‹å•†ç«äº‰**ï¼šç«äº‰å¯¹æ‰‹çš„å¸‚åœºåŠ¨ä½œ
- ğŸ“¦ **ç‰©æ–™å“ç±»**ï¼šè¿æ¥å™¨/çº¿æ/ç”µæºç­‰æ ¸å¿ƒç‰©æ–™å¸‚åœºå˜åŒ–
- âš ï¸ **é£é™©æç¤º**ï¼šå…³ç¨ã€ä¾›åº”é“¾ä¸­æ–­ç­‰é£é™©

æ¯ä¸ªè¦ç‚¹ç”¨ âœ… âš ï¸ ğŸ”´ æ ‡æ³¨åˆ©å¥½/ä¸­æ€§/åˆ©ç©ºã€‚

## äºŒã€å…³é”®å®¢æˆ·åŠ¨æ€åˆ†æ
**ä¾§é‡åˆ†æå®¢æˆ·çš„æœ€æ–°åŠ¨æ€å¯¹{request.company_name}çš„å½±å“**ï¼š

### 2.1 å®¢æˆ·è¦ç‚¹æ€»ç»“
| å®¢æˆ· | æœ€æ–°åŠ¨æ€ | å¯¹{request.company_name}å½±å“ | å…³è”ç‰©æ–™å“ç±» | æ–°é—»æ¥æº |
|------|----------|------------------------------|--------------|----------|
| è‹¹æœ | ... | ... | è¿æ¥å™¨/çº¿æ/ç”µæº | [æ–°é—»æ ‡é¢˜](é“¾æ¥) |
| åä¸º | ... | ... | ... | ... |
| Meta | ... | ... | ... | ... |

### 2.2 æ–°é—»äº‹ä»¶æ·±åº¦è§£è¯»
æŒ‰**å®¢æˆ·ã€å‹å•†ã€ç‰©æ–™å“ç±»**ä¸‰ä¸ªå±‚æ¬¡åˆ†æï¼ˆ**å¿…é¡»ä¿ç•™æ–°é—»åŸæ–‡é“¾æ¥**ï¼‰ï¼š

| å±‚æ¬¡ | æ–°é—»æ ‡é¢˜ | æ¥æº | äº‹ä»¶æ¦‚è¿° | å¯¹{request.company_name}å½±å“ | å½±å“ç¨‹åº¦ |
|------|----------|------|----------|------------------------------|----------|
| å®¢æˆ· | [æ ‡é¢˜](é“¾æ¥) | æ¥æº | æ¦‚è¿° | å½±å“è·¯å¾„ | é«˜/ä¸­/ä½ |
| å‹å•† | [æ ‡é¢˜](é“¾æ¥) | æ¥æº | æ¦‚è¿° | å½±å“è·¯å¾„ | é«˜/ä¸­/ä½ |
| ç‰©æ–™ | [æ ‡é¢˜](é“¾æ¥) | æ¥æº | æ¦‚è¿° | å½±å“è·¯å¾„ | é«˜/ä¸­/ä½ |

## ä¸‰ã€å‹å•†ç«äº‰æ ¼å±€åˆ†æ

### 3.1 å‹å•†å¸‚å€¼ä¸ä¾›åº”é“¾å¯¹æ¯”
| å‹å•† | å¸‚å€¼(äº¿å…ƒ) | ä¸»è¥ç‰©æ–™å“ç±» | æ ¸å¿ƒå®¢æˆ· | ä¾›åº”é“¾ç‰¹ç‚¹ | å¯¹{request.company_name}å¨èƒç­‰çº§ |
|------|------------|--------------|----------|------------|----------------------------------|
| æ­Œå°”è‚¡ä»½ | ... | å£°å­¦/VR | è‹¹æœ/Meta | ... | â­â­â­ |
| å·¥ä¸šå¯Œè” | ... | è¿æ¥å™¨/æœºæ„ä»¶ | è‹¹æœ/åä¸º | ... | â­â­â­â­ |
| è“æ€ç§‘æŠ€ | ... | ç»ç’ƒ/é™¶ç“· | è‹¹æœ | ... | â­â­ |
| ... | ... | ... | ... | ... | ... |

### 3.2 æ ¸å¿ƒç‰©æ–™å“ç±»å¸‚åœºä»½é¢å¯¹æ¯”
**é‡ç‚¹åˆ†æ**ï¼šè¿æ¥å™¨ã€çº¿æã€ç”µæºæ¨¡ç»„

| ç‰©æ–™å“ç±» | {request.company_name}ä»½é¢ | æ­Œå°”ä»½é¢ | å·¥ä¸šå¯Œè”ä»½é¢ | å…¶ä»– | å¸‚åœºè¶‹åŠ¿ |
|----------|----------------------------|----------|--------------|------|----------|
| è¿æ¥å™¨ | ... | ... | ... | ... | ... |
| çº¿æ | ... | ... | ... | ... | ... |
| ç”µæºæ¨¡ç»„ | ... | ... | ... | ... | ... |

### 3.3 ç«äº‰åŠ›é›·è¾¾å›¾æ•°æ®
è¯·æä¾›ä»¥ä¸‹ç»´åº¦çš„1-10åˆ†è¯„åˆ†ï¼ˆ**å°†è‡ªåŠ¨æ¸²æŸ“ä¸ºé›·è¾¾å›¾**ï¼‰ï¼š

```json:radar-chart
{{
  "type": "radar",
  "title": "{request.company_name}ä¸å‹å•†ç«äº‰åŠ›å¯¹æ¯”",
  "dimensions": ["å®¢æˆ·å…³ç³»", "è¿æ¥å™¨èƒ½åŠ›", "çº¿æèƒ½åŠ›", "ç”µæºèƒ½åŠ›", "æˆæœ¬æ§åˆ¶", "äº§èƒ½è§„æ¨¡"],
  "companies": {{
    "{request.company_name}": [10, 9, 9, 8, 8, 9],
    "æ­Œå°”è‚¡ä»½": [7, 6, 5, 4, 7, 7],
    "å·¥ä¸šå¯Œè”": [8, 8, 7, 6, 9, 10]
  }}
}}
```

## å››ã€ä¾›åº”é“¾é£é™©è¯„ä¼°

### 4.1 ç‰©æ–™å“ç±»é£é™©çŸ©é˜µ
**ç»†åŒ–åˆ°å…·ä½“ç‰©æ–™å“ç±»**ï¼Œé‡ç‚¹å…³æ³¨**å…³ç¨å½±å“**ï¼š

| ç‰©æ–™å“ç±» | é£é™©ç±»å‹ | é£é™©æè¿° | å…³ç¨å½±å“ | é£é™©ç­‰çº§ | ç¼“è§£æªæ–½ | ç›¸å…³æ–°é—» |
|----------|----------|----------|----------|----------|----------|----------|
| è¿æ¥å™¨ | ä¾›åº”é£é™© | ... | è‹¥åŠ å¾X%å…³ç¨... | ğŸ”´/ğŸŸ¡/ğŸŸ¢ | ... | [é“¾æ¥](url) |
| çº¿æ | æˆæœ¬é£é™© | ... | ... | ... | ... | ... |
| ç”µæºæ¨¡ç»„ | æ›¿ä»£é£é™© | ... | ... | ... | ... | ... |

### 4.2 å…³ç¨æ”¿ç­–å½±å“ä¸“é¡¹åˆ†æ
| æ”¿ç­–åœºæ™¯ | æ¶‰åŠç‰©æ–™ | æˆæœ¬å½±å“ | å¯¹{request.company_name}å½±å“ | åº”å¯¹ç­–ç•¥ |
|----------|----------|----------|------------------------------|----------|
| ä¸­ç¾å…³ç¨åŠ å¾ | è¿æ¥å™¨/çº¿æ | +X% | ... | ... |
| ... | ... | ... | ... | ... |

### 4.3 å…³é”®ä¾›åº”å•†ç«äº‰åŠ›åˆ†æ
| ä¾›åº”å•† | ä¾›åº”ç‰©æ–™ | ä¸{request.company_name}å…³ç³» | ç«äº‰åŠ›è¯„åˆ† | æ›¿ä»£éš¾åº¦ | å¤‡é€‰æ–¹æ¡ˆ |
|--------|----------|------------------------------|------------|----------|----------|
| ... | è¿æ¥å™¨ | æˆ˜ç•¥åˆä½œ | â­â­â­â­ | é«˜ | ... |
| ... | ... | ... | ... | ... | ... |

## äº”ã€SWOTåˆ†æï¼ˆä»¥{request.company_name}ä¸ºä¸»ä½“ï¼‰

**åˆ†æä¸»ä½“**ï¼š{request.company_name}ï¼ˆç«‹è®¯ç²¾å¯†ï¼‰

| | æ­£é¢å› ç´  | è´Ÿé¢å› ç´  |
|---|----------|----------|
| **å†…éƒ¨å› ç´ ** | **ä¼˜åŠ¿(S)**ï¼š<br>1. [å…·ä½“ä¼˜åŠ¿] - *ç†ç”±ï¼š...*<br>2. [å…·ä½“ä¼˜åŠ¿] - *ç†ç”±ï¼š...* | **åŠ£åŠ¿(W)**ï¼š<br>1. [å…·ä½“åŠ£åŠ¿] - *ç†ç”±ï¼š...*<br>2. [å…·ä½“åŠ£åŠ¿] - *ç†ç”±ï¼š...* |
| **å¤–éƒ¨å› ç´ ** | **æœºä¼š(O)**ï¼š<br>1. [å…·ä½“æœºä¼š] - *ç†ç”±ï¼š...*<br>2. [å…·ä½“æœºä¼š] - *ç†ç”±ï¼š...* | **å¨èƒ(T)**ï¼š<br>1. [å…·ä½“å¨èƒ] - *ç†ç”±ï¼š...*<br>2. [å…·ä½“å¨èƒ] - *ç†ç”±ï¼š...* |

**æ³¨**ï¼šæ¯ä¸ªè¦ç‚¹å¿…é¡»è¯´æ˜å¾—å‡ºè¯¥ç»“è®ºçš„å…·ä½“ç†ç”±å’Œæ•°æ®æ”¯æ’‘ã€‚

## å…­ã€ç»¼åˆç»“è®ºï¼ˆå››ç»´åº¦åˆ†æï¼‰

### 6.1 å®¢æˆ·ç»´åº¦
| å®¢æˆ· | å½“å‰å…³ç³» | æœªæ¥è¶‹åŠ¿ | å…³é”®è¡ŒåŠ¨å»ºè®® |
|------|----------|----------|--------------|
| è‹¹æœ | ... | ... | ... |
| åä¸º | ... | ... | ... |
| ... | ... | ... | ... |

### 6.2 å‹å•†ç»´åº¦
| å‹å•† | ç«äº‰æ€åŠ¿ | ä¸»è¦å¨èƒç‚¹ | åº”å¯¹ç­–ç•¥ |
|------|----------|------------|----------|
| æ­Œå°”è‚¡ä»½ | ... | ... | ... |
| å·¥ä¸šå¯Œè” | ... | ... | ... |

### 6.3 ä¾›åº”å•†ç»´åº¦
| ä¾›åº”å•†ç±»å‹ | å…³é”®ä¾›åº”å•† | åˆä½œç¨³å®šæ€§ | é£é™©ç‚¹ |
|------------|------------|------------|--------|
| è¿æ¥å™¨ä¾›åº”å•† | ... | ... | ... |
| åŸææ–™ä¾›åº”å•† | ... | ... | ... |

### 6.4 ç‰©æ–™å“ç±»ç»´åº¦
| ç‰©æ–™å“ç±» | å¸‚åœºåœ°ä½ | ç«äº‰åŠ›è¯„åˆ† | å¢é•¿æ½œåŠ› |
|----------|----------|------------|----------|
| è¿æ¥å™¨ | ... | â­â­â­â­â­ | ... |
| çº¿æ | ... | ... | ... |
| ç”µæºæ¨¡ç»„ | ... | ... | ... |

---

# æ ¼å¼è¦æ±‚
1. å¿…é¡»ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«è¡¨æ ¼ã€åˆ—è¡¨ã€åŠ ç²—ã€emoji
2. è¡¨æ ¼æ•°æ®è¦å®Œæ•´ï¼Œ**ä¸è¦ç”¨çœç•¥å·ä»£æ›¿å®é™…åˆ†æ**
3. **å¿…é¡»ä¿ç•™æ‰€æœ‰æ–°é—»çš„åŸæ–‡é“¾æ¥**ï¼Œä½¿ç”¨ [title](url) æ ¼å¼
4. SWOTåˆ†ææ¯ä¸ªè¦ç‚¹å¿…é¡»è¯´æ˜ç†ç”±
5. JSONä»£ç å—ç”¨äºå‰ç«¯å›¾è¡¨æ¸²æŸ“ï¼Œæ ¼å¼å¿…é¡»æ­£ç¡®
6. **ä¸éœ€è¦æŠ•èµ„è¯„çº§**
7. æŠ¥å‘Šé•¿åº¦ï¼š2500-4500å­—"""

    # å®šä¹‰ API è°ƒç”¨å‡½æ•°
    def call_ai_api(api_base, api_key, model, timeout=180):
        headers = {"Content-Type": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        
        response = req.post(
            f"{api_base.rstrip('/')}/chat/completions",
            headers=headers,
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯é¡¶çº§æŠ•è¡ŒTMTè¡Œä¸šé¦–å¸­åˆ†æå¸ˆï¼Œæ“…é•¿æ¶ˆè´¹ç”µå­äº§ä¸šé“¾ç«äº‰æ ¼å±€åˆ†æã€‚åˆ†ææ—¶ä¾§é‡ä»¥ä¸‹ç»´åº¦ï¼š1)å®¢æˆ·åŠ¨æ€ï¼ˆè‹¹æœã€åä¸ºç­‰å…³é”®å®¢æˆ·ï¼‰2)å‹å•†ç«äº‰ï¼ˆå¸‚å€¼ã€ä¾›åº”é“¾ã€å¨èƒç­‰çº§ï¼‰3)ç‰©æ–™å“ç±»ï¼ˆè¿æ¥å™¨ã€çº¿æã€ç”µæºï¼‰4)ä¾›åº”é“¾é£é™©ï¼ˆå…³ç¨å½±å“ï¼‰ã€‚ä½ çš„æŠ¥å‘Šå¿…é¡»åŒ…å«ï¼šæ•°æ®è¡¨æ ¼ã€ç«äº‰åŠ›é›·è¾¾å›¾ã€é£é™©çŸ©é˜µã€SWOTåˆ†æï¼ˆæ¯ç‚¹éœ€è¯´æ˜ç†ç”±ï¼‰ã€å››ç»´åº¦ç»“è®ºã€‚ä¸éœ€è¦æŠ•èµ„è¯„çº§ã€‚ä½¿ç”¨ä¸“ä¸šçš„Markdownæ ¼å¼ï¼Œä¿ç•™æ‰€æœ‰æ–°é—»é“¾æ¥ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "": 8000
            },
            timeout=timeout
        )
        return response
    
    used_model = ""
    used_api = ""
    
    try:
        # ä¼˜å…ˆå°è¯•å†…ç½‘ API
        print(f"ğŸ”„ å°è¯•å†…ç½‘ API: {internal_api_base}")
        response = call_ai_api(internal_api_base, internal_api_key, internal_model, timeout=60)
        
        if response.status_code == 200:
            used_model = internal_model
            used_api = "å†…ç½‘"
            print(f"âœ… å†…ç½‘ API è°ƒç”¨æˆåŠŸ")
        else:
            raise Exception(f"å†…ç½‘ API è¿”å› {response.status_code}")
            
    except Exception as e:
        print(f"âš ï¸ å†…ç½‘ API ä¸å¯ç”¨: {e}")
        print(f"ğŸ”„ åˆ‡æ¢åˆ°å¤–ç½‘ API: {external_api_base}")
        
        if not external_api_key:
            raise HTTPException(
                status_code=400, 
                detail="å†…ç½‘ API ä¸å¯ç”¨ï¼Œä¸”æœªé…ç½®å¤–ç½‘ API Key"
            )
        
        try:
            response = call_ai_api(external_api_base, external_api_key, external_model, timeout=180)
            used_model = external_model
            used_api = "å¤–ç½‘"
            print(f"âœ… å¤–ç½‘ API è°ƒç”¨æˆåŠŸ")
        except Exception as e2:
            raise HTTPException(status_code=500, detail=f"å†…å¤–ç½‘ API å‡ä¸å¯ç”¨: å†…ç½‘({e}), å¤–ç½‘({e2})")
    
    try:
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail=f"AI APIè°ƒç”¨å¤±è´¥: {response.text}")
        
        result = response.json()
        
        # æå–ç”Ÿæˆçš„å†…å®¹ (OpenAI æ ¼å¼)
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
        else:
            raise HTTPException(status_code=500, detail=f"æ— æ³•è§£æAIå“åº”: {result}")
        
        return {
            "status": "success",
            "company": request.company_name,
            "report": content,
            "model": used_model,
            "api_source": used_api,
            "timestamp": datetime.now().isoformat()
        }
        
    except req.exceptions.Timeout:
        raise HTTPException(status_code=504, detail="AI APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
    except req.exceptions.RequestException as e:
        raise HTTPException(status_code=500, detail=f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")


# æ—§çš„ web/ é™æ€é¡µé¢å·²ç§»é™¤ï¼Œè¯·ä½¿ç”¨ React å‰ç«¯ (web-crawler/web_ui)


# ==================== ç¼“å­˜ç®¡ç† API ====================

@app.get("/api/cache/status")
async def get_cache_status():
    """è·å– Redis ç¼“å­˜çŠ¶æ€"""
    if not cache.client:
        return {"status": "disconnected", "message": "Redis æœªè¿æ¥"}
    
    try:
        keys = cache.client.keys(f"{REDIS_PREFIX}*")
        cache_info = []
        for key in keys:
            short_key = key.replace(REDIS_PREFIX, "")
            ttl = cache.client.ttl(key)
            cache_info.append({
                "key": short_key,
                "ttl": ttl,
                "ttl_human": f"{ttl // 60}åˆ†{ttl % 60}ç§’" if ttl > 0 else "å·²è¿‡æœŸ"
            })
        
        return {
            "status": "connected",
            "redis": f"{REDIS_HOST}:{REDIS_PORT}",
            "total_keys": len(keys),
            "default_ttl": CACHE_TTL,
            "keys": cache_info
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.post("/api/cache/clear")
async def clear_cache():
    """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
    cache.clear_all()
    return {"status": "success", "message": "ç¼“å­˜å·²æ¸…é™¤"}


@app.delete("/api/cache/{key}")
async def delete_cache_key(key: str):
    """åˆ é™¤æŒ‡å®šç¼“å­˜"""
    cache.delete(key)
    return {"status": "success", "message": f"å·²åˆ é™¤ç¼“å­˜: {key}"}


# ==================== å¯åŠ¨æœåŠ¡ ====================

@app.on_event("startup")
async def startup():
    """æœåŠ¡å¯åŠ¨"""
    print("ğŸš€ TrendRadar API å¯åŠ¨ä¸­...")
    print(f"ğŸ“¦ Redis: {REDIS_HOST}:{REDIS_PORT}")
    print(f"â° ç¼“å­˜ TTL: {CACHE_TTL}ç§’ ({CACHE_TTL // 60}åˆ†é’Ÿ)")
    print("ğŸ’¡ æç¤º: æ•°æ®ä¸ä¼šè‡ªåŠ¨åŠ è½½ï¼Œç”¨æˆ·éœ€ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æ•°æ®")
    print("âœ… æœåŠ¡å°±ç»ªï¼")


if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ TrendRadar API æœåŠ¡...")
    print("ğŸ“ API: http://localhost:8000")
    print("ğŸŒ Web UI: http://localhost:8000/ui")
    print("ğŸ“š API æ–‡æ¡£: http://localhost:8000/docs")
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=True)
