# coding=utf-8
"""
LangGraph èŠå¤©å¼•æ“

å®ç°å¸¦è®°å¿†å‹ç¼©çš„æ™ºèƒ½å¯¹è¯ç³»ç»Ÿã€‚
æ¶æ„ï¼šæ»‘åŠ¨çª—å£ + æ‘˜è¦å‹ç¼©ç­–ç•¥
"""

import os
import json
import logging
from typing import Literal, Optional, List, Dict, Any, Annotated
from datetime import datetime
from pathlib import Path

import yaml
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import (
    SystemMessage,
    HumanMessage,
    AIMessage,
    RemoveMessage,
    BaseMessage
)
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver

from typing_extensions import TypedDict

from .tools import DataInsightTools, get_tools_instance
from .mongo_checkpointer import get_mongo_checkpointer
from .hybrid_query import get_hybrid_router, HybridQueryRouter

logger = logging.getLogger(__name__)


# ==================== é…ç½®åŠ è½½ ====================

def _load_google_api_key() -> str:
    """ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶åŠ è½½ Google API Key"""
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–
    api_key = os.getenv("GOOGLE_API_KEY")
    if api_key:
        return api_key

    # ä»é…ç½®æ–‡ä»¶è¯»å–
    config_path = Path(__file__).parent.parent / "config" / "database.yaml"
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f) or {}
        google_config = config.get('google_ai', {})
        api_key = google_config.get('api_key', '')
        if api_key:
            return api_key

    logger.warning("GOOGLE_API_KEY æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ config/database.yaml ä¸­é…ç½®")
    return ""


# ==================== State å®šä¹‰ ====================

class AgentState(TypedDict):
    """Agent çŠ¶æ€ç»“æ„"""
    # messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œä½¿ç”¨ add_messages è‡ªåŠ¨å¤„ç†è¿½åŠ 
    messages: Annotated[list, add_messages]
    # summary: å†å²å¯¹è¯æ‘˜è¦
    summary: str
    # session_id: ä¼šè¯ID
    session_id: str


# ==================== ç³»ç»Ÿæç¤ºè¯ ====================

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ´å¯ŸåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åˆ†ææ–°é—»çƒ­æœæ•°æ®å’Œå¤§å®—å•†å“è¡Œæƒ…ã€‚

ä½ çš„èƒ½åŠ›ï¼š

ã€æ–°é—»çƒ­æœã€‘
1. è·å–æœ€æ–°çƒ­æœæ–°é—»ï¼ˆæ¥è‡ªçŸ¥ä¹ã€å¾®åšã€ç™¾åº¦ã€æŠ–éŸ³ã€Bç«™ã€å¤´æ¡ç­‰å¹³å°ï¼‰
2. æœç´¢å†å²æ–°é—»æ•°æ®
3. åˆ†æè¯é¢˜çƒ­åº¦è¶‹åŠ¿
4. å¯¹æ¯”ä¸åŒæ—¶æœŸçš„çƒ­ç‚¹å˜åŒ–

ã€å¤§å®—å•†å“ã€‘
5. æŸ¥è¯¢å®æ—¶å•†å“ä»·æ ¼ï¼ˆé»„é‡‘ã€ç™½é“¶ã€åŸæ²¹ã€é“œã€é“ç­‰ï¼‰
6. æŸ¥çœ‹å•†å“å†å²ä»·æ ¼èµ°åŠ¿
7. æŒ‰åˆ†ç±»æŸ¥è¯¢ï¼šè´µé‡‘å±ã€èƒ½æºã€å·¥ä¸šé‡‘å±ã€å†œäº§å“

å›ç­”é£æ ¼ï¼š
- ç®€æ´æ˜äº†ï¼Œçªå‡ºå…³é”®ä¿¡æ¯
- ä½¿ç”¨æ•°æ®æ”¯æ’‘è§‚ç‚¹
- ä¸»åŠ¨æä¾›æ´å¯Ÿå’Œå»ºè®®
- å•†å“ä»·æ ¼å›ç­”æ—¶æ³¨æ˜å•ä½å’Œæ¶¨è·Œå¹…

é‡è¦è§„åˆ™ - å½“æ–°é—»æ•°æ®ä¸ºç©ºæ—¶ï¼š
- è°ƒç”¨ trigger_crawl å·¥å…·å¯åŠ¨çˆ¬è™«
- å‘Šè¯‰ç”¨æˆ·ï¼šã€ŒğŸ“­ æ•°æ®åº“æš‚æ— æ•°æ®ï¼Œå·²ä¸ºæ‚¨å¯åŠ¨çˆ¬è™«ï¼è¯·ç­‰å¾… 30-60 ç§’åå†æ¬¡æé—®ã€‚ã€

é‡è¦è§„åˆ™ - å½“å•†å“æ•°æ®ä¸ºç©ºæ—¶ï¼š
- å‘Šè¯‰ç”¨æˆ·ï¼šã€ŒğŸ“­ æš‚æ— è¯¥å•†å“æ•°æ®ï¼Œè¯·ç¡®è®¤å•†å“åç§°æˆ–ç¨åå†è¯•ã€‚ã€

å½“å‰æ—¶é—´ï¼š{current_time}

{summary_context}
"""


# ==================== æ ¸å¿ƒèŠ‚ç‚¹ ====================

class ChatEngine:
    """èŠå¤©å¼•æ“ä¸»ç±»"""

    def __init__(
        self,
        model_name: str = "gemini-3-flash-preview",
        max_messages_before_summary: int = 10,
        messages_to_keep: int = 4,
        project_root: str = None
    ):
        """
        åˆå§‹åŒ–èŠå¤©å¼•æ“

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œæ”¯æŒ:
                - gemini-2.5-pro-preview-06-05 (æœ€æ–°é¢„è§ˆç‰ˆ)
                - gemini-2.0-flash (å¿«é€Ÿç‰ˆ)
                - gemini-1.5-pro (ç¨³å®šç‰ˆ)
                - gemini-1.5-flash (è½»é‡ç‰ˆ)
            max_messages_before_summary: è§¦å‘æ‘˜è¦çš„æ¶ˆæ¯æ•°é˜ˆå€¼
            messages_to_keep: æ‘˜è¦åä¿ç•™çš„æœ€è¿‘æ¶ˆæ¯æ•°
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.model_name = model_name
        self.max_messages_before_summary = max_messages_before_summary
        self.messages_to_keep = messages_to_keep

        # åˆå§‹åŒ–æ¨¡å‹ (ä½¿ç”¨ Google AI Studio API)
        api_key = _load_google_api_key()
        if not api_key:
            raise ValueError("GOOGLE_API_KEY æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ config/database.yaml ä¸­é…ç½®")

        logger.info(f"åˆå§‹åŒ–æ¨¡å‹: {model_name}")

        self.model = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=0.7,
            max_output_tokens=8192,
            convert_system_message_to_human=True,  # Gemini ä¸åŸç”Ÿæ”¯æŒ system message
            timeout=120,  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        )

        # åˆå§‹åŒ–å·¥å…·
        self.tools_manager = get_tools_instance(project_root)
        self.tools = self.tools_manager.get_langchain_tools()

        # ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
        self.model_with_tools = self.model.bind_tools(self.tools)

        # æ„å»ºå›¾
        self.graph = self._build_graph()

        # å°è¯•ä½¿ç”¨ MongoDB å­˜å‚¨ï¼Œå¤±è´¥åˆ™å›é€€åˆ°å†…å­˜å­˜å‚¨
        try:
            self.checkpointer = get_mongo_checkpointer(required=False)
            if self.checkpointer:
                self.using_mongodb = True
                logger.info("ä½¿ç”¨ MongoDB å­˜å‚¨èŠå¤©å†å²")
            else:
                self.checkpointer = MemorySaver()
                self.using_mongodb = False
                logger.info("MongoDB ä¸å¯ç”¨ï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨èŠå¤©å†å²")
        except Exception as e:
            logger.warning(f"MongoDB è¿æ¥å¤±è´¥: {e}ï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨")
            self.checkpointer = MemorySaver()
            self.using_mongodb = False

        self.app = self.graph.compile(checkpointer=self.checkpointer)

    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph å·¥ä½œæµ"""
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("conversation", self._call_model)
        workflow.add_node("tools", ToolNode(self.tools))
        workflow.add_node("summarize", self._summarize_conversation)

        # å®šä¹‰è¾¹
        workflow.add_edge(START, "conversation")

        # å¯¹è¯èŠ‚ç‚¹ -> åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        workflow.add_conditional_edges(
            "conversation",
            self._route_after_conversation,
            {
                "tools": "tools",
                "summarize": "summarize",
                "end": END
            }
        )

        # å·¥å…·èŠ‚ç‚¹ -> å›åˆ°å¯¹è¯
        workflow.add_edge("tools", "conversation")

        # æ‘˜è¦èŠ‚ç‚¹ -> ç»“æŸ
        workflow.add_edge("summarize", END)

        return workflow

    def _call_model(self, state: AgentState) -> Dict:
        """å¯¹è¯èŠ‚ç‚¹ï¼šè°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤"""
        summary = state.get("summary", "")
        messages = state["messages"]

        # æ„å»ºç³»ç»Ÿæç¤º
        summary_context = f"ä¹‹å‰çš„å¯¹è¯æ‘˜è¦ï¼š{summary}" if summary else ""
        system_prompt = SYSTEM_PROMPT.format(
            current_time=datetime.now().strftime("%Y-%m-%d %H:%M"),
            summary_context=summary_context
        )

        # è¿‡æ»¤æ¶ˆæ¯ï¼Œç¡®ä¿ Gemini æ¶ˆæ¯é¡ºåºæ­£ç¡®
        # Gemini è¦æ±‚: tool_call åå¿…é¡»ç´§è·Ÿ tool_response
        filtered_messages = self._filter_messages_for_gemini(messages)

        # ç»„è£…æ¶ˆæ¯
        full_messages = [SystemMessage(content=system_prompt)] + filtered_messages

        # è°ƒç”¨æ¨¡å‹
        response = self.model_with_tools.invoke(full_messages)

        return {"messages": [response]}

    def _filter_messages_for_gemini(self, messages: list) -> list:
        """
        è¿‡æ»¤æ¶ˆæ¯ä»¥ç¬¦åˆ Gemini çš„æ¶ˆæ¯é¡ºåºè¦æ±‚

        Gemini è¦æ±‚:
        - function call å¿…é¡»ç´§è·Ÿåœ¨ user turn æˆ– function response ä¹‹å
        - ä¸èƒ½æœ‰å­¤ç«‹çš„ tool_call æ²¡æœ‰å¯¹åº”çš„ tool_response
        """
        from langchain_core.messages import ToolMessage

        filtered = []
        i = 0
        while i < len(messages):
            msg = messages[i]

            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¦å·¥å…·è°ƒç”¨çš„ AI æ¶ˆæ¯
            if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                # éœ€è¦ç¡®ä¿åé¢æœ‰å¯¹åº”çš„ ToolMessage
                tool_call_ids = {tc.get('id') or tc.get('tool_call_id') for tc in msg.tool_calls if isinstance(tc, dict)}

                # æ”¶é›†åç»­çš„ ToolMessage
                j = i + 1
                tool_responses = []
                while j < len(messages):
                    next_msg = messages[j]
                    if isinstance(next_msg, ToolMessage) or (hasattr(next_msg, 'type') and next_msg.type == 'tool'):
                        tool_responses.append(next_msg)
                        j += 1
                    else:
                        break

                # åªæœ‰å½“æœ‰å®Œæ•´çš„å·¥å…·è°ƒç”¨é“¾æ—¶æ‰ä¿ç•™
                if tool_responses:
                    filtered.append(msg)
                    filtered.extend(tool_responses)
                    i = j
                    continue
                else:
                    # è·³è¿‡æ²¡æœ‰å“åº”çš„å·¥å…·è°ƒç”¨
                    i += 1
                    continue

            # è·³è¿‡å­¤ç«‹çš„ ToolMessage
            if isinstance(msg, ToolMessage) or (hasattr(msg, 'type') and msg.type == 'tool'):
                i += 1
                continue

            # ä¿ç•™æ™®é€šçš„ Human/AI æ¶ˆæ¯
            if isinstance(msg, (HumanMessage, AIMessage)):
                # å¯¹äº AIMessageï¼Œåªä¿ç•™æœ‰å†…å®¹çš„
                if isinstance(msg, AIMessage):
                    if msg.content:
                        filtered.append(msg)
                else:
                    filtered.append(msg)

            i += 1

        return filtered

    def _route_after_conversation(self, state: AgentState) -> str:
        """è·¯ç”±ï¼šåˆ¤æ–­ä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        messages = state["messages"]

        if not messages:
            return "end"

        last_message = messages[-1]

        # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æœ‰å·¥å…·è°ƒç”¨ï¼Œè½¬åˆ°å·¥å…·èŠ‚ç‚¹
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools"

        # å¦‚æœæ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼ï¼Œè§¦å‘æ‘˜è¦
        if len(messages) > self.max_messages_before_summary:
            return "summarize"

        return "end"

    def _summarize_conversation(self, state: AgentState) -> Dict:
        """æ‘˜è¦èŠ‚ç‚¹ï¼šå‹ç¼©å¯¹è¯å†å²"""
        summary = state.get("summary", "")
        messages = state["messages"]

        # æ„å»ºæ‘˜è¦æç¤º
        if summary:
            summary_prompt = f"""å½“å‰æ‘˜è¦ï¼š{summary}

è¯·åŸºäºä¸Šè¿°æ‘˜è¦å’Œä¸‹é¢çš„æ–°å¯¹è¯ï¼Œç”Ÿæˆä¸€ä¸ªæ›´æ–°åçš„ç®€æ´æ‘˜è¦ã€‚
æ‘˜è¦åº”è¯¥ä¿ç•™å…³é”®ä¿¡æ¯ç‚¹ï¼ŒåŒ…æ‹¬ï¼š
- ç”¨æˆ·æŸ¥è¯¢è¿‡çš„è¯é¢˜
- é‡è¦çš„æ•°æ®å‘ç°
- ç”¨æˆ·çš„åå¥½æˆ–å…³æ³¨ç‚¹

æ–°å¯¹è¯ï¼š
"""
        else:
            summary_prompt = """è¯·å°†ä¸‹é¢çš„å¯¹è¯æ€»ç»“æˆä¸€æ®µç®€æ´çš„æ‘˜è¦ã€‚
æ‘˜è¦åº”è¯¥ä¿ç•™å…³é”®ä¿¡æ¯ç‚¹ï¼ŒåŒ…æ‹¬ï¼š
- ç”¨æˆ·æŸ¥è¯¢è¿‡çš„è¯é¢˜
- é‡è¦çš„æ•°æ®å‘ç°
- ç”¨æˆ·çš„åå¥½æˆ–å…³æ³¨ç‚¹

å¯¹è¯ï¼š
"""

        # æå–å¯¹è¯æ–‡æœ¬
        conversation_text = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                conversation_text.append(f"ç”¨æˆ·: {msg.content}")
            elif isinstance(msg, AIMessage):
                # åªä¿ç•™æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡å·¥å…·è°ƒç”¨
                if msg.content:
                    conversation_text.append(f"åŠ©æ‰‹: {msg.content[:500]}...")  # æˆªæ–­é•¿å›å¤

        full_prompt = summary_prompt + "\n".join(conversation_text)

        # è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ‘˜è¦ï¼ˆä½¿ç”¨ HumanMessage æ ¼å¼é¿å… Gemini API æ¶ˆæ¯é¡ºåºé”™è¯¯ï¼‰
        response = self.model.invoke([HumanMessage(content=full_prompt)])
        new_summary = response.content

        # åˆ é™¤æ—§æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘å‡ æ¡
        delete_messages = [
            RemoveMessage(id=m.id)
            for m in messages[:-self.messages_to_keep]
            if hasattr(m, 'id') and m.id
        ]

        logger.info(f"å¯¹è¯æ‘˜è¦å®Œæˆï¼Œåˆ é™¤ {len(delete_messages)} æ¡æ—§æ¶ˆæ¯")

        return {
            "summary": new_summary,
            "messages": delete_messages
        }

    async def chat(
        self,
        message: str,
        session_id: str = "default"
    ) -> str:
        """
        å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID

        Returns:
            AI å›å¤å†…å®¹
        """
        # ä½¿ç”¨åŒæ­¥æ–¹æ³•ï¼Œå› ä¸º MongoDB Checkpointer ä¸æ”¯æŒå¼‚æ­¥
        return self.chat_sync(message, session_id)

    def chat_sync(
        self,
        message: str,
        session_id: str = "default"
    ) -> str:
        """
        åŒæ­¥ç‰ˆæœ¬çš„èŠå¤©æ–¹æ³•

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID

        Returns:
            AI å›å¤å†…å®¹
        """
        config = {"configurable": {"thread_id": session_id}}

        # è°ƒç”¨å›¾
        result = self.app.invoke(
            {
                "messages": [HumanMessage(content=message)],
                "session_id": session_id
            },
            config=config
        )

        # æå–æœ€åçš„ AI å›å¤
        messages = result.get("messages", [])
        for msg in reversed(messages):
            if isinstance(msg, AIMessage) and msg.content:
                content = msg.content
                # å¤„ç† Gemini 3 è¿”å›çš„åˆ—è¡¨æ ¼å¼
                if isinstance(content, list):
                    for item in content:
                        if isinstance(item, dict) and item.get('type') == 'text':
                            return item.get('text', '')
                    return str(content)
                return content

        return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚"

    def chat_hybrid(
        self,
        message: str,
        session_id: str = "default"
    ) -> Dict:
        """
        ä½¿ç”¨æ··åˆæŸ¥è¯¢æ¶æ„å¤„ç†æ¶ˆæ¯

        ä¼˜åŠ¿:
        - å•†å“æŸ¥è¯¢: Text-to-SQLï¼Œè·³è¿‡å·¥å…·é€‰æ‹©ï¼Œé€Ÿåº¦å¿«ä¸”å‡†ç¡®
        - æ–°é—»æŸ¥è¯¢: RAG è¯­ä¹‰æ£€ç´¢ + LLM æ‘˜è¦

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID

        Returns:
            {
                "query_type": "commodity" | "news" | "mixed" | "general",
                "success": bool,
                "answer": str,
                "data": any,
                "execution_time_ms": float
            }
        """
        try:
            router = get_hybrid_router()
            result = router.route_and_query(message)

            logger.info(f"æ··åˆæŸ¥è¯¢ [{result['query_type']}]: {result.get('total_time_ms', 0):.0f}ms")

            # ä¿å­˜åˆ°ä¼šè¯å†å²
            self._save_hybrid_to_history(message, result, session_id)

            return result
        except Exception as e:
            logger.error(f"æ··åˆæŸ¥è¯¢å¤±è´¥: {e}")
            return {
                "query_type": "error",
                "success": False,
                "answer": f"æŸ¥è¯¢å¤±è´¥: {e}",
                "data": None,
                "execution_time_ms": 0
            }

    def _save_hybrid_to_history(
        self,
        user_message: str,
        result: Dict,
        session_id: str
    ) -> None:
        """
        å°†æ··åˆæŸ¥è¯¢ç»“æœä¿å­˜åˆ°ä¼šè¯å†å²

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            result: æŸ¥è¯¢ç»“æœ
            session_id: ä¼šè¯ID
        """
        try:
            config = {"configurable": {"thread_id": session_id}}

            # è·å–å½“å‰çŠ¶æ€
            current_state = self.app.get_state(config)
            current_messages = []
            current_summary = ""

            if current_state and current_state.values:
                current_messages = list(current_state.values.get("messages", []))
                current_summary = current_state.values.get("summary", "")

            # è¿‡æ»¤æ‰å¸¦æœ‰å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯ï¼ˆé¿å… Gemini æ¶ˆæ¯é¡ºåºé”™è¯¯ï¼‰
            # Gemini è¦æ±‚: tool_call åå¿…é¡»ç´§è·Ÿ tool_response
            filtered_messages = []
            for msg in current_messages:
                # è·³è¿‡å¸¦å·¥å…·è°ƒç”¨çš„ AI æ¶ˆæ¯
                if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                    continue
                # è·³è¿‡å·¥å…·å“åº”æ¶ˆæ¯
                if hasattr(msg, 'type') and msg.type == 'tool':
                    continue
                # åªä¿ç•™çº¯æ–‡æœ¬çš„ Human/AI æ¶ˆæ¯
                if isinstance(msg, (HumanMessage, AIMessage)) and msg.content:
                    filtered_messages.append(msg)

            # åˆ›å»ºæ–°æ¶ˆæ¯
            import uuid
            human_msg = HumanMessage(
                content=user_message,
                id=str(uuid.uuid4())
            )
            ai_msg = AIMessage(
                content=result.get("answer", ""),
                id=str(uuid.uuid4())
            )

            # è¿½åŠ æ¶ˆæ¯
            new_messages = filtered_messages + [human_msg, ai_msg]

            # æ›´æ–°çŠ¶æ€
            self.app.update_state(
                config,
                {
                    "messages": new_messages,
                    "summary": current_summary,
                    "session_id": session_id
                }
            )

            logger.debug(f"æ··åˆæŸ¥è¯¢å†å²å·²ä¿å­˜ [session={session_id}]")

        except Exception as e:
            logger.warning(f"ä¿å­˜æ··åˆæŸ¥è¯¢å†å²å¤±è´¥: {e}")

    def get_history(self, session_id: str = "default") -> List[Dict]:
        """
        è·å–ä¼šè¯å†å²

        Args:
            session_id: ä¼šè¯ID

        Returns:
            æ¶ˆæ¯å†å²åˆ—è¡¨
        """
        config = {"configurable": {"thread_id": session_id}}

        try:
            state = self.app.get_state(config)
            if state and state.values:
                messages = state.values.get("messages", [])
                history = []
                for msg in messages:
                    if isinstance(msg, HumanMessage):
                        history.append({
                            "role": "user",
                            "content": msg.content,
                            "timestamp": datetime.now().isoformat()
                        })
                    elif isinstance(msg, AIMessage) and msg.content:
                        history.append({
                            "role": "assistant",
                            "content": msg.content,
                            "timestamp": datetime.now().isoformat()
                        })
                return history
        except Exception as e:
            logger.error(f"è·å–å†å²å¤±è´¥: {e}")

        return []

    def clear_history(self, session_id: str = "default") -> bool:
        """
        æ¸…é™¤ä¼šè¯å†å²

        Args:
            session_id: ä¼šè¯ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            if self.using_mongodb and hasattr(self.checkpointer, 'delete_thread'):
                # ä½¿ç”¨ MongoDB ç›´æ¥åˆ é™¤ä¼šè¯
                self.checkpointer.delete_thread(session_id)
                logger.info(f"å·²æ¸…é™¤ä¼šè¯ {session_id} çš„ MongoDB å†å²")
            else:
                # å†…å­˜å­˜å‚¨ï¼šé‡æ–°åˆ›å»º checkpointer
                self.checkpointer = MemorySaver()
                self.app = self.graph.compile(checkpointer=self.checkpointer)
                logger.info("å·²é‡ç½®å†…å­˜å­˜å‚¨")
            return True
        except Exception as e:
            logger.error(f"æ¸…é™¤å†å²å¤±è´¥: {e}")
            return False


# ==================== å…¨å±€å®ä¾‹ç®¡ç† ====================

_engine_instance: Optional[ChatEngine] = None


def get_chat_engine(
    project_root: str = None,
    force_new: bool = False
) -> ChatEngine:
    """
    è·å–èŠå¤©å¼•æ“å•ä¾‹

    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•
        force_new: æ˜¯å¦å¼ºåˆ¶åˆ›å»ºæ–°å®ä¾‹

    Returns:
        ChatEngine å®ä¾‹
    """
    global _engine_instance

    if _engine_instance is None or force_new:
        _engine_instance = ChatEngine(
            project_root=project_root
        )

    return _engine_instance


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    import asyncio

    async def test():
        engine = get_chat_engine()

        # æµ‹è¯•å¯¹è¯
        response = await engine.chat("æœ€è¿‘æœ‰ä»€ä¹ˆçƒ­é—¨æ–°é—»ï¼Ÿ")
        print(f"AI: {response}")

        response = await engine.chat("åˆ†æä¸€ä¸‹AIè¯é¢˜çš„è¶‹åŠ¿")
        print(f"AI: {response}")

    asyncio.run(test())
