"""
å¤§å®—å•†å“æ•°æ®çˆ¬è™«
æ•´åˆ pacong çš„ Business Insider æ•°æ®æº
"""
import requests
import re
from typing import List, Dict, Any
from bs4 import BeautifulSoup

# å•†å“ä¸­è‹±æ–‡å¯¹ç…§
COMMODITY_TRANSLATIONS = {
    # è´µé‡‘å±
    'Gold': 'é»„é‡‘', 'Silver': 'ç™½é“¶', 'Platinum': 'é“‚é‡‘', 'Palladium': 'é’¯é‡‘',
    # èƒ½æº
    'Oil (Brent)': 'å¸ƒä¼¦ç‰¹åŸæ²¹', 'Oil (WTI)': 'WTIåŸæ²¹', 'Crude Oil': 'åŸæ²¹',
    'Natural Gas': 'å¤©ç„¶æ°”', 'Heating Oil': 'å–æš–æ²¹', 'RBOB Gasoline': 'RBOBæ±½æ²¹',
    # å·¥ä¸šé‡‘å±
    'Copper': 'é“œ', 'Aluminium': 'é“', 'Zinc': 'é”Œ',
    'Nickel': 'é•', 'Lead': 'é“…', 'Tin': 'é”¡',
    # å†œäº§å“
    'Corn': 'ç‰ç±³', 'Wheat': 'å°éº¦', 'Soybeans': 'å¤§è±†', 'Cotton': 'æ£‰èŠ±',
    'Sugar': 'ç³–', 'Coffee': 'å’–å•¡', 'Cocoa': 'å¯å¯', 'Rice': 'å¤§ç±³',
}

# å•†å“å•ä½
COMMODITY_UNITS = {
    'é»„é‡‘': 'USD/ç›å¸', 'ç™½é“¶': 'USD/ç›å¸', 'é“‚é‡‘': 'USD/ç›å¸', 'é’¯é‡‘': 'USD/ç›å¸',
    'å¸ƒä¼¦ç‰¹åŸæ²¹': 'USD/æ¡¶', 'WTIåŸæ²¹': 'USD/æ¡¶', 'åŸæ²¹': 'USD/æ¡¶',
    'å¤©ç„¶æ°”': 'USD/MMBtu', 'é“œ': 'USD/ç£…', 'é“': 'USD/å¨',
    'ç‰ç±³': 'USD/è’²å¼è€³', 'å°éº¦': 'USD/è’²å¼è€³', 'å¤§è±†': 'USD/è’²å¼è€³',
}


class CommodityScraper:
    """å¤§å®—å•†å“æ•°æ®çˆ¬è™«"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        }
    
    def scrape(self) -> List[Dict[str, Any]]:
        """çˆ¬å–å¤§å®—å•†å“æ•°æ®"""
        # ä½¿ç”¨å­—å…¸è¿›è¡Œå»é‡ï¼Œé”®ä¸º chinese_name
        # ä¼˜å…ˆçº§ï¼šæ–°æµªæœŸè´§ > SMM > Business Insider > ä¸­å¡‘åœ¨çº¿
        commodities_map = {}
        
        # 1. ä»æ–°æµªæœŸè´§è·å–æ•°æ®ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        sina_data = self._scrape_sina_commodities()
        for item in sina_data:
            commodities_map[item['chinese_name']] = item
        print(f"ğŸ“¦ [Sina] çˆ¬å–åˆ° {len(sina_data)} æ¡æ•°æ®: {sina_data}")
        
        # 2. ä»ä¸Šæµ·æœ‰è‰²ç½‘è·å–é‡‘å±ä»·æ ¼
        smm_data = self._scrape_smm_prices()
        for item in smm_data:
            if item['chinese_name'] not in commodities_map:
                commodities_map[item['chinese_name']] = item
        print(f"ğŸ“¦ [SMM] çˆ¬å–åˆ° {len(smm_data)} æ¡æ•°æ®: {smm_data}")
        
        # 3. ä» Business Insider è·å–è¡¥å……æ•°æ®
        bi_data = self._scrape_business_insider()
        for item in bi_data:
            if item['chinese_name'] not in commodities_map:
                commodities_map[item['chinese_name']] = item
        print(f"ğŸ“¦ [BI] çˆ¬å–åˆ° {len(bi_data)} æ¡æ•°æ®: {bi_data}")
        
        # 4. ä»ä¸­å¡‘åœ¨çº¿è·å– WTI åŸæ²¹æ•°æ®ï¼ˆå¢é‡ï¼‰
        wti_21cp = self._scrape_21cp_wti()
        for item in wti_21cp:
            if item['chinese_name'] not in commodities_map:
                commodities_map[item['chinese_name']] = item
        print(f"ğŸ“¦ [21CP-WTI] çˆ¬å–åˆ° {len(wti_21cp)} æ¡æ•°æ®: {wti_21cp}")
        
        # 5. ä»ä¸­å¡‘åœ¨çº¿è·å–å¡‘æ–™ä»·æ ¼æ•°æ®ï¼ˆå¢é‡ï¼‰
        plastics_21cp = self._scrape_21cp_plastics()
        for item in plastics_21cp:
            if item['chinese_name'] not in commodities_map:
                commodities_map[item['chinese_name']] = item
        print(f"ğŸ“¦ [21CP-Plastics] çˆ¬å–åˆ° {len(plastics_21cp)} æ¡æ•°æ®: {plastics_21cp}")

        return list(commodities_map.values())
    
    def _scrape_business_insider(self) -> List[Dict[str, Any]]:
        """çˆ¬å– Business Insider å¤§å®—å•†å“æ•°æ®"""
        url = 'https://markets.businessinsider.com/commodities'
        commodities = []
        
        try:
            resp = requests.get(url, headers=self.headers, timeout=15)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.content, 'html.parser')
            
            # æŸ¥æ‰¾å•†å“è¡¨æ ¼
            tables = soup.find_all('table')
            
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 3:
                        data = self._extract_from_row(cells)
                        if data:
                            commodities.append(data)
            
            print(f"âœ… Business Insider: è·å– {len(commodities)} æ¡æ•°æ®")
            
        except Exception as e:
            print(f"âŒ Business Insider çˆ¬å–å¤±è´¥: {e}")
        
        return commodities
    
    def _scrape_sina_commodities(self) -> List[Dict[str, Any]]:
        """ä»æ–°æµªè·å–å¤§å®—å•†å“æ•°æ®"""
        commodities = []
        
        # æ–°æµªæœŸè´§æ•°æ®æ¥å£
        urls = [
            ('https://hq.sinajs.cn/list=hf_GC', 'é»„é‡‘', 'COMEXé»„é‡‘'),
            ('https://hq.sinajs.cn/list=hf_SI', 'ç™½é“¶', 'COMEXç™½é“¶'),
            ('https://hq.sinajs.cn/list=hf_CL', 'åŸæ²¹', 'WTIåŸæ²¹'),
            ('https://hq.sinajs.cn/list=hf_NG', 'å¤©ç„¶æ°”', 'å¤©ç„¶æ°”'),
            ('https://hq.sinajs.cn/list=hf_HG', 'é“œ', 'COMEXé“œ'),
        ]
        
        for url, cn_name, full_name in urls:
            try:
                headers = {**self.headers, 'Referer': 'https://finance.sina.com.cn'}
                resp = requests.get(url, headers=headers, timeout=10)
                
                if resp.status_code == 200:
                    text = resp.text
                    # è§£ææ–°æµªæ•°æ®æ ¼å¼: var hq_str_hf_GC="å½“å‰ä»·,ç©º,å¼€ç›˜ä»·,æœ€é«˜ä»·,æ˜¨æ”¶ç›˜,æœ€ä½ä»·,æ—¶é—´,..."
                    match = re.search(r'"([^"]+)"', text)
                    if match:
                        parts = match.group(1).split(',')
                        if len(parts) >= 5 and parts[0]:
                            price = float(parts[0])
                            prev_close = float(parts[4]) if parts[4] else price
                            # è®¡ç®—æ¶¨è·Œå¹…
                            change_percent = ((price - prev_close) / prev_close * 100) if prev_close > 0 else 0
                            
                            commodities.append({
                                'name': full_name,
                                'chinese_name': full_name,
                                'price': price,
                                'current_price': price,
                                'change_percent': round(change_percent, 2),
                                'unit': COMMODITY_UNITS.get(cn_name, 'USD'),
                                'source': 'æ–°æµªæœŸè´§',
                                'category': self._categorize(cn_name),
                                'url': f'https://finance.sina.com.cn/futures/quotes/{url.split("=")[1]}.shtml'
                            })
            except Exception as e:
                print(f"æ–°æµª {cn_name} è·å–å¤±è´¥: {e}")
        
        print(f"âœ… æ–°æµªæœŸè´§: è·å– {len(commodities)} æ¡æ•°æ®")
        return commodities
    
    def _extract_from_row(self, cells) -> Dict[str, Any]:
        """
        ä»è¡¨æ ¼è¡Œæå–æ•°æ®
        Business Insider è¡¨æ ¼ç»“æ„: [Name, Price, %, +/-, Unit, Date]
        """
        try:
            cell_texts = [c.get_text(strip=True) for c in cells]
            
            if len(cell_texts) < 3:
                return None
            
            name = cell_texts[0]
            
            # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆè¡¨å¤´ã€ç©ºè¡Œï¼‰
            if not name or len(name) <= 2 or name.isdigit():
                return None
            if any(kw in name.lower() for kw in ['commodity', 'price', 'precious', 'energy', 'industrial', 'agriculture']):
                return None
            
            # æ™ºèƒ½æ£€æµ‹åˆ—
            price = None
            change_percent = 0
            unit_text = ''

            # éå†å¯»æ‰¾ä»·æ ¼å’Œæ¶¨è·Œå¹…
            # ä»·æ ¼é€šå¸¸æ˜¯æ•°å­—ï¼ˆå¯å¸¦é€—å·ï¼‰ï¼Œæ¶¨è·Œå¹…å¸¦æœ‰ %
            for i, text in enumerate(cell_texts[1:5], start=1):
                if not text:
                    continue
                    
                # å°è¯•åŒ¹é…ç™¾åˆ†æ¯” (æ¶¨è·Œå¹…)
                if '%' in text:
                    match = re.search(r'([+-]?\d+\.?\d*)%', text)
                    if match:
                        change_percent = float(match.group(1))
                    continue
                
                # å°è¯•åŒ¹é…ä»·æ ¼ (æ’é™¤æ—¥æœŸæ ¼å¼)
                # ä»·æ ¼ç‰¹å¾: åŒ…å«æ•°å­—, å¯èƒ½æœ‰é€—å·/ç‚¹, ä½†ä¸æ˜¯çº¯æ—¥æœŸ MM/DD
                if re.match(r'^\d{1,2}/\d{1,2}$', text):
                    continue
                    
                clean_price = text.replace(',', '')
                # åŒ¹é…å¼€å¤´çš„æ•°å­— (å…è®¸åé¢è·Ÿå•ä½ï¼Œå¦‚ '1787.50 USD')
                match = re.search(r'^(\d+\.?\d*)', clean_price)
                if match and price is None:
                    # åªæœ‰å½“è¿˜æ²¡æ‰¾åˆ°ä»·æ ¼æ—¶æ‰èµ‹å€¼ï¼Œé¿å…è¯¯åˆ¤å…¶ä»–æ•°å­—åˆ—
                    price = float(match.group(1))
                    
            # å°è¯•æå–å•ä½ (åˆ— 4 æˆ– åé¢)
            if len(cell_texts) > 4:
                unit_text = cell_texts[4]
            
            # åˆ— 4: å•ä½ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(cell_texts) > 4:
                unit_text = cell_texts[4]
            
            if price is None:
                return None
            
            chinese_name = COMMODITY_TRANSLATIONS.get(name, name)
            
            # æ ¹æ®å•ä½åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬æ¢ï¼ˆUSc = ç¾åˆ†ï¼‰
            display_unit = COMMODITY_UNITS.get(chinese_name, 'USD')
            if 'USc' in unit_text:
                # ç¾åˆ†å•ä½ï¼Œæ ‡æ³¨æ¸…æ¥š
                display_unit = unit_text.replace('USc', 'ç¾åˆ†').replace('per', '/').replace('lb.', 'ç£…').replace('Bushel', 'è’²å¼è€³')
            elif 'per Ton' in unit_text:
                display_unit = 'USD/å¨'
            elif 'per Barrel' in unit_text:
                display_unit = 'USD/æ¡¶'
            elif 'per Troy Ounce' in unit_text:
                display_unit = 'USD/ç›å¸'
            elif 'per Gallone' in unit_text:
                display_unit = 'USD/åŠ ä»‘'
            elif 'per MMBtu' in unit_text:
                display_unit = 'USD/MMBtu'
            elif 'GBP' in unit_text:
                display_unit = 'GBP/å¨'
            
            return {
                'name': name,
                'chinese_name': chinese_name,
                'price': price,
                'current_price': price,
                'change_percent': change_percent,
                'unit': display_unit,
                'source': 'Business Insider',
                'category': self._categorize(name),
                'url': f'https://markets.businessinsider.com/commodities/{name.lower().replace(" ", "-")}'
            }
        except Exception:
            return None
    
    def _scrape_smm_prices(self) -> List[Dict[str, Any]]:
        """ä»ä¸Šæµ·æœ‰è‰²ç½‘è·å–é‡‘å±ä»·æ ¼"""
        prices = []
        
        # SMM æœ‰è‰²é‡‘å±ä»·æ ¼é¡µé¢
        metals = [
            ('copper', 'é“œ', 'SMMé“œ'),
            ('aluminum', 'é“', 'SMMé“'),
            ('zinc', 'é”Œ', 'SMMé”Œ'),
            ('lead', 'é“…', 'SMMé“…'),
            ('nickel', 'é•', 'SMMé•'),
            ('tin', 'é”¡', 'SMMé”¡'),
        ]
        
        for metal_en, metal_cn, full_name in metals:
            try:
                url = f'https://hq.smm.cn/{metal_en}'
                resp = requests.get(url, headers=self.headers, timeout=10)
                
                if resp.status_code == 200:
                    soup = BeautifulSoup(resp.text, 'html.parser')
                    
                    # æŸ¥æ‰¾ä»·æ ¼è¡¨æ ¼
                    tables = soup.find_all('table')
                    for table in tables[:3]:
                        rows = table.find_all('tr')
                        for row in rows[1:5]:  # è·³è¿‡è¡¨å¤´
                            cells = row.find_all(['td', 'th'])
                            if len(cells) >= 2:
                                name_cell = cells[0].get_text(strip=True)
                                price_cell = cells[1].get_text(strip=True) if len(cells) > 1 else ''
                                
                                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
                                if 'æœªç™»å½•' in price_cell or not price_cell:
                                    continue
                                
                                # æå–ä»·æ ¼èŒƒå›´
                                price_match = re.search(r'(\d+[\d,]*)', price_cell.replace(',', ''))
                                if price_match:
                                    try:
                                        price = float(price_match.group(1))
                                        if price > 100:  # è¿‡æ»¤æ— æ•ˆä»·æ ¼
                                            prices.append({
                                                'name': name_cell or full_name,
                                                'chinese_name': name_cell or full_name,
                                                'price': price,
                                                'current_price': price,
                                                'change_percent': 0,
                                                'unit': 'å…ƒ/å¨',
                                                'source': 'ä¸Šæµ·æœ‰è‰²ç½‘',
                                                'category': 'å·¥ä¸šé‡‘å±',
                                                'url': url
                                            })
                                            break
                                    except ValueError:
                                        continue
                        if any(p.get('chinese_name', '').startswith(metal_cn) for p in prices):
                            break
                            
            except Exception as e:
                print(f"SMM {metal_cn}è·å–å¤±è´¥: {e}")
        
        print(f"âœ… ä¸Šæµ·æœ‰è‰²ç½‘: è·å– {len(prices)} æ¡ä»·æ ¼æ•°æ®")
        return prices
    
    def _scrape_21cp_wti(self) -> List[Dict[str, Any]]:
        """ä»ä¸­å¡‘åœ¨çº¿è·å– WTI åŸæ²¹å¢é‡æ•°æ®"""
        try:
            from .intercrude import InterCrudePriceScraper
            scraper = InterCrudePriceScraper()
            return scraper.fetch_incremental()
        except Exception as e:
            print(f"âŒ ä¸­å¡‘åœ¨çº¿ WTI è·å–å¤±è´¥: {e}")
            return []
    
    def _scrape_21cp_plastics(self) -> List[Dict[str, Any]]:
        """ä»ä¸­å¡‘åœ¨çº¿è·å–å¡‘æ–™ä»·æ ¼å¢é‡æ•°æ®"""
        try:
            from .plastic21cp import Plastic21CPScraper
            scraper = Plastic21CPScraper()
            # è·å–æ‰€æœ‰å¡‘æ–™äº§å“çš„ä»Šæ—¥æ•°æ®
            all_data = []
            for product in scraper.list_products():
                data = scraper.fetch_incremental(product)
                all_data.extend(data)
            return all_data
        except Exception as e:
            print(f"âŒ ä¸­å¡‘åœ¨çº¿å¡‘æ–™è·å–å¤±è´¥: {e}")
            return []
    
    def _categorize(self, name: str) -> str:
        """å•†å“åˆ†ç±»"""
        name_lower = name.lower()
        
        if any(k in name_lower for k in ['gold', 'silver', 'platinum', 'palladium', 'é»„é‡‘', 'ç™½é“¶', 'é“‚é‡‘', 'é’¯é‡‘']):
            return 'è´µé‡‘å±'
        if any(k in name_lower for k in ['oil', 'gas', 'brent', 'wti', 'åŸæ²¹', 'å¤©ç„¶æ°”']):
            return 'èƒ½æº'
        if any(k in name_lower for k in ['copper', 'aluminum', 'zinc', 'nickel', 'é“œ', 'é“', 'é”Œ', 'é•']):
            return 'å·¥ä¸šé‡‘å±'
        if any(k in name_lower for k in ['corn', 'wheat', 'soybean', 'cotton', 'sugar', 'ç‰ç±³', 'å°éº¦', 'å¤§è±†']):
            return 'å†œäº§å“'
        if any(k in name_lower for k in ['pp', 'polypropylene', 'pe', 'polyethylene', 'pvc', 'abs', 'hips', 'gpps', 'pet', 'pa', 'pc', 'pbt', 'pcta', 'å¡‘æ–™', 'èšä¸™çƒ¯', 'èšä¹™çƒ¯', 'èšæ°¯ä¹™çƒ¯']):
            return 'å¡‘æ–™'
        
        return 'å…¶ä»–'


# æµ‹è¯•
if __name__ == '__main__':
    scraper = CommodityScraper()
    data = scraper.scrape()
    for item in data[:10]:
        print(f"{item['chinese_name']}: {item['price']} {item.get('unit', '')} ({item.get('change_percent', 0):+.2f}%)")
