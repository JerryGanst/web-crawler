"""
æ•°æ®ç›¸å…³ API è·¯ç”±

ä¼˜åŒ–ç­–ç•¥ï¼šç¼“å­˜ä¼˜å…ˆ + åå°å¼‚æ­¥åˆ·æ–°
"""
from fastapi import APIRouter, HTTPException
from datetime import datetime
from typing import Optional
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

from ..cache import cache, CACHE_TTL
from database.manager import db_manager

router = APIRouter()

# åŸºç¡€ç›®å½•
BASE_DIR = Path(__file__).parent.parent.parent

# åå°ä»»åŠ¡
_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="data-bg")
_pending_refreshes = set()


def load_config():
    """åŠ è½½é…ç½®"""
    import yaml
    config_path = BASE_DIR / "config" / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


@router.get("/api/categories")
async def get_categories():
    """è·å–æ‰€æœ‰åˆ†ç±»"""
    config = load_config()
    categories = config.get("categories", {})
    
    result = []
    for key, value in categories.items():
        result.append({
            "id": key,
            "name": value.get("name", key),
            "keywords": value.get("keywords", [])
        })
    
    return {"categories": result}


@router.get("/api/platforms")
async def get_platforms():
    """è·å–æ‰€æœ‰å¹³å°"""
    config = load_config()
    platforms = config.get("platforms", [])
    
    # æŒ‰åˆ†ç±»åˆ†ç»„
    by_category = {}
    for p in platforms:
        cat = p.get("category", "other")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(p)
    
    return {
        "platforms": platforms,
        "by_category": by_category,
        "total": len(platforms)
    }


def _background_fetch_commodity_data(cache_key: str):
    """åå°çˆ¬å–å•†å“æ•°æ®"""
    try:
        print(f"ğŸ”„ [åå°] å¼€å§‹çˆ¬å–å•†å“æ•°æ®...")
        from scrapers.commodity import CommodityScraper
        scraper = CommodityScraper()
        data = scraper.scrape()
        
        category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
        data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))
        
        result = {
            "data": data,
            "source": "TrendRadar Commodity",
            "timestamp": datetime.now().isoformat(),
            "cached": False,
            "background_refresh": True,
            "categories": list(set(item.get('category', 'å…¶ä»–') for item in data))
        }
        cache.set(cache_key, result, ttl=CACHE_TTL)
        
        # å†™å…¥ MySQLï¼ˆå¦‚æœå·²å¯ç”¨ï¼‰ï¼ŒæŒ‰æ¥æºåˆ†ç»„ä»¥ä¿ç•™çœŸå®æ¥æº
        try:
            stats_by_source = {}
            sources = set(item.get("source", "unknown") for item in data)
            for src in sources:
                src_records = [item for item in data if item.get("source", "unknown") == src]
                if not src_records:
                    continue
                db_stats = db_manager.write_commodity(src_records, source=src)
                if db_stats:
                    stats_by_source[src] = db_stats
            if stats_by_source:
                print(f"âœ… [åå°] MySQL å…¥åº“å®Œæˆï¼ˆæŒ‰æ¥æºï¼‰: {stats_by_source}")
        except Exception as e:
            print(f"âš ï¸ MySQL å…¥åº“å¤±è´¥: {e}")
        
        # ä¿å­˜ä»·æ ¼å†å²
        try:
            from core.price_history import PriceHistoryManager
            history_manager = PriceHistoryManager()
            history_manager.save_current_prices(data)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ä»·æ ¼å†å²å¤±è´¥: {e}")
        
        print(f"âœ… [åå°] å•†å“æ•°æ®å®Œæˆ: {len(data)} æ¡")
    except Exception as e:
        print(f"âŒ [åå°] å•†å“æ•°æ®å¤±è´¥: {e}")
    finally:
        _pending_refreshes.discard(cache_key)


@router.get("/api/data")
async def get_data(refresh: bool = False):
    """
    è·å–å¤§å®—å•†å“å¸‚åœºæ•°æ®
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    - refresh=false: ç›´æ¥è¿”å›ç¼“å­˜ï¼ˆ<50msï¼‰
    - refresh=true: ç«‹å³è¿”å›ç¼“å­˜ + åå°å¼‚æ­¥åˆ·æ–°
    """
    cache_key = "data:commodity"
    cached = cache.get(cache_key)
    
    if refresh:
        # è§¦å‘åå°åˆ·æ–°
        triggered = False
        if cache_key not in _pending_refreshes:
            _pending_refreshes.add(cache_key)
            _executor.submit(_background_fetch_commodity_data, cache_key)
            triggered = True
            print(f"ğŸ”„ å•†å“æ•°æ®åå°åˆ·æ–°å·²è§¦å‘")
        
        # ç«‹å³è¿”å›ç°æœ‰ç¼“å­˜
        if cached:
            cached["cached"] = True
            cached["refreshing"] = triggered
            cached["message"] = "æ•°æ®æ­£åœ¨åå°åˆ·æ–°" if triggered else "åˆ·æ–°ä»»åŠ¡å·²åœ¨è¿›è¡Œä¸­"
            return cached
        
        return {
            "data": [],
            "source": "TrendRadar Commodity",
            "timestamp": None,
            "cached": False,
            "refreshing": triggered,
            "categories": [],
            "message": "æ•°æ®æ­£åœ¨åå°åŠ è½½"
        }
    
    if cached:
        cached["cached"] = True
        cached["cache_ttl"] = cache.get_ttl(cache_key)
        return cached
    
    return {
        "data": [],
        "source": "TrendRadar Commodity",
        "timestamp": None,
        "cached": False,
        "categories": [],
        "message": "æš‚æ— ç¼“å­˜æ•°æ®ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æœ€æ–°æ•°æ®"
    }


@router.get("/api/price-history")
async def get_price_history(commodity: Optional[str] = None, days: int = 7):
    """
    è·å–ä»·æ ¼å†å²æ•°æ®
    
    ä¼˜åŒ–ï¼šä½¿ç”¨ç¼“å­˜ï¼ˆä»·æ ¼å†å²ä¸å¸¸å˜ï¼‰
    """
    cache_key = f"price-history:{commodity or 'all'}:{days}"
    
    # æ£€æŸ¥ç¼“å­˜
    cached = cache.get(cache_key)
    if cached:
        cached["cached"] = True
        return cached
    
    try:
        from core.price_history import PriceHistoryManager
        history_manager = PriceHistoryManager()
        
        if commodity:
            history = history_manager.get_history(commodity, days)
            result = {
                "status": "success",
                "commodity": commodity,
                "days": days,
                "data": history,
                "cached": False
            }
        else:
            all_history = history_manager.get_all_commodities_history(days)
            result = {
                "status": "success",
                "days": days,
                "data": all_history,
                "commodities": list(all_history.keys()),
                "cached": False
            }
        
        # ç¼“å­˜ 5 åˆ†é’Ÿ
        cache.set(cache_key, result, ttl=300)
        return result
        
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "data": {},
            "cached": False
        }


@router.post("/api/price-history/init-plastics")
async def init_plastics_history(days: int = 30):
    """
    åˆå§‹åŒ–å¡‘æ–™å†å²æ•°æ®ï¼ˆä»ä¸­å¡‘åœ¨çº¿æ‹‰å–å†å²è®°å½•ï¼‰
    
    Args:
        days: æ‹‰å–æœ€è¿‘å¤šå°‘å¤©çš„å†å²æ•°æ®ï¼Œé»˜è®¤30å¤©
    """
    try:
        from scrapers.plastic21cp import Plastic21CPScraper
        from core.price_history import PriceHistoryManager
        from datetime import datetime, timedelta
        
        scraper = Plastic21CPScraper()
        history_manager = PriceHistoryManager()
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        
        total_saved = 0
        products_processed = []
        
        for product_key in scraper.list_products():
            try:
                # è·å–å†å²æ•°æ®
                records = scraper.fetch(product_key, start_date=start_date, end_date=end_date)
                
                # ä¿å­˜åˆ°å†å²è®°å½•
                for record in records:
                    name = record.get("chinese_name") or record.get("name")
                    price = record.get("price")
                    change = record.get("change_percent", 0)
                    source = record.get("source", "ä¸­å¡‘åœ¨çº¿")
                    date = record.get("price_date")
                    
                    if name and price and date:
                        history_manager.save_daily_price(name, price, change, source, date)
                        total_saved += 1
                
                products_processed.append({
                    "product": product_key,
                    "records": len(records)
                })
                
            except Exception as e:
                products_processed.append({
                    "product": product_key,
                    "error": str(e)
                })
        
        return {
            "status": "success",
            "message": f"å·²åˆå§‹åŒ– {total_saved} æ¡å¡‘æ–™å†å²æ•°æ®",
            "date_range": {"start": start_date, "end": end_date},
            "products": products_processed
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }


@router.get("/api/data/sources")
async def get_data_sources():
    """
    è·å–å•†å“æ•°æ®æ¥æºä¿¡æ¯ï¼ˆå›½å®¶ã€ç½‘ç«™çº§è”ï¼‰
    """
    # æ•°æ®æºå®šä¹‰
    sources = {
        "US": {
            "name": "ç¾å›½",
            "name_en": "United States",
            "flag": "ğŸ‡ºğŸ‡¸",
            "websites": [
                {
                    "id": "business_insider",
                    "name": "Business Insider",
                    "url": "https://markets.businessinsider.com",
                    "commodities": ["Gold", "Silver", "Platinum", "Palladium", "WTI Crude Oil", "Brent Crude", "Natural Gas", "Copper"]
                },
                {
                    "id": "comex",
                    "name": "COMEX",
                    "url": "https://www.cmegroup.com",
                    "commodities": ["COMEXé»„é‡‘", "COMEXç™½é“¶", "COMEXé“œ"]
                }
            ]
        },
        "CN": {
            "name": "ä¸­å›½",
            "name_en": "China",
            "flag": "ğŸ‡¨ğŸ‡³",
            "websites": [
                {
                    "id": "sina_futures",
                    "name": "æ–°æµªæœŸè´§",
                    "url": "https://finance.sina.com.cn/futures",
                    "commodities": ["æ²ªé‡‘", "æ²ªé“¶", "æ²ªé“œ", "æ²ªé“", "æ²ªé”Œ", "æ²ªé•", "èºçº¹é’¢", "é“çŸ¿çŸ³"]
                },
                {
                    "id": "smm",
                    "name": "ä¸Šæµ·æœ‰è‰²ç½‘",
                    "url": "https://www.smm.cn",
                    "commodities": ["SMMé“œ", "SMMé“", "SMMé”Œ", "SMMé•", "SMMé”¡", "SMMé“…"]
                },
                {
                    "id": "shfe",
                    "name": "ä¸Šæµ·æœŸè´§äº¤æ˜“æ‰€",
                    "url": "https://www.shfe.com.cn",
                    "commodities": ["æ²ªé‡‘", "æ²ªé“¶", "æ²ªé“œ", "æ²ªé“", "æ²ªé”Œ", "å¤©ç„¶æ©¡èƒ¶"]
                },
                {
                    "id": "21cp",
                    "name": "ä¸­å¡‘åœ¨çº¿",
                    "url": "https://quote.21cp.com",
                    "commodities": [
                        "ABS(åå—)", "ABS(åä¸œ)", "ABS(ååŒ—)",
                        "PP(åä¸œ)", "PP(åå—)", "PP(ååŒ—)",
                        "PE(åä¸œ)", "PE(åå—)", "PE(ååŒ—)",
                        "GPPS(åä¸œ)", "GPPS(åå—)", "GPPSä½ç«¯(åä¸œ)", "GPPSä½ç«¯(åå—)",
                        "HIPS(åä¸œ)", "HIPS(åå—)", "HIPSä½ç«¯(åä¸œ)", "HIPSä½ç«¯(åå—)",
                        "WTIåŸæ²¹"
                    ]
                }
            ]
        },
        "UK": {
            "name": "è‹±å›½",
            "name_en": "United Kingdom",
            "flag": "ğŸ‡¬ğŸ‡§",
            "websites": [
                {
                    "id": "lme",
                    "name": "ä¼¦æ•¦é‡‘å±äº¤æ˜“æ‰€",
                    "url": "https://www.lme.com",
                    "commodities": ["LMEé“œ", "LMEé“", "LMEé”Œ", "LMEé•", "LMEé”¡", "LMEé“…"]
                }
            ]
        },
        "JP": {
            "name": "æ—¥æœ¬",
            "name_en": "Japan",
            "flag": "ğŸ‡¯ğŸ‡µ",
            "websites": [
                {
                    "id": "tocom",
                    "name": "ä¸œäº¬å•†å“äº¤æ˜“æ‰€",
                    "url": "https://www.tocom.or.jp",
                    "commodities": ["ä¸œäº¬é»„é‡‘", "ä¸œäº¬ç™½é“¶", "ä¸œäº¬é“‚é‡‘"]
                }
            ]
        }
    }
    
    # æ„å»ºçº§è”ç»“æ„
    cascade = []
    for country_code, country_info in sources.items():
        country_data = {
            "code": country_code,
            "name": country_info["name"],
            "name_en": country_info["name_en"],
            "flag": country_info["flag"],
            "websites": country_info["websites"],
            "commodity_count": sum(len(w["commodities"]) for w in country_info["websites"])
        }
        cascade.append(country_data)
    
    return {
        "status": "success",
        "sources": sources,
        "cascade": cascade,
        "total_countries": len(sources),
        "total_websites": sum(len(c["websites"]) for c in sources.values())
    }


@router.get("/api/config")
async def get_config():
    """è·å–é…ç½®"""
    config = load_config()
    
    # éšè—æ•æ„Ÿä¿¡æ¯
    if "notification" in config and "webhooks" in config["notification"]:
        webhooks = config["notification"]["webhooks"]
        for key in webhooks:
            if webhooks[key] and len(str(webhooks[key])) > 10:
                webhooks[key] = webhooks[key][:10] + "***"
    
    return config


@router.get("/api/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return {
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "cache": cache.get_status(),
        "version": "2.0.0"
    }


@router.get("/api/exchange-rate")
async def get_exchange_rate():
    """è·å–å®æ—¶æ±‡ç‡ï¼ˆUSD/CNYï¼‰"""
    import requests
    
    # å°è¯•å¤šä¸ªæ±‡ç‡æº
    sources = [
        # ExchangeRate-API (å…è´¹)
        ("https://api.exchangerate-api.com/v4/latest/USD", lambda d: d.get("rates", {}).get("CNY")),
        # Open Exchange Rates (å¤‡ç”¨)
        ("https://open.er-api.com/v6/latest/USD", lambda d: d.get("rates", {}).get("CNY")),
    ]
    
    for url, extractor in sources:
        try:
            resp = requests.get(url, timeout=5)
            if resp.status_code == 200:
                data = resp.json()
                rate = extractor(data)
                if rate:
                    return {
                        "status": "success",
                        "base": "USD",
                        "target": "CNY",
                        "rate": round(float(rate), 4),
                        "timestamp": datetime.now().isoformat(),
                        "source": url.split("/")[2]
                    }
        except Exception:
            continue
    
    # é»˜è®¤å¤‡ç”¨æ±‡ç‡
    return {
        "status": "fallback",
        "base": "USD",
        "target": "CNY",
        "rate": 7.2,
        "timestamp": datetime.now().isoformat(),
        "source": "default"
    }
