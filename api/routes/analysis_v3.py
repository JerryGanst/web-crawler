"""
æ¨¡å—åŒ–åˆ†æ API V3 - åˆ†è€Œæ²»ä¹‹

è°ƒç”¨æµç¨‹ï¼š
1. ç¬¬ä¸€è½®ï¼šå¹¶è¡Œè°ƒç”¨ 4 ä¸ªæ¨¡å—ï¼ˆå®¢æˆ·/å‹å•†/åŸææ–™/æ”¿ç­–ï¼‰
2. ç¬¬äºŒè½®ï¼šæ•´åˆæ€»ç»“

ä¼˜åŠ¿ï¼š
- æ¯ä¸ª prompt æ›´çŸ­æ›´ä¸“æ³¨
- AI æ³¨æ„åŠ›é›†ä¸­ï¼Œè¾“å‡ºè´¨é‡é«˜
- å¯å¹¶è¡Œè°ƒç”¨ï¼Œé€Ÿåº¦å¿«
"""
import asyncio
import aiohttp
from datetime import datetime
from typing import Dict
from pathlib import Path
from fastapi import APIRouter, HTTPException
import yaml
import os

from ..cache import cache
from ..models import AnalysisRequest

# å¯¼å…¥æ¨¡å—åŒ– prompts
from prompts.analysis_prompts_v3 import (
    get_all_module_prompts,
    get_summary_prompt,
    precheck_news_quality
)

router = APIRouter()

BASE_DIR = Path(__file__).parent.parent.parent


def get_ai_config():
    """è·å– AI é…ç½®"""
    config_path = BASE_DIR / "config" / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    ai_config = config.get("ai", {})
    external = ai_config.get("external", {})
    
    return {
        "api_key": external.get("api_key", "") or os.environ.get("AI_API_KEY", ""),
        "api_base": external.get("api_base", "https://api.siliconflow.cn/v1"),
        "model": external.get("model", "Pro/google/gemini-2.0-flash-001")
    }


async def call_ai_async(
    session: aiohttp.ClientSession,
    api_base: str,
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    max_tokens: int = 1500,
    timeout: int = 60
) -> str:
    """å¼‚æ­¥è°ƒç”¨ AI API"""
    is_google_api = "generativelanguage.googleapis.com" in api_base
    
    # Google å®˜æ–¹ generateContent æ¥å£
    if is_google_api:
        headers = {"Content-Type": "application/json"}
        if api_key:
            # Google API æ”¯æŒ query paramï¼Œä¹Ÿæ¥å— header
            headers["x-goog-api-key"] = api_key
        
        payload = {
            "system_instruction": {"parts": [{"text": system_prompt}]},
            "contents": [{"role": "user", "parts": [{"text": user_prompt}]}],
            "generation_config": {
                "temperature": 0.7,
                "max_output_tokens": max_tokens
            }
        }
        url = f"{api_base.rstrip('/')}/models/{model}:generateContent"
        if api_key and "key=" not in url:
            url = f"{url}?key={api_key}"
    else:
        # OpenAI/SiliconFlow å…¼å®¹çš„ chat/completions
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7,
            "max_tokens": max_tokens
        }
        url = f"{api_base.rstrip('/')}/chat/completions"
    
    try:
        async with session.post(
            url,
            headers=headers,
            json=payload,
            timeout=aiohttp.ClientTimeout(total=timeout)
        ) as response:
            if response.status != 200:
                text = await response.text()
                raise Exception(f"API è¿”å› {response.status}: {text[:200]}")
            
            result = await response.json()
            if is_google_api:
                # Google generateContent å“åº”
                candidates = result.get("candidates", [])
                for cand in candidates:
                    parts = cand.get("content", {}).get("parts", [])
                    texts = [p.get("text", "") for p in parts if isinstance(p, dict)]
                    merged = "".join(texts).strip()
                    if merged:
                        return merged
                raise Exception("æ— æ³•è§£æ AI å“åº” (google)")
            else:
                # OpenAI å…¼å®¹å“åº”
                if "choices" in result and len(result["choices"]) > 0:
                    return result["choices"][0]["message"]["content"]
                else:
                    raise Exception("æ— æ³•è§£æ AI å“åº”")
                
    except asyncio.TimeoutError:
        raise Exception("API è°ƒç”¨è¶…æ—¶")


async def run_first_round(
    news_summary: str,
    commodity_summary: str,
    today: str,
    ai_config: dict
) -> Dict[str, str]:
    """
    ç¬¬ä¸€è½®ï¼šå¹¶è¡Œè°ƒç”¨ 4 ä¸ªåˆ†ææ¨¡å—
    """
    prompts = get_all_module_prompts(news_summary, commodity_summary, today)
    
    results = {}
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        module_names = []
        
        for name, prompt_data in prompts.items():
            module_names.append(name)
            task = call_ai_async(
                session=session,
                api_base=ai_config["api_base"],
                api_key=ai_config["api_key"],
                model=ai_config["model"],
                system_prompt=prompt_data["system"],
                user_prompt=prompt_data["user"],
                max_tokens=prompt_data["max_tokens"],
                timeout=60
            )
            tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œ
        print(f"ğŸš€ [V3] å¹¶è¡Œè°ƒç”¨ {len(tasks)} ä¸ªæ¨¡å—...")
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        for name, response in zip(module_names, responses):
            if isinstance(response, Exception):
                print(f"âš ï¸ æ¨¡å— {name} å¤±è´¥: {response}")
                results[name] = f"*{name} æ¨¡å—åˆ†æå¤±è´¥: {str(response)[:100]}*"
            else:
                print(f"âœ… æ¨¡å— {name} å®Œæˆ")
                results[name] = response
    
    return results


async def run_second_round(
    today: str,
    first_round_results: Dict[str, str],
    ai_config: dict
) -> str:
    """
    ç¬¬äºŒè½®ï¼šæ•´åˆæ€»ç»“
    """
    prompt_data = get_summary_prompt(
        today=today,
        customer_analysis=first_round_results.get("customer", "æ— æ•°æ®"),
        competitor_analysis=first_round_results.get("competitor", "æ— æ•°æ®"),
        material_analysis=first_round_results.get("material", "æ— æ•°æ®"),
        tariff_analysis=first_round_results.get("tariff", "æ— æ•°æ®")
    )
    
    async with aiohttp.ClientSession() as session:
        print(f"ğŸ”„ [V3] ç¬¬äºŒè½®ï¼šæ•´åˆæ€»ç»“...")
        result = await call_ai_async(
            session=session,
            api_base=ai_config["api_base"],
            api_key=ai_config["api_key"],
            model=ai_config["model"],
            system_prompt=prompt_data["system"],
            user_prompt=prompt_data["user"],
            max_tokens=prompt_data["max_tokens"],
            timeout=90
        )
        print(f"âœ… æ•´åˆå®Œæˆ")
        return result


def assemble_final_report(
    first_round: Dict[str, str],
    second_round: str,
    today: str
) -> str:
    """
    ç»„è£…æœ€ç»ˆæŠ¥å‘Š
    """
    report = f"""# ç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†ææŠ¥å‘Š
**åˆ†ææ—¥æœŸ**ï¼š{today}

---

{second_round}

---

# è¯¦ç»†åˆ†æ

{first_round.get("customer", "")}

---

{first_round.get("competitor", "")}

---

{first_round.get("material", "")}

---

{first_round.get("tariff", "")}

---

*æŠ¥å‘Šç”± TrendRadar V3 æ¨¡å—åŒ–åˆ†æç³»ç»Ÿç”Ÿæˆ*
"""
    return report


def fetch_realtime_news(keywords: list, max_news: int = 30) -> list:
    """è·å–å®æ—¶æ–°é—»ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰"""
    import requests as req
    
    all_news = []
    
    # åŒèŠ±é¡ºå¿«è®¯
    try:
        url = "https://news.10jqka.com.cn/tapp/news/push/stock/?page=1&tag=&track=website&pagesize=50"
        resp = req.get(url, timeout=10, headers={
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })
        if resp.status_code == 200:
            data = resp.json()
            if data.get("data", {}).get("list"):
                for item in data["data"]["list"][:30]:
                    title = item.get("title", "")
                    if any(kw in title for kw in keywords):
                        all_news.append({
                            "title": title,
                            "url": item.get("url", ""),
                            "source": "åŒèŠ±é¡º",
                            "time": item.get("ctime", "")
                        })
    except Exception as e:
        print(f"âš ï¸ åŒèŠ±é¡ºè·å–å¤±è´¥: {e}")
    
    # ä¸œæ–¹è´¢å¯Œå¿«è®¯
    try:
        url = "https://np-listapi.eastmoney.com/comm/wap/getListInfo?cb=callback&client=wap&type=0&mession=&page=1&pagesize=50"
        resp = req.get(url, timeout=10)
        if resp.status_code == 200:
            text = resp.text
            if text.startswith("callback("):
                text = text[9:-1]
            import json
            data = json.loads(text)
            if data.get("data", {}).get("list"):
                for item in data["data"]["list"][:30]:
                    title = item.get("title", "")
                    if any(kw in title for kw in keywords):
                        all_news.append({
                            "title": title,
                            "url": item.get("url", ""),
                            "source": "ä¸œæ–¹è´¢å¯Œ",
                            "time": item.get("showtime", "")
                        })
    except Exception as e:
        print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œè·å–å¤±è´¥: {e}")
    
    return all_news[:max_news]


@router.post("/api/generate-analysis-v3")
async def generate_analysis_modular(request: AnalysisRequest):
    """
    æ¨¡å—åŒ–åˆ†ææŠ¥å‘Šç”Ÿæˆï¼ˆV3ï¼‰
    
    ä¼˜åŠ¿ï¼š
    - ç¬¬ä¸€è½® 4 ä¸ªæ¨¡å—å¹¶è¡Œè°ƒç”¨ï¼Œé€Ÿåº¦å¿«
    - æ¯ä¸ªæ¨¡å— prompt æ›´çŸ­æ›´ä¸“æ³¨ï¼Œè´¨é‡é«˜
    - ç¬¬äºŒè½®æ•´åˆï¼Œæœ‰å…¨å±€è§†è§’
    """
    ai_config = get_ai_config()
    if request.model:
        ai_config["model"] = request.model.strip()
    
    if not ai_config["api_key"]:
        raise HTTPException(status_code=400, detail="æœªé…ç½® AI API Key")
    
    # ==================== è·å–æ•°æ® ====================
    print(f"ğŸ“¡ [V3] å¼€å§‹æ¨¡å—åŒ–åˆ†æ...")
    
    # è·å–æ–°é—»
    supply_chain_keywords = [
        "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "æ—­åˆ›", "æ–°æ˜“ç››", "å…‰è¿…", "å¤©å­š",
        "è‹¹æœ", "Apple", "iPhone", "åä¸º", "Meta", "å°ç±³",
        "è¿æ¥å™¨", "ç”µæº", "å……ç”µå™¨", "å…‰æ¨¡å—", "çº¿æ",
        "å®‰è´¹è¯º", "è«ä»•", "TE", "ä¸­èˆªå…‰ç”µ", "å¥¥æµ·", "èˆªå˜‰", "å°è¾¾",
        "å…³ç¨", "è´¸æ˜“", "åˆ¶è£",
        "é“œ", "é•", "å¡‘æ–™", "ABS", "PA66"
    ]
    
    realtime_news = fetch_realtime_news(supply_chain_keywords)
    print(f"ğŸ“° å®æ—¶æ–°é—»: {len(realtime_news)} æ¡")
    
    # åˆå¹¶è¯·æ±‚ä¸­çš„æ–°é—»
    all_news = list(request.news) if request.news else []
    all_news.extend(realtime_news)
    
    # åˆå¹¶ç¼“å­˜æ–°é—»
    cached_supply = cache.get("news:supply-chain")
    if cached_supply:
        all_news.extend(cached_supply.get("data", []))
    
    # å»é‡
    seen = set()
    unique_news = []
    for n in all_news:
        title = n.get("title", "")
        if title and title not in seen:
            seen.add(title)
            unique_news.append(n)
    
    print(f"âœ… å»é‡åæ–°é—»: {len(unique_news)} æ¡")
    
    # æ–°é—»è´¨é‡é¢„æ£€
    news_quality = precheck_news_quality(unique_news)
    print(f"ğŸ“Š æ–°é—»è´¨é‡: {news_quality['quality_score']}/100")
    if news_quality['suggestions']:
        for s in news_quality['suggestions']:
            print(f"   ğŸ’¡ {s}")
    
    # æ„å»ºæ–°é—»æ‘˜è¦
    news_summary = "\n".join([
        f"- [{n.get('title', '')}]({n.get('url', '')}) ã€{n.get('source', '')}ã€‘"
        for n in unique_news[:50]
    ])
    
    # è·å–å¤§å®—å•†å“æ•°æ®
    commodity_summary = ""
    try:
        from scrapers.commodity import CommodityScraper
        scraper = CommodityScraper()
        commodity_data = scraper.scrape()
        
        if commodity_data:
            lines = []
            for c in commodity_data[:30]:
                name = c.get('chinese_name') or c.get('name', '')
                price = c.get('price', 0)
                change = c.get('change_percent', 0)
                unit = c.get('unit', '')
                lines.append(f"- {name}: {price} {unit} ({'+' if change >= 0 else ''}{change}%)")
            commodity_summary = "\n".join(lines)
            print(f"ğŸ“ˆ å¤§å®—å•†å“: {len(commodity_data)} æ¡")
    except Exception as e:
        print(f"âš ï¸ å¤§å®—å•†å“æ•°æ®è·å–å¤±è´¥: {e}")
        commodity_summary = "å¤§å®—å•†å“æ•°æ®æš‚æœªè·å–"
    
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    
    # ==================== æ¨¡å—åŒ–è°ƒç”¨ ====================
    try:
        # ç¬¬ä¸€è½®ï¼šå¹¶è¡Œåˆ†æ
        first_round = await run_first_round(
            news_summary=news_summary,
            commodity_summary=commodity_summary,
            today=today,
            ai_config=ai_config
        )
        
        # ç¬¬äºŒè½®ï¼šæ•´åˆæ€»ç»“
        second_round = await run_second_round(
            today=today,
            first_round_results=first_round,
            ai_config=ai_config
        )
        
        # ç»„è£…æœ€ç»ˆæŠ¥å‘Š
        final_report = assemble_final_report(first_round, second_round, today)
        
        return {
            "status": "success",
            "content": final_report,
            "model": ai_config["model"],
            "api_source": "å¤–ç½‘",
            "news_count": len(unique_news),
            "news_quality": {
                "score": news_quality["quality_score"],
                "suggestions": news_quality.get("suggestions", [])
            },
            "modules_completed": list(first_round.keys()),
            "version": "V3-modular",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")
