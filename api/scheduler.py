# coding=utf-8
"""
åå°å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨

åŠŸèƒ½ï¼š
1. æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨é¢„çƒ­ç¼“å­˜
2. å®šæœŸåˆ·æ–°å„åˆ†ç±»æ•°æ®
3. é¿å…ç”¨æˆ·ç­‰å¾…çˆ¬è™«

è°ƒåº¦ç­–ç•¥ï¼š
- å¯åŠ¨æ—¶ï¼šé¢„çƒ­æ‰€æœ‰åˆ†ç±»ç¼“å­˜
- æ¯ 30 åˆ†é’Ÿï¼šåˆ·æ–°è´¢ç»ã€ç§‘æŠ€ã€æ–°é—»
- æ¯ 15 åˆ†é’Ÿï¼šåˆ·æ–°å¤§å®—å•†å“æ•°æ®
- æ¯ 10 åˆ†é’Ÿï¼šåˆ·æ–°ä¾›åº”é“¾ã€å…³ç¨æ–°é—»
"""

import asyncio
import os
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Callable, Dict, List

from .cache import cache, CACHE_TTL


class BackgroundScheduler:
    """åå°ä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self):
        self._executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="scheduler")
        self._running = False
        self._tasks: Dict[str, dict] = {}
        self._test_env = "PYTEST_CURRENT_TEST" in os.environ
    
    def _crawl_category(self, category: str, include_custom: bool = True):
        """çˆ¬å–æŒ‡å®šåˆ†ç±»"""
        try:
            from scrapers.unified import UnifiedDataSource
            
            print(f"â° [å®šæ—¶] å¼€å§‹çˆ¬å– {category}...")
            unified = UnifiedDataSource()
            data = unified.crawl_category(category, include_custom=include_custom)
            
            result = {
                "status": "success",
                "category": category,
                "data": data,
                "timestamp": datetime.now().isoformat(),
                "total": len(data),
                "cached": False,
                "scheduled_refresh": True
            }
            cache.set(f"news:{category}", result, ttl=CACHE_TTL)
            print(f"â° [å®šæ—¶] {category} å®Œæˆ: {len(data)} æ¡")
        except Exception as e:
            print(f"â° [å®šæ—¶] {category} å¤±è´¥: {e}")
    
    def _crawl_commodity_data(self):
        """çˆ¬å–å¤§å®—å•†å“æ•°æ®"""
        try:
            from scrapers.commodity import CommodityScraper
            
            print(f"â° [å®šæ—¶] å¼€å§‹çˆ¬å–å¤§å®—å•†å“æ•°æ®...")
            scraper = CommodityScraper()
            data = scraper.scrape()
            
            category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
            data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))
            
            result = {
                "data": data,
                "source": "TrendRadar Commodity",
                "timestamp": datetime.now().isoformat(),
                "cached": False,
                "scheduled_refresh": True,
                "categories": list(set(item.get('category', 'å…¶ä»–') for item in data))
            }
            cache.set("data:commodity", result, ttl=CACHE_TTL)
            
            # ä¿å­˜ä»·æ ¼å†å²
            try:
                from core.price_history import PriceHistoryManager
                history_manager = PriceHistoryManager()
                history_manager.save_current_prices(data)
            except Exception as e:
                print(f"âš ï¸ [å®šæ—¶] ä¿å­˜ä»·æ ¼å†å²å¤±è´¥: {e}")
            
            print(f"â° [å®šæ—¶] å¤§å®—å•†å“æ•°æ®å®Œæˆ: {len(data)} æ¡")
        except Exception as e:
            print(f"â° [å®šæ—¶] å¤§å®—å•†å“æ•°æ®å¤±è´¥: {e}")
    
    def _fetch_realtime_news(self, cache_key: str, keywords: list, category: str = None):
        """æŠ“å–å®æ—¶æ–°é—»"""
        try:
            from api.routes.analysis import fetch_realtime_news
            
            print(f"â° [å®šæ—¶] å¼€å§‹æŠ“å– {cache_key}...")
            news = fetch_realtime_news(keywords)
            
            result = {
                "status": "success",
                "data": news,
                "timestamp": datetime.now().isoformat(),
                "total": len(news),
                "cached": False,
                "scheduled_refresh": True
            }
            if category:
                result["category"] = category
            cache.set(cache_key, result, ttl=CACHE_TTL)
            print(f"â° [å®šæ—¶] {cache_key} å®Œæˆ: {len(news)} æ¡")
        except Exception as e:
            print(f"â° [å®šæ—¶] {cache_key} å¤±è´¥: {e}")
    
    def warmup_cache(self):
        """é¢„çƒ­ç¼“å­˜ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
        if self._test_env:
            print("ğŸ”¥ è·³è¿‡æµ‹è¯•ç¯å¢ƒä¸‹çš„é¢„çƒ­ä»»åŠ¡")
            return
        print("ğŸ”¥ å¼€å§‹é¢„çƒ­ç¼“å­˜...")
        
        # ä» news.py å¯¼å…¥ç»Ÿä¸€çš„å…³é”®è¯é…ç½®
        from .routes.news import SUPPLY_CHAIN_KEYWORDS, TARIFF_KEYWORDS, PLASTICS_KEYWORDS
        supply_chain_keywords = SUPPLY_CHAIN_KEYWORDS
        tariff_keywords = TARIFF_KEYWORDS
        plastics_keywords = PLASTICS_KEYWORDS
        
        # é¢„çƒ­ä»»åŠ¡åˆ—è¡¨
        warmup_tasks = [
            ("å¤§å®—å•†å“æ•°æ®", self._crawl_commodity_data),
            ("è´¢ç»æ–°é—»", lambda: self._crawl_category("finance")),
            ("ç§‘æŠ€æ–°é—»", lambda: self._crawl_category("tech")),
            ("ä¾›åº”é“¾æ–°é—»", lambda: self._fetch_realtime_news("news:supply-chain", supply_chain_keywords)),
            ("å…³ç¨æ–°é—»", lambda: self._fetch_realtime_news("news:tariff", tariff_keywords, "tariff")),
            ("å¡‘æ–™æ–°é—»", lambda: self._fetch_realtime_news("news:plastics", plastics_keywords, "plastics")),
            ("å¤§å®—å•†å“æ–°é—»", lambda: self._crawl_category("commodity")),
        ]
        
        for name, task in warmup_tasks:
            try:
                self._executor.submit(task)
                print(f"  ğŸ“Œ å·²æäº¤: {name}")
            except Exception as e:
                print(f"  âŒ æäº¤å¤±è´¥ {name}: {e}")
        
        print("ğŸ”¥ é¢„çƒ­ä»»åŠ¡å·²å…¨éƒ¨æäº¤")
    
    def start_scheduled_tasks(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼ˆéé˜»å¡ï¼‰"""
        if self._running:
            return
        
        self._running = True
        if self._test_env:
            # æµ‹è¯•ç¯å¢ƒä¸å¯åŠ¨åå°å¾ªç¯ï¼Œé¿å…å¹²æ‰°å…¶å®ƒç”¨ä¾‹çš„ mock
            return
        
        def scheduler_loop():
            """è°ƒåº¦å¾ªç¯"""
            # ä» news.py å¯¼å…¥ç»Ÿä¸€çš„å…³é”®è¯é…ç½®
            from .routes.news import SUPPLY_CHAIN_KEYWORDS, TARIFF_KEYWORDS
            supply_chain_keywords = SUPPLY_CHAIN_KEYWORDS
            tariff_keywords = TARIFF_KEYWORDS
            
            # ä»»åŠ¡é…ç½®ï¼š(é—´éš”ç§’æ•°, ä¸Šæ¬¡æ‰§è¡Œæ—¶é—´, ä»»åŠ¡å‡½æ•°)
            tasks = {
                "commodity_data": {
                    "interval": 15 * 60,  # 15åˆ†é’Ÿ
                    "last_run": 0,
                    "func": self._crawl_commodity_data
                },
                "finance_news": {
                    "interval": 30 * 60,  # 30åˆ†é’Ÿ
                    "last_run": 0,
                    "func": lambda: self._crawl_category("finance")
                },
                "tech_news": {
                    "interval": 30 * 60,
                    "last_run": 0,
                    "func": lambda: self._crawl_category("tech")
                },
                "supply_chain": {
                    "interval": 10 * 60,  # 10åˆ†é’Ÿ
                    "last_run": 0,
                    "func": lambda: self._fetch_realtime_news("news:supply-chain", supply_chain_keywords)
                },
                "tariff": {
                    "interval": 10 * 60,
                    "last_run": 0,
                    "func": lambda: self._fetch_realtime_news("news:tariff", tariff_keywords, "tariff")
                }
            }
            
            import time
            while self._running:
                now = time.time()
                
                for name, config in tasks.items():
                    if now - config["last_run"] >= config["interval"]:
                        try:
                            self._executor.submit(config["func"])
                            config["last_run"] = now
                            print(f"â° [è°ƒåº¦] å·²è§¦å‘: {name}")
                        except Exception as e:
                            print(f"â° [è°ƒåº¦] è§¦å‘å¤±è´¥ {name}: {e}")
                
                # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                time.sleep(60)
        
        # åœ¨åå°çº¿ç¨‹è¿è¡Œè°ƒåº¦å¾ªç¯
        thread = threading.Thread(target=scheduler_loop, daemon=True, name="scheduler-main")
        thread.start()
        print("â° å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self._running = False
        self._executor.shutdown(wait=False)
        print("â° å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = BackgroundScheduler()
