"""
TrendRadar Web API æœåŠ¡
æä¾›æ–°é—»æ•°æ®ã€çˆ¬è™«é…ç½®å’Œè§¦å‘çˆ¬å–çš„ REST API
"""
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import yaml
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import time
import threading

# ==================== ç®€å•ç¼“å­˜ ====================
class SimpleCache:
    """ç®€å•çš„å†…å­˜ç¼“å­˜ï¼Œå¸¦è¿‡æœŸæ—¶é—´"""
    def __init__(self, ttl_seconds: int = 300):  # é»˜è®¤5åˆ†é’Ÿ
        self.cache = {}
        self.ttl = ttl_seconds
        self.lock = threading.Lock()
    
    def get(self, key: str):
        with self.lock:
            if key in self.cache:
                data, expire_time = self.cache[key]
                if time.time() < expire_time:
                    return data
                del self.cache[key]
        return None
    
    def set(self, key: str, value):
        with self.lock:
            self.cache[key] = (value, time.time() + self.ttl)
    
    def clear(self):
        with self.lock:
            self.cache.clear()

# å…¨å±€ç¼“å­˜å®ä¾‹
news_cache = SimpleCache(ttl_seconds=180)  # æ–°é—»ç¼“å­˜3åˆ†é’Ÿ
data_cache = SimpleCache(ttl_seconds=120)  # æ•°æ®ç¼“å­˜2åˆ†é’Ÿ

# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title="TrendRadar API",
    description="çƒ­ç‚¹æ–°é—»èšåˆä¸æ¨é€æœåŠ¡",
    version="1.0.0"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è·¯å¾„é…ç½®
BASE_DIR = Path(__file__).parent
CONFIG_PATH = BASE_DIR / "config" / "config.yaml"
SCRAPERS_CONFIG_PATH = BASE_DIR / "config" / "scrapers.yaml"
OUTPUT_DIR = BASE_DIR / "output"


def load_config() -> Dict:
    """åŠ è½½é…ç½®"""
    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


# ==================== æ•°æ®æ¨¡å‹ ====================

class CrawlRequest(BaseModel):
    category: str
    include_custom: bool = True

class PushRequest(BaseModel):
    category: str
    data: List[Dict]

class ReportPushRequest(BaseModel):
    title: str
    content: str

class AnalysisRequest(BaseModel):
    company_name: str = "ç«‹è®¯ç²¾å¯†"
    competitors: List[str] = []
    upstream: List[str] = []
    downstream: List[str] = []
    news: List[Dict] = []


# ==================== API è·¯ç”± ====================

@app.get("/")
async def root():
    """API æ ¹è·¯å¾„"""
    return {
        "name": "TrendRadar API",
        "version": "1.0.0",
        "endpoints": {
            "/api/categories": "è·å–æ‰€æœ‰åˆ†ç±»",
            "/api/platforms": "è·å–æ‰€æœ‰å¹³å°",
            "/api/news/{category}": "è·å–æŒ‡å®šåˆ†ç±»çš„æ–°é—»",
            "/api/crawl": "è§¦å‘çˆ¬å–",
            "/api/config": "è·å–/æ›´æ–°é…ç½®",
        }
    }


@app.get("/api/categories")
async def get_categories():
    """è·å–æ‰€æœ‰åˆ†ç±»"""
    config = load_config()
    categories = config.get("categories", {})
    
    result = []
    for key, value in categories.items():
        result.append({
            "id": key,
            "name": value.get("name", key),
            "keywords": value.get("keywords", [])
        })
    
    return {"categories": result}


@app.get("/api/platforms")
async def get_platforms():
    """è·å–æ‰€æœ‰å¹³å°"""
    config = load_config()
    platforms = config.get("platforms", [])
    
    # æŒ‰åˆ†ç±»åˆ†ç»„
    by_category = {}
    for p in platforms:
        cat = p.get("category", "other")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(p)
    
    return {
        "platforms": platforms,
        "by_category": by_category,
        "total": len(platforms)
    }


@app.get("/api/data")
async def get_data():
    """
    è·å–å¤§å®—å•†å“å¸‚åœºæ•°æ®ï¼ˆæ•°æ®çœ‹æ¿ä¸“ç”¨ï¼‰
    è¿”å›è´µé‡‘å±ã€èƒ½æºã€å·¥ä¸šé‡‘å±ã€å†œäº§å“ç­‰å¤§å®—å•†å“æ•°æ®
    """
    # æ£€æŸ¥ç¼“å­˜
    cached = data_cache.get("commodity_data")
    if cached:
        cached["cached"] = True
        return cached
    
    try:
        from scrapers.commodity import CommodityScraper
        
        scraper = CommodityScraper()
        data = scraper.scrape()
        
        # æŒ‰åˆ†ç±»æ’åºï¼šè´µé‡‘å± > èƒ½æº > å·¥ä¸šé‡‘å± > å†œäº§å“
        category_order = {'è´µé‡‘å±': 0, 'èƒ½æº': 1, 'å·¥ä¸šé‡‘å±': 2, 'å†œäº§å“': 3, 'å…¶ä»–': 4}
        data.sort(key=lambda x: category_order.get(x.get('category', 'å…¶ä»–'), 4))
        
        result = {
            "data": data,
            "source": "TrendRadar Commodity",
            "cached": False,
            "categories": list(set(item.get('category', 'å…¶ä»–') for item in data))
        }
        data_cache.set("commodity_data", result)
        return result
    except Exception as e:
        print(f"è·å–å¤§å®—å•†å“æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/commodity-news")
async def get_commodity_news():
    """
    è·å–å¤§å®—å•†å“ç›¸å…³æ–°é—»ï¼ˆå¸‚åœºå¿«è®¯ä¸“ç”¨ï¼‰
    ç­›é€‰è´¢ç»æ–°é—»ä¸­ä¸å¤§å®—å•†å“ç›¸å…³çš„å†…å®¹
    """
    # æ£€æŸ¥ç¼“å­˜
    cached = news_cache.get("commodity_news")
    if cached:
        cached["cached"] = True
        return cached
    
    try:
        from scrapers.unified import UnifiedDataSource
        ds = UnifiedDataSource()
        
        # è·å–è´¢ç»æ–°é—»
        data = ds.crawl_category("finance", include_custom=False)
        
        # å¤§å®—å•†å“å…³é”®è¯
        commodity_keywords = [
            'é»„é‡‘', 'ç™½é“¶', 'åŸæ²¹', 'çŸ³æ²¹', 'å¤©ç„¶æ°”', 'é“œ', 'é“', 'é”Œ',
            'ç‰ç±³', 'å°éº¦', 'å¤§è±†', 'æœŸè´§', 'å¤§å®—å•†å“', 'è´µé‡‘å±', 'æœ‰è‰²é‡‘å±',
            'gold', 'silver', 'oil', 'copper', 'commodit', 'futures',
            'å¸ƒä¼¦ç‰¹', 'WTI', 'COMEX', 'LME', 'çº½çº¦', 'ä¼¦æ•¦é‡‘å±'
        ]
        
        # ç­›é€‰ç›¸å…³æ–°é—»
        commodity_news = []
        for item in data:
            title = (item.get('title', '') or '').lower()
            if any(kw.lower() in title for kw in commodity_keywords):
                commodity_news.append(item)
        
        # å¦‚æœç­›é€‰ç»“æœå¤ªå°‘ï¼Œè¿”å›å‰10æ¡è´¢ç»æ–°é—»ä½œä¸ºè¡¥å……
        if len(commodity_news) < 5:
            commodity_news = data[:10]
        
        result = {
            "data": commodity_news[:15],
            "total": len(commodity_news),
            "cached": False,
            "timestamp": datetime.now().isoformat()
        }
        news_cache.set("commodity_news", result)
        return result
    except Exception as e:
        print(f"è·å–å¤§å®—å•†å“æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ä¾›åº”é“¾æ–°é—»ç¼“å­˜ï¼ˆéœ€è¦æ”¾åœ¨é€šé…ç¬¦è·¯ç”±ä¹‹å‰ï¼‰
_supply_chain_news_cache = {
    "data": [],
    "timestamp": None
}

@app.get("/api/news/supply-chain")
async def get_supply_chain_news():
    """è·å–ä¾›åº”é“¾ç›¸å…³æ–°é—»ï¼ˆå¸¦ç¼“å­˜ï¼Œ5åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡ï¼‰"""
    from datetime import datetime, timedelta
    
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆ5åˆ†é’Ÿå†…ï¼‰
    if _supply_chain_news_cache["timestamp"]:
        cache_age = datetime.now() - _supply_chain_news_cache["timestamp"]
        if cache_age < timedelta(minutes=5) and _supply_chain_news_cache["data"]:
            return {
                "status": "cache",
                "data": _supply_chain_news_cache["data"],
                "count": len(_supply_chain_news_cache["data"]),
                "cached_at": _supply_chain_news_cache["timestamp"].isoformat()
            }
    
    # æŠ“å–æ–°é—»
    keywords = [
        # æ ¸å¿ƒå…¬å¸
        "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹", "BOE",
        "æ¬£æ—ºè¾¾", "å¾·èµ›", "èˆœå®‡", "é¹é¼", "ä¸œå±±ç²¾å¯†", "é¢†ç›Š", "ç‘å£°",
        # å®¢æˆ·
        "è‹¹æœ", "Apple", "iPhone", "AirPods", "Vision Pro", "iPad", "Mac",
        "åä¸º", "Huawei", "é¸¿è’™", "Mate", "è£è€€",
        "å°ç±³", "OPPO", "vivo", "ä¸‰æ˜Ÿ", "Samsung",
        # è¡Œä¸šå…³é”®è¯
        "æ¶ˆè´¹ç”µå­", "æœé“¾", "ä»£å·¥", "ä¾›åº”é“¾", "èŠ¯ç‰‡", "åŠå¯¼ä½“",
        "æ™ºèƒ½æ‰‹æœº", "ç©¿æˆ´", "è€³æœº", "VR", "AR", "XR",
        "æ–°èƒ½æºæ±½è½¦", "ç”µåŠ¨æ±½è½¦", "åŠ¨åŠ›ç”µæ± ", "é”‚ç”µ",
        "AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "GPU", "è‹±ä¼Ÿè¾¾"
    ]
    
    news = fetch_realtime_news(keywords)
    
    # æ›´æ–°ç¼“å­˜
    _supply_chain_news_cache["data"] = news
    _supply_chain_news_cache["timestamp"] = datetime.now()
    
    return {
        "status": "success",
        "data": news,
        "count": len(news),
        "fetched_at": datetime.now().isoformat()
    }


@app.get("/api/news/{category}")
async def get_news(category: str, include_custom: bool = True, refresh: bool = False):
    """
    è·å–æŒ‡å®šåˆ†ç±»çš„æ–°é—»ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Args:
        category: åˆ†ç±»åç§° (finance, news, social, tech, all)
        include_custom: æ˜¯å¦åŒ…å«è‡ªå®šä¹‰çˆ¬è™«æ•°æ®
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    cache_key = f"news_{category}_{include_custom}"
    
    # æ£€æŸ¥ç¼“å­˜
    if not refresh:
        cached = news_cache.get(cache_key)
        if cached:
            cached["cached"] = True
            return cached
    
    try:
        from scrapers.unified import UnifiedDataSource
        ds = UnifiedDataSource()
        
        data = ds.crawl_category(category, include_custom=include_custom)
        
        # ç»Ÿè®¡
        sources = {}
        for item in data:
            src = item.get("platform_name", item.get("platform", "unknown"))
            sources[src] = sources.get(src, 0) + 1
        
        result = {
            "category": category,
            "total": len(data),
            "sources": sources,
            "data": data,
            "timestamp": datetime.now().isoformat(),
            "cached": False
        }
        news_cache.set(cache_key, result)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/crawl")
async def trigger_crawl(request: CrawlRequest, background_tasks: BackgroundTasks):
    """
    è§¦å‘çˆ¬å–ä»»åŠ¡
    
    Args:
        category: è¦çˆ¬å–çš„åˆ†ç±»
        include_custom: æ˜¯å¦åŒ…å«è‡ªå®šä¹‰çˆ¬è™«
    """
    try:
        # ä¾›åº”é“¾åˆ†ç±»ç‰¹æ®Šå¤„ç†ï¼ˆåŒæ—¶æ”¯æŒ supply-chain å’Œ supply_chainï¼‰
        if request.category in ["supply-chain", "supply_chain"]:
            keywords = [
                "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹", "BOE",
                "æ¬£æ—ºè¾¾", "å¾·èµ›", "èˆœå®‡", "é¹é¼", "ä¸œå±±ç²¾å¯†", "é¢†ç›Š", "ç‘å£°",
                "è‹¹æœ", "Apple", "iPhone", "AirPods", "Vision Pro", "iPad", "Mac",
                "åä¸º", "Huawei", "é¸¿è’™", "Mate", "è£è€€",
                "å°ç±³", "OPPO", "vivo", "ä¸‰æ˜Ÿ", "Samsung",
                "æ¶ˆè´¹ç”µå­", "æœé“¾", "ä»£å·¥", "ä¾›åº”é“¾", "èŠ¯ç‰‡", "åŠå¯¼ä½“",
                "AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "GPU", "è‹±ä¼Ÿè¾¾"
            ]
            data = fetch_realtime_news(keywords)
            
            # æ›´æ–°ç¼“å­˜
            _supply_chain_news_cache["data"] = data
            _supply_chain_news_cache["timestamp"] = datetime.now()
            
            return {
                "status": "success",
                "category": request.category,
                "total": len(data),
                "message": f"å·²çˆ¬å– {len(data)} æ¡ä¾›åº”é“¾ç›¸å…³æ–°é—»"
            }
        
        from scrapers.unified import UnifiedDataSource
        ds = UnifiedDataSource()
        
        # çˆ¬å–æ•°æ®
        data = ds.crawl_category(request.category, include_custom=request.include_custom)
        
        # è·å– webhook URL
        config = load_config()
        webhook_url = config.get("notification", {}).get("webhooks", {}).get("wework_url", "")
        
        # å¼‚æ­¥æ¨é€
        if webhook_url and data:
            background_tasks.add_task(ds.push_to_wework, data, request.category, webhook_url)
        
        return {
            "status": "success",
            "category": request.category,
            "total": len(data),
            "message": f"å·²çˆ¬å– {len(data)} æ¡æ•°æ®" + ("ï¼Œæ­£åœ¨æ¨é€..." if webhook_url else "")
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/config")
async def get_config():
    """è·å–é…ç½®"""
    config = load_config()
    
    # éšè—æ•æ„Ÿä¿¡æ¯
    if "notification" in config and "webhooks" in config["notification"]:
        webhooks = config["notification"]["webhooks"]
        for key in webhooks:
            if webhooks[key] and len(str(webhooks[key])) > 10:
                webhooks[key] = webhooks[key][:10] + "***"
    
    return config


# æŠ¥å‘Šå­˜å‚¨ç›®å½•
REPORTS_DIR = BASE_DIR / "reports"
REPORTS_DIR.mkdir(exist_ok=True)

@app.post("/api/push-report")
async def push_report(request: ReportPushRequest):
    """æ¨é€åˆ†ææŠ¥å‘Šåˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ¸²æŸ“ä¸ºå›¾ç‰‡ç›´æ¥å‘é€ï¼‰"""
    import requests
    import urllib3
    import hashlib
    import base64
    import markdown
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    config = load_config()
    webhook_urls = config.get("notification", {}).get("webhooks", {}).get("wework_url", "")
    
    # æ”¯æŒå•ä¸ªURLæˆ–URLåˆ—è¡¨
    if isinstance(webhook_urls, str):
        webhook_urls = [webhook_urls] if webhook_urls else []
    elif not webhook_urls:
        webhook_urls = []
    
    if not webhook_urls:
        return {"status": "error", "message": "æœªé…ç½®ä¼ä¸šå¾®ä¿¡ Webhookï¼Œè¯·åœ¨ config/config.yaml ä¸­è®¾ç½® wework_url"}
    
    try:
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_id = hashlib.md5(f"{request.title}{timestamp}".encode()).hexdigest()[:8]
        filename = f"report_{timestamp}_{report_id}.md"
        filepath = REPORTS_DIR / filename
        
        # å†™å…¥ Markdown æ–‡ä»¶
        full_report = f"""# {request.title}

> ğŸ“… ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
> ğŸ¤– æ¥æºï¼šç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†æåŠ©æ‰‹

---

{request.content}

---
*æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚*
"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(full_report)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {filepath}")
        
        # æ¸²æŸ“æŠ¥å‘Šä¸ºå›¾ç‰‡
        image_data = await render_report_to_image(request.title, request.content, timestamp)
        
        if image_data:
            # è®¡ç®—å›¾ç‰‡MD5
            image_md5 = hashlib.md5(image_data).hexdigest()
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # å‘é€å›¾ç‰‡åˆ°ä¼ä¸šå¾®ä¿¡
            payload = {
                "msgtype": "image",
                "image": {
                    "base64": image_base64,
                    "md5": image_md5
                }
            }
            
            success_count = 0
            errors = []
            for webhook_url in webhook_urls:
                try:
                    resp = requests.post(webhook_url, json=payload, timeout=60, verify=False)
                    if resp.status_code == 200 and resp.json().get("errcode") == 0:
                        success_count += 1
                        print(f"âœ… å›¾ç‰‡æ¨é€æˆåŠŸ: {webhook_url[:50]}...")
                    else:
                        errors.append(f"{webhook_url[:30]}: {resp.json().get('errmsg', 'HTTP ' + str(resp.status_code))}")
                except Exception as e:
                    errors.append(f"{webhook_url[:30]}: {str(e)[:50]}")
            
            if success_count > 0:
                print(f"âœ… æ¨é€å®Œæˆ: {success_count}/{len(webhook_urls)} ä¸ªç¾¤æˆåŠŸ")
                return {
                    "status": "success",
                    "message": f"æŠ¥å‘Šå›¾ç‰‡å·²æ¨é€åˆ° {success_count}/{len(webhook_urls)} ä¸ªç¾¤",
                    "filename": filename,
                    "errors": errors if errors else None
                }
            else:
                return {"status": "error", "message": f"æ‰€æœ‰æ¨é€å‡å¤±è´¥: {'; '.join(errors)}"}
        else:
            # å›¾ç‰‡æ¸²æŸ“å¤±è´¥ï¼Œé™çº§ä¸ºMarkdownæ‘˜è¦
            print("âš ï¸ å›¾ç‰‡æ¸²æŸ“å¤±è´¥ï¼Œé™çº§ä¸ºMarkdownæ‘˜è¦å‘é€")
            summary = request.content[:3500]
            if len(request.content) > 3500:
                last_newline = summary.rfind('\n')
                if last_newline > 2000:
                    summary = summary[:last_newline]
                summary += "\n\n... *(æŠ¥å‘Šè¾ƒé•¿ï¼Œå·²æˆªæ–­)*"
            
            message = f"""ğŸ“Š **{request.title}**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“… ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{summary}"""
            
            payload = {"msgtype": "markdown", "markdown": {"content": message}}
            
            success_count = 0
            errors = []
            for webhook_url in webhook_urls:
                try:
                    resp = requests.post(webhook_url, json=payload, timeout=30, verify=False)
                    if resp.status_code == 200 and resp.json().get("errcode") == 0:
                        success_count += 1
                except Exception as e:
                    errors.append(str(e)[:50])
            
            return {
                "status": "partial",
                "message": f"å›¾ç‰‡æ¸²æŸ“å¤±è´¥ï¼Œå·²å‘é€æ–‡å­—æ‘˜è¦åˆ° {success_count}/{len(webhook_urls)} ä¸ªç¾¤",
                "errors": errors if errors else None
            }
        
    except Exception as e:
        error_msg = str(e)
        if "SSL" in error_msg or "ssl" in error_msg:
            return {"status": "error", "message": "SSLè¿æ¥å¤±è´¥ï¼Œå¯èƒ½æ˜¯ä»£ç†/VPNå¯¼è‡´ã€‚è¯·å°è¯•å…³é—­ä»£ç†åé‡è¯•ã€‚"}
        return {"status": "error", "message": error_msg}


async def render_report_to_image(title: str, content: str, timestamp: str) -> bytes:
    """ä½¿ç”¨ Playwright å°†æŠ¥å‘Šæ¸²æŸ“ä¸ºå›¾ç‰‡ï¼ˆå‹ç¼©è‡³2MBä»¥å†…ï¼‰"""
    import markdown
    from io import BytesIO
    
    try:
        from playwright.async_api import async_playwright
        from PIL import Image
        
        # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œæˆªæ–­ï¼ˆé¿å…å›¾ç‰‡è¿‡å¤§ï¼‰
        max_content_length = 8000
        if len(content) > max_content_length:
            content = content[:max_content_length] + "\n\n... *(æŠ¥å‘Šè¾ƒé•¿ï¼Œå·²æˆªæ–­æ˜¾ç¤º)*"
        
        # è½¬æ¢ Markdown ä¸º HTML
        html_content = markdown.markdown(
            content,
            extensions=['tables', 'fenced_code', 'nl2br']
        )
        
        # ç”Ÿæˆå®Œæ•´çš„ HTML é¡µé¢
        full_html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            padding: 40px;
            min-width: 800px;
            max-width: 1000px;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            border-radius: 16px;
            margin-bottom: 30px;
            box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
        }}
        .header h1 {{
            font-size: 28px;
            margin-bottom: 10px;
            color: white;
        }}
        .header .meta {{
            font-size: 14px;
            opacity: 0.9;
            color: rgba(255,255,255,0.9);
        }}
        .content {{
            background: rgba(255,255,255,0.05);
            padding: 30px;
            border-radius: 16px;
            line-height: 1.8;
        }}
        h1, h2, h3, h4 {{
            color: #a5b4fc;
            margin: 20px 0 15px 0;
        }}
        h2 {{ font-size: 22px; border-bottom: 2px solid #4f46e5; padding-bottom: 10px; }}
        h3 {{ font-size: 18px; }}
        p {{ margin: 12px 0; }}
        ul, ol {{ margin: 12px 0; padding-left: 24px; }}
        li {{ margin: 6px 0; }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: rgba(0,0,0,0.2);
            border-radius: 8px;
            overflow: hidden;
        }}
        th {{
            background: rgba(79, 70, 229, 0.3);
            padding: 12px;
            text-align: left;
            font-weight: 600;
        }}
        td {{
            padding: 12px;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }}
        tr:last-child td {{ border-bottom: none; }}
        code {{
            background: rgba(0,0,0,0.3);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Fira Code', monospace;
        }}
        pre {{
            background: rgba(0,0,0,0.3);
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
        }}
        blockquote {{
            border-left: 4px solid #4f46e5;
            padding-left: 16px;
            margin: 16px 0;
            color: #a0a0b0;
        }}
        .footer {{
            margin-top: 30px;
            text-align: center;
            font-size: 12px;
            color: #6b7280;
        }}
        strong {{ color: #fbbf24; }}
        em {{ color: #a5b4fc; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“Š {title}</h1>
        <div class="meta">ğŸ“… ç”Ÿæˆæ—¶é—´ï¼š{timestamp} | ğŸ¤– ç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†æåŠ©æ‰‹</div>
    </div>
    <div class="content">
        {html_content}
    </div>
    <div class="footer">
        æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
    </div>
</body>
</html>"""
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page(viewport={'width': 800, 'height': 600})
            await page.set_content(full_html, wait_until='networkidle')
            
            # è·å–å†…å®¹é«˜åº¦å¹¶æˆªå›¾ï¼ˆé™åˆ¶æœ€å¤§é«˜åº¦ï¼‰
            height = await page.evaluate('document.body.scrollHeight')
            max_height = 4000  # é™åˆ¶æœ€å¤§é«˜åº¦
            await page.set_viewport_size({'width': 800, 'height': min(height + 50, max_height)})
            
            screenshot = await page.screenshot(full_page=True, type='jpeg', quality=85)
            await browser.close()
            
            # å¦‚æœå›¾ç‰‡ä»ç„¶å¤ªå¤§ï¼ˆ>1.8MBï¼‰ï¼Œè¿›ä¸€æ­¥å‹ç¼©
            if len(screenshot) > 1800000:
                img = Image.open(BytesIO(screenshot))
                # ç¼©å°å°ºå¯¸
                new_width = int(img.width * 0.7)
                new_height = int(img.height * 0.7)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                output = BytesIO()
                img.save(output, format='JPEG', quality=75, optimize=True)
                screenshot = output.getvalue()
            
            print(f"ğŸ“¸ æŠ¥å‘Šå›¾ç‰‡ç”ŸæˆæˆåŠŸ: {len(screenshot) / 1024:.1f} KB")
            return screenshot
            
    except Exception as e:
        print(f"âŒ å›¾ç‰‡æ¸²æŸ“å¤±è´¥: {e}")
        return None


@app.get("/api/reports/{filename}")
async def download_report(filename: str, format: str = "html"):
    """
    ä¸‹è½½æŠ¥å‘Šæ–‡ä»¶
    
    Args:
        filename: æŠ¥å‘Šæ–‡ä»¶å
        format: è¾“å‡ºæ ¼å¼ - html(é»˜è®¤ï¼Œæµè§ˆå™¨æ¸²æŸ“) æˆ– md(åŸå§‹Markdownä¸‹è½½)
    """
    from fastapi.responses import FileResponse, HTMLResponse
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†
    if ".." in filename or "/" in filename:
        raise HTTPException(status_code=400, detail="éæ³•æ–‡ä»¶å")
    
    filepath = REPORTS_DIR / filename
    if not filepath.exists():
        raise HTTPException(status_code=404, detail="æŠ¥å‘Šä¸å­˜åœ¨")
    
    # è¯»å– Markdown å†…å®¹
    with open(filepath, 'r', encoding='utf-8') as f:
        md_content = f.read()
    
    # å¦‚æœè¯·æ±‚åŸå§‹ Markdown ä¸‹è½½
    if format == "md":
        return FileResponse(
            path=str(filepath),
            filename=filename,
            media_type="text/markdown"
        )
    
    # é»˜è®¤è¿”å› HTML æ¸²æŸ“ç‰ˆæœ¬
    import markdown
    import re
    
    # é¢„å¤„ç† Markdownï¼šä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
    def preprocess_markdown(text):
        lines = text.split('\n')
        result = []
        in_table = False
        table_has_separator = False
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # æ£€æµ‹è¡¨æ ¼è¡Œï¼ˆä»¥ | å¼€å¤´å’Œç»“å°¾ï¼‰
            is_table_row = stripped.startswith('|') and stripped.endswith('|')
            is_separator = bool(re.match(r'^\|[\s\-:|]+\|$', stripped))
            
            if is_table_row:
                if not in_table:
                    in_table = True
                    table_has_separator = False
                
                # å¦‚æœæ˜¯åˆ†éš”ç¬¦è¡Œï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                if is_separator:
                    parts = stripped.split('|')
                    normalized = '|' + '|'.join([' --- ' if p.strip().replace('-', '').replace(':', '') == '' else p for p in parts[1:-1]]) + '|'
                    result.append(normalized)
                    table_has_separator = True
                else:
                    if in_table and not table_has_separator and len(result) > 0:
                        prev_line = result[-1].strip()
                        if prev_line.startswith('|') and prev_line.endswith('|'):
                            cols = prev_line.count('|') - 1
                            separator = '|' + ' --- |' * cols
                            result.append(separator)
                            table_has_separator = True
                    result.append(line)
            else:
                if in_table and stripped == '':
                    in_table = False
                    table_has_separator = False
                result.append(line)
        
        return '\n'.join(result)
    
    # é¢„å¤„ç†
    processed_content = preprocess_markdown(md_content)
    
    # è½¬æ¢ Markdown ä¸º HTML
    html_content = markdown.markdown(
        processed_content,
        extensions=['tables', 'fenced_code', 'codehilite', 'toc', 'nl2br']
    )
    
    # åå¤„ç†ï¼šä¸ºè¡¨æ ¼æ·»åŠ å®¹å™¨ä»¥æ”¯æŒæ¨ªå‘æ»šåŠ¨
    html_content = re.sub(
        r'<table>',
        '<div class="table-wrapper"><table>',
        html_content
    )
    html_content = re.sub(
        r'</table>',
        '</table></div>',
        html_content
    )
    
    # åå¤„ç†ï¼šæ£€æµ‹å¹¶è½¬æ¢JSONé›·è¾¾å›¾ä¸ºçœŸå®å›¾è¡¨
    import json
    radar_charts = []
    chart_id = 0
    
    def replace_radar_chart(match):
        nonlocal chart_id
        json_str = match.group(1)
        try:
            data = json.loads(json_str)
            if data.get('type') == 'radar' or 'dimensions' in data:
                chart_id += 1
                radar_charts.append({'id': f'radar-chart-{chart_id}', 'data': data})
                title = data.get('title', 'ç«äº‰åŠ›å¯¹æ¯”é›·è¾¾å›¾')
                return f'<div class="chart-container"><h4 class="chart-title">{title}</h4><canvas id="radar-chart-{chart_id}"></canvas></div>'
        except:
            pass
        return match.group(0)
    
    # åŒ¹é… JSON ä»£ç å—ï¼ˆåŒ…æ‹¬ json:radar-chart å’Œæ™®é€š jsonï¼‰
    html_content = re.sub(
        r'<code class="[^"]*">(\{[\s\S]*?"dimensions"[\s\S]*?\})</code>',
        replace_radar_chart,
        html_content
    )
    # ä¹ŸåŒ¹é… pre > code ç»“æ„
    html_content = re.sub(
        r'<pre><code[^>]*>(\{[\s\S]*?"dimensions"[\s\S]*?\})</code></pre>',
        replace_radar_chart,
        html_content
    )
    
    # ç”Ÿæˆé›·è¾¾å›¾åˆå§‹åŒ–JSä»£ç 
    radar_init_js = ""
    colors = [
        ('rgba(99, 102, 241, 0.8)', 'rgba(99, 102, 241, 0.2)'),   # ç´«è‰²
        ('rgba(34, 197, 94, 0.8)', 'rgba(34, 197, 94, 0.2)'),     # ç»¿è‰²
        ('rgba(245, 158, 11, 0.8)', 'rgba(245, 158, 11, 0.2)'),   # æ©™è‰²
        ('rgba(239, 68, 68, 0.8)', 'rgba(239, 68, 68, 0.2)'),     # çº¢è‰²
        ('rgba(59, 130, 246, 0.8)', 'rgba(59, 130, 246, 0.2)'),   # è“è‰²
        ('rgba(168, 85, 247, 0.8)', 'rgba(168, 85, 247, 0.2)'),   # ç´«çº¢
    ]
    
    for chart in radar_charts:
        chart_data = chart['data']
        dimensions = chart_data.get('dimensions', [])
        companies = chart_data.get('companies', {})
        
        datasets_js = []
        for i, (company, scores) in enumerate(companies.items()):
            color_border, color_bg = colors[i % len(colors)]
            datasets_js.append(f'''{{
                label: '{company}',
                data: {scores},
                borderColor: '{color_border}',
                backgroundColor: '{color_bg}',
                borderWidth: 2,
                pointBackgroundColor: '{color_border}',
                pointRadius: 4
            }}''')
        
        radar_init_js += f'''
        new Chart(document.getElementById('{chart['id']}'), {{
            type: 'radar',
            data: {{
                labels: {json.dumps(dimensions, ensure_ascii=False)},
                datasets: [{','.join(datasets_js)}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: true,
                scales: {{
                    r: {{
                        min: 0,
                        max: 10,
                        ticks: {{ stepSize: 2, color: '#6b6b7a', backdropColor: 'transparent' }},
                        grid: {{ color: 'rgba(255,255,255,0.1)' }},
                        angleLines: {{ color: 'rgba(255,255,255,0.1)' }},
                        pointLabels: {{ color: '#a0a0b0', font: {{ size: 12 }} }}
                    }}
                }},
                plugins: {{
                    legend: {{
                        position: 'bottom',
                        labels: {{ color: '#a0a0b0', padding: 20, font: {{ size: 12 }} }}
                    }}
                }}
            }}
        }});
        '''
    
    # ç”Ÿæˆå®Œæ•´ HTML é¡µé¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    html_page = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç«‹è®¯æŠ€æœ¯æ–°é—»ä¸“ä¸šåˆ†æåŠ©æ‰‹</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Noto+Sans+SC:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {{
            --bg-primary: #0a0a0f;
            --bg-secondary: #12121a;
            --bg-card: #1a1a24;
            --bg-hover: #22222e;
            --text-primary: #f0f0f5;
            --text-secondary: #a0a0b0;
            --text-muted: #6b6b7a;
            --accent: #6366f1;
            --accent-light: #818cf8;
            --accent-dim: rgba(99, 102, 241, 0.15);
            --success: #22c55e;
            --success-dim: rgba(34, 197, 94, 0.15);
            --warning: #f59e0b;
            --warning-dim: rgba(245, 158, 11, 0.15);
            --danger: #ef4444;
            --danger-dim: rgba(239, 68, 68, 0.15);
            --border: #2a2a3a;
            --border-light: #3a3a4a;
            --gradient-1: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
            --gradient-2: linear-gradient(135deg, #0a0a0f 0%, #1a1a24 100%);
            --shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
        }}
        
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        
        html {{ scroll-behavior: smooth; }}
        
        body {{
            font-family: 'Inter', 'Noto Sans SC', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.75;
            font-size: 15px;
            min-height: 100vh;
        }}
        
        /* é¡¶éƒ¨å¯¼èˆªæ  */
        .navbar {{
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 60px;
            background: rgba(10, 10, 15, 0.85);
            backdrop-filter: blur(20px);
            border-bottom: 1px solid var(--border);
            z-index: 1000;
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 0 2rem;
        }}
        
        .navbar-brand {{
            display: flex;
            align-items: center;
            gap: 0.75rem;
            font-weight: 700;
            font-size: 1.25rem;
            color: var(--text-primary);
        }}
        
        .navbar-brand svg {{
            width: 28px;
            height: 28px;
        }}
        
        .navbar-actions {{
            display: flex;
            gap: 0.75rem;
        }}
        
        .btn {{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: 8px;
            font-size: 0.875rem;
            font-weight: 500;
            text-decoration: none;
            transition: all 0.2s ease;
            cursor: pointer;
            border: none;
        }}
        
        .btn-primary {{
            background: var(--gradient-1);
            color: white;
        }}
        
        .btn-primary:hover {{
            transform: translateY(-1px);
            box-shadow: 0 4px 20px rgba(99, 102, 241, 0.4);
        }}
        
        .btn-ghost {{
            background: transparent;
            color: var(--text-secondary);
            border: 1px solid var(--border);
        }}
        
        .btn-ghost:hover {{
            background: var(--bg-hover);
            color: var(--text-primary);
            border-color: var(--border-light);
        }}
        
        /* ä¸»å†…å®¹åŒº */
        .main {{
            max-width: 900px;
            margin: 0 auto;
            padding: 100px 2rem 4rem;
        }}
        
        /* æŠ¥å‘Šå¤´éƒ¨ */
        .report-header {{
            margin-bottom: 3rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid var(--border);
        }}
        
        .report-meta {{
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin-bottom: 1.5rem;
        }}
        
        .meta-badge {{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.375rem 0.875rem;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 20px;
            font-size: 0.8rem;
            color: var(--text-secondary);
        }}
        
        /* æ–‡ç« å†…å®¹ */
        article {{
            color: var(--text-secondary);
        }}
        
        article h1 {{
            font-size: 2.25rem;
            font-weight: 700;
            color: var(--text-primary);
            margin: 2.5rem 0 1.5rem;
            letter-spacing: -0.02em;
            line-height: 1.3;
        }}
        
        article h1:first-child {{
            margin-top: 0;
        }}
        
        article h2 {{
            font-size: 1.5rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 3rem 0 1.25rem;
            padding-bottom: 0.75rem;
            border-bottom: 2px solid var(--accent);
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }}
        
        article h2::before {{
            content: '';
            width: 4px;
            height: 24px;
            background: var(--gradient-1);
            border-radius: 2px;
        }}
        
        article h3 {{
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 2rem 0 1rem;
        }}
        
        article h4 {{
            font-size: 1.05rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 1.5rem 0 0.75rem;
        }}
        
        article p {{
            margin-bottom: 1.25rem;
            color: var(--text-secondary);
        }}
        
        article strong {{
            color: var(--text-primary);
            font-weight: 600;
        }}
        
        /* å¼•ç”¨å— */
        article blockquote {{
            background: var(--accent-dim);
            border-left: 4px solid var(--accent);
            border-radius: 0 12px 12px 0;
            padding: 1.25rem 1.5rem;
            margin: 1.5rem 0;
        }}
        
        article blockquote p {{
            margin: 0;
            color: var(--text-primary);
        }}
        
        article blockquote strong {{
            color: var(--accent-light);
        }}
        
        /* è¡¨æ ¼ */
        .table-wrapper {{
            overflow-x: auto;
            margin: 1.5rem 0;
            border-radius: 12px;
            border: 1px solid var(--border);
            background: var(--bg-card);
        }}
        
        article table {{
            width: 100%;
            border-collapse: collapse;
            font-size: 0.875rem;
        }}
        
        article th {{
            background: var(--bg-secondary);
            color: var(--accent-light);
            font-weight: 600;
            text-align: left;
            padding: 1rem;
            white-space: nowrap;
            border-bottom: 1px solid var(--border);
        }}
        
        article td {{
            padding: 0.875rem 1rem;
            border-bottom: 1px solid var(--border);
            color: var(--text-secondary);
            vertical-align: top;
        }}
        
        article tr:last-child td {{
            border-bottom: none;
        }}
        
        article tr:hover td {{
            background: var(--bg-hover);
        }}
        
        article td strong {{
            color: var(--text-primary);
        }}
        
        /* è¡¨æ ¼å†…çš„æ ‡è®° */
        article td:first-child {{
            font-weight: 500;
        }}
        
        /* åˆ—è¡¨ */
        article ul, article ol {{
            margin: 1rem 0 1.5rem;
            padding-left: 1.75rem;
        }}
        
        article li {{
            margin-bottom: 0.625rem;
            color: var(--text-secondary);
        }}
        
        article li::marker {{
            color: var(--accent);
        }}
        
        article li strong {{
            color: var(--text-primary);
        }}
        
        /* ä»£ç  */
        article code {{
            background: var(--bg-secondary);
            padding: 0.2rem 0.5rem;
            border-radius: 6px;
            font-family: 'SF Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.85em;
            color: var(--success);
            border: 1px solid var(--border);
        }}
        
        article pre {{
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.25rem;
            overflow-x: auto;
            margin: 1.5rem 0;
        }}
        
        article pre code {{
            background: none;
            padding: 0;
            border: none;
            color: var(--text-secondary);
            font-size: 0.875rem;
        }}
        
        /* åˆ†éš”çº¿ */
        article hr {{
            border: none;
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--border-light), transparent);
            margin: 3rem 0;
        }}
        
        /* é›·è¾¾å›¾å®¹å™¨ */
        .chart-container {{
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.5rem;
            margin: 2rem 0;
            max-width: 600px;
        }}
        
        .chart-title {{
            color: var(--accent-light);
            font-size: 1rem;
            font-weight: 600;
            margin-bottom: 1rem;
            text-align: center;
        }}
        
        .chart-container canvas {{
            max-height: 400px;
        }}
        
        /* ç‰¹æ®Šæ ‡è®°æ ·å¼ */
        article em {{
            color: var(--text-muted);
            font-style: italic;
        }}
        
        /* é¡µè„š */
        .footer {{
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-muted);
            font-size: 0.875rem;
        }}
        
        .footer-logo {{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 0.5rem;
            color: var(--text-secondary);
            font-weight: 500;
        }}
        
        /* è¿”å›é¡¶éƒ¨æŒ‰é’® */
        .back-to-top {{
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 44px;
            height: 44px;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--text-secondary);
            cursor: pointer;
            transition: all 0.2s;
            opacity: 0;
            visibility: hidden;
        }}
        
        .back-to-top.visible {{
            opacity: 1;
            visibility: visible;
        }}
        
        .back-to-top:hover {{
            background: var(--accent);
            border-color: var(--accent);
            color: white;
            transform: translateY(-2px);
        }}
        
        /* å“åº”å¼ */
        @media (max-width: 768px) {{
            .navbar {{
                padding: 0 1rem;
            }}
            .main {{
                padding: 80px 1rem 2rem;
            }}
            article h1 {{
                font-size: 1.75rem;
            }}
            article h2 {{
                font-size: 1.25rem;
            }}
            .table-wrapper {{
                margin-left: -1rem;
                margin-right: -1rem;
                border-radius: 0;
                border-left: none;
                border-right: none;
            }}
            article th, article td {{
                padding: 0.625rem 0.75rem;
                font-size: 0.8rem;
            }}
        }}
        
        /* æ‰“å°æ ·å¼ */
        @media print {{
            .navbar, .back-to-top, .navbar-actions {{
                display: none !important;
            }}
            body {{
                background: white;
                color: #1a1a1a;
            }}
            .main {{
                padding-top: 0;
                max-width: 100%;
            }}
            article h1, article h2, article h3, article strong {{
                color: #1a1a1a;
            }}
            article p, article li, article td {{
                color: #333;
            }}
            .table-wrapper {{
                border-color: #ddd;
            }}
        }}
    </style>
</head>
<body>
    <!-- é¡¶éƒ¨å¯¼èˆª -->
    <nav class="navbar">
        <div class="navbar-brand">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <circle cx="12" cy="12" r="10"/>
                <path d="M12 6v6l4 2"/>
            </svg>
            ç«‹è®¯æŠ€æœ¯
        </div>
        <div class="navbar-actions">
            <a href="/api/reports/{filename}?format=md" download="{filename}" class="btn btn-ghost">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/>
                    <polyline points="7,10 12,15 17,10"/>
                    <line x1="12" y1="15" x2="12" y2="3"/>
                </svg>
                ä¸‹è½½ MD
            </a>
            <button onclick="window.print()" class="btn btn-primary">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M6 9V2h12v7"/>
                    <path d="M6 18H4a2 2 0 0 1-2-2v-5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2v5a2 2 0 0 1-2 2h-2"/>
                    <rect x="6" y="14" width="12" height="8"/>
                </svg>
                æ‰“å°
            </button>
        </div>
    </nav>
    
    <!-- ä¸»å†…å®¹ -->
    <main class="main">
        <article>
            {html_content}
        </article>
        
        <footer class="footer">
            <div class="footer-logo">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <path d="M12 6v6l4 2"/>
                </svg>
                ç«‹è®¯æŠ€æœ¯äº§ä¸šé“¾åˆ†æåŠ©æ‰‹
            </div>
            <p>Powered by AI Â· ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®</p>
        </footer>
    </main>
    
    <!-- è¿”å›é¡¶éƒ¨ -->
    <button class="back-to-top" onclick="window.scrollTo({{top:0,behavior:'smooth'}})">
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <polyline points="18,15 12,9 6,15"/>
        </svg>
    </button>
    
    <script>
        // è¿”å›é¡¶éƒ¨æŒ‰é’®æ˜¾ç¤ºé€»è¾‘
        const backToTop = document.querySelector('.back-to-top');
        window.addEventListener('scroll', () => {{
            if (window.scrollY > 300) {{
                backToTop.classList.add('visible');
            }} else {{
                backToTop.classList.remove('visible');
            }}
        }});
        
        // åˆå§‹åŒ–é›·è¾¾å›¾
        document.addEventListener('DOMContentLoaded', function() {{
            {radar_init_js}
        }});
    </script>
</body>
</html>"""
    
    return HTMLResponse(content=html_page)


@app.get("/api/reports")
async def list_reports():
    """åˆ—å‡ºæ‰€æœ‰æŠ¥å‘Š"""
    reports = []
    for f in sorted(REPORTS_DIR.glob("*.md"), reverse=True):
        stat = f.stat()
        reports.append({
            "filename": f.name,
            "size": stat.st_size,
            "created": datetime.fromtimestamp(stat.st_mtime).isoformat(),
            "download_url": f"http://localhost:8000/api/reports/{f.name}"
        })
    return {"reports": reports[:20]}  # æœ€è¿‘20ä»½


@app.get("/api/custom-scrapers")
async def get_custom_scrapers():
    """è·å–è‡ªå®šä¹‰çˆ¬è™«é…ç½®"""
    try:
        if SCRAPERS_CONFIG_PATH.exists():
            with open(SCRAPERS_CONFIG_PATH, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                return config.get("custom_scrapers", {})
        return {}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    config = load_config()
    
    # æ£€æŸ¥ webhook é…ç½®
    webhooks = config.get("notification", {}).get("webhooks", {})
    wework_configured = bool(webhooks.get("wework_url"))
    
    return {
        "status": "running",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "config": {
            "platforms_count": len(config.get("platforms", [])),
            "categories_count": len(config.get("categories", {})),
            "wework_configured": wework_configured,
        }
    }


def fetch_realtime_news(keywords: list) -> list:
    """
    å®æ—¶æŠ“å–ä¾›åº”é“¾ç›¸å…³æ–°é—»
    æ•°æ®æºï¼šä¸œæ–¹è´¢å¯Œã€åŒèŠ±é¡ºã€æ–°æµªè´¢ç»ç­‰è¯åˆ¸ç½‘ç«™
    """
    import requests as req
    from urllib.parse import quote
    
    all_news = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://www.eastmoney.com/"
    }
    
    # ä¸Šå¸‚å…¬å¸è‚¡ç¥¨ä»£ç æ˜ å°„ï¼ˆç”¨äºç²¾å‡†æŠ“å–ä¸ªè‚¡æ–°é—»ï¼‰
    stock_codes = {
        "ç«‹è®¯ç²¾å¯†": "002475",
        "æ­Œå°”è‚¡ä»½": "002241",
        "è“æ€ç§‘æŠ€": "300433",
        "å·¥ä¸šå¯Œè”": "601138",
        "äº¬ä¸œæ–¹A": "000725",
        "äº¬ä¸œæ–¹": "000725",
        "èˆœå®‡å…‰å­¦": "02382",
        "æ¬£æ—ºè¾¾": "300207",
        "å¾·èµ›ç”µæ± ": "000049",
        "é¹é¼æ§è‚¡": "002938",
        "ä¸œå±±ç²¾å¯†": "002384",
        "é¢†ç›Šæ™ºé€ ": "002600",
        "ç‘å£°ç§‘æŠ€": "02018",
        "ä¿¡ç»´é€šä¿¡": "300136",
        "é•¿ç›ˆç²¾å¯†": "300115",
        "æ¯”äºšè¿ª": "002594",
        "å®å¾·æ—¶ä»£": "300750",
    }
    
    # ==================== 1. ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—» ====================
    for company, code in stock_codes.items():
        if not any(kw in company for kw in keywords):
            continue
        try:
            # ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—»API
            url = f"https://search-api-web.eastmoney.com/search/jsonp?cb=jQuery&param=%7B%22uid%22%3A%22%22%2C%22keyword%22%3A%22{code}%22%2C%22type%22%3A%5B%22cmsArticleWebOld%22%5D%2C%22client%22%3A%22web%22%2C%22clientType%22%3A%22web%22%2C%22clientVersion%22%3A%22curr%22%2C%22param%22%3A%7B%22cmsArticleWebOld%22%3A%7B%22searchScope%22%3A%22default%22%2C%22sort%22%3A%22default%22%2C%22pageIndex%22%3A1%2C%22pageSize%22%3A10%2C%22preTag%22%3A%22%22%2C%22postTag%22%3A%22%22%7D%7D%7D"
            resp = req.get(url, headers=headers, timeout=8)
            text = resp.text
            # è§£æJSONP
            if "jQuery" in text:
                import json
                json_str = text[text.index("(")+1:text.rindex(")")]
                data = json.loads(json_str)
                articles = data.get("result", {}).get("cmsArticleWebOld", [])
                for item in articles:
                    title = item.get("title", "").replace("<em>", "").replace("</em>", "")
                    if title:
                        all_news.append({
                            "title": f"[{company}] {title}",
                            "url": item.get("url", ""),
                            "source": "ä¸œæ–¹è´¢å¯Œ",
                            "stock_code": code
                        })
        except Exception as e:
            print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œä¸ªè‚¡({company})æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 2. ä¸œæ–¹è´¢å¯Œå¿«è®¯ ====================
    try:
        url = "https://np-listapi.eastmoney.com/comm/web/getNewsByKeyword?keyword=&fields=title,url&pageSize=50&pageNo=1&type=0"
        resp = req.get(url, headers=headers, timeout=10)
        data = resp.json()
        if data.get("success") and data.get("data"):
            for item in data["data"].get("list", []):
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", f"https://finance.eastmoney.com/a/{item.get('code', '')}.html"),
                        "source": "ä¸œæ–¹è´¢å¯Œå¿«è®¯"
                    })
    except Exception as e:
        print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œå¿«è®¯æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 3. ä¸œæ–¹è´¢å¯Œ7x24å¿«è®¯ ====================
    try:
        url = "https://np-listapi.eastmoney.com/comm/web/getLivingList?pageSize=50&pageNo=1&type=0"
        resp = req.get(url, headers=headers, timeout=10)
        data = resp.json()
        if data.get("success") and data.get("data"):
            for item in data["data"].get("list", []):
                title = item.get("title", "") or item.get("digest", "")
                if title and any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": f"https://kuaixun.eastmoney.com/",
                        "source": "ä¸œæ–¹è´¢å¯Œ7x24"
                    })
    except Exception as e:
        print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œ7x24æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 4. åŒèŠ±é¡ºä¸ªè‚¡æ–°é—» ====================
    for company, code in stock_codes.items():
        if not any(kw in company for kw in keywords):
            continue
        try:
            # åŒèŠ±é¡ºä¸ªè‚¡æ–°é—»
            url = f"https://stockpage.10jqka.com.cn/ajax/code/{code}/type/news/"
            ths_headers = {**headers, "Referer": "https://stockpage.10jqka.com.cn/"}
            resp = req.get(url, headers=ths_headers, timeout=8)
            data = resp.json()
            if data.get("data"):
                for item in data["data"][:5]:
                    title = item.get("title", "")
                    if title:
                        all_news.append({
                            "title": f"[{company}] {title}",
                            "url": item.get("url", ""),
                            "source": "åŒèŠ±é¡º",
                            "stock_code": code
                        })
        except Exception as e:
            pass  # åŒèŠ±é¡ºåçˆ¬ä¸¥æ ¼ï¼Œé™é»˜å¤±è´¥
    
    # ==================== 5. æ–°æµªè´¢ç»æ»šåŠ¨æ–°é—» ====================
    try:
        resp = req.get(
            "https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2516&k=&num=50",
            headers={"User-Agent": "Mozilla/5.0"},
            timeout=10
        )
        data = resp.json()
        if "result" in data and "data" in data["result"]:
            for item in data["result"]["data"]:
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", ""),
                        "source": "æ–°æµªè´¢ç»"
                    })
    except Exception as e:
        print(f"âš ï¸ æ–°æµªè´¢ç»æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 6. æ–°æµªè‚¡ç¥¨æ–°é—» ====================
    try:
        resp = req.get(
            "https://feed.mix.sina.com.cn/api/roll/get?pageid=155&lid=2520&k=&num=50",
            headers={"User-Agent": "Mozilla/5.0"},
            timeout=10
        )
        data = resp.json()
        if "result" in data and "data" in data["result"]:
            for item in data["result"]["data"]:
                title = item.get("title", "")
                if any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": item.get("url", ""),
                        "source": "æ–°æµªè‚¡ç¥¨"
                    })
    except Exception as e:
        print(f"âš ï¸ æ–°æµªè‚¡ç¥¨æŠ“å–å¤±è´¥: {e}")
    
    # ==================== 7. é›ªçƒçƒ­å¸– ====================
    try:
        url = "https://xueqiu.com/statuses/hot/listV2.json?since_id=-1&max_id=-1&size=30"
        xq_headers = {**headers, "Referer": "https://xueqiu.com/", "Cookie": "xq_a_token=test"}
        resp = req.get(url, headers=xq_headers, timeout=10)
        data = resp.json()
        if data.get("data"):
            for item in data["data"].get("items", []):
                title = item.get("original_status", {}).get("title", "") or item.get("original_status", {}).get("text", "")[:80]
                if title and any(kw in title for kw in keywords):
                    all_news.append({
                        "title": title,
                        "url": f"https://xueqiu.com{item.get('target', '')}",
                        "source": "é›ªçƒ"
                    })
    except Exception as e:
        print(f"âš ï¸ é›ªçƒæŠ“å–å¤±è´¥: {e}")
    
    # å»é‡
    seen = set()
    unique_news = []
    for n in all_news:
        title = n["title"]
        if title not in seen and len(title) > 5:
            seen.add(title)
            unique_news.append(n)
    
    # æŒ‰æ¥æºä¼˜å…ˆçº§æ’åºï¼ˆè¯åˆ¸ç½‘ç«™ä¼˜å…ˆï¼‰
    source_priority = {"ä¸œæ–¹è´¢å¯Œ": 0, "åŒèŠ±é¡º": 1, "ä¸œæ–¹è´¢å¯Œå¿«è®¯": 2, "ä¸œæ–¹è´¢å¯Œ7x24": 3, "é›ªçƒ": 4, "æ–°æµªè‚¡ç¥¨": 5, "æ–°æµªè´¢ç»": 6}
    unique_news.sort(key=lambda x: source_priority.get(x["source"], 10))
    
    return unique_news[:50]


@app.post("/api/generate-analysis")
async def generate_analysis(request: AnalysisRequest):
    """
    ä½¿ç”¨ AI ç”Ÿæˆä¾›åº”é“¾åˆ†ææŠ¥å‘Š (OpenAI å…¼å®¹æ ¼å¼)
    
    Args:
        company_name: ä¸»ä½“å…¬å¸åç§°
        competitors: ç«äº‰å¯¹æ‰‹åˆ—è¡¨
        upstream: ä¸Šæ¸¸ä¾›åº”å•†åˆ—è¡¨
        downstream: ä¸‹æ¸¸å®¢æˆ·åˆ—è¡¨
        news: ç›¸å…³æ–°é—»åˆ—è¡¨
    """
    import os
    import requests as req
    from datetime import datetime
    
    config = load_config()
    ai_config = config.get("ai", {})
    
    # æ”¯æŒå†…å¤–ç½‘åŒ API é…ç½®
    internal_config = ai_config.get("internal", {})
    external_config = ai_config.get("external", {})
    
    # å†…ç½‘é…ç½®
    internal_api_key = internal_config.get("api_key", "")
    internal_api_base = internal_config.get("api_base", "http://10.180.116.5:6410/v1")
    internal_model = internal_config.get("model", "Qwen_Qwen3-VL-235B-A22B-Instruct-FP8")
    
    # å¤–ç½‘é…ç½®
    external_api_key = external_config.get("api_key", "") or os.environ.get("AI_API_KEY", "")
    external_api_base = external_config.get("api_base", "https://api.siliconflow.cn/v1")
    external_model = external_config.get("model", "Pro/moonshotai/Kimi-K2-Thinking")
    
    # å…¼å®¹æ—§é…ç½®æ ¼å¼
    if not internal_config and not external_config:
        internal_api_key = ai_config.get("api_key", "")
        internal_api_base = ai_config.get("api_base", "https://api.siliconflow.cn/v1")
        internal_model = ai_config.get("model", "Qwen/Qwen2.5-7B-Instruct")
    
    # å®æ—¶æŠ“å–ä¾›åº”é“¾ç›¸å…³æ–°é—» - æ‰©å¤§å…³é”®è¯èŒƒå›´
    keywords = [
        # æ ¸å¿ƒå…¬å¸
        "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹", "BOE",
        "æ¬£æ—ºè¾¾", "å¾·èµ›", "èˆœå®‡", "é¹é¼", "ä¸œå±±ç²¾å¯†", "é¢†ç›Š", "ç‘å£°",
        # å®¢æˆ·
        "è‹¹æœ", "Apple", "iPhone", "AirPods", "Vision Pro", "iPad", "Mac",
        "åä¸º", "Huawei", "é¸¿è’™", "Mate", "è£è€€",
        "å°ç±³", "OPPO", "vivo", "ä¸‰æ˜Ÿ", "Samsung",
        # è¡Œä¸šå…³é”®è¯
        "æ¶ˆè´¹ç”µå­", "æœé“¾", "ä»£å·¥", "ä¾›åº”é“¾", "èŠ¯ç‰‡", "åŠå¯¼ä½“",
        "æ™ºèƒ½æ‰‹æœº", "ç©¿æˆ´", "è€³æœº", "VR", "AR", "XR",
        "æ–°èƒ½æºæ±½è½¦", "ç”µåŠ¨æ±½è½¦", "åŠ¨åŠ›ç”µæ± ", "é”‚ç”µ",
        "AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "GPU", "è‹±ä¼Ÿè¾¾"
    ]
    
    print(f"ğŸ“¡ æ­£åœ¨å®æ—¶æŠ“å–ä¾›åº”é“¾ç›¸å…³æ–°é—»...")
    realtime_news = fetch_realtime_news(keywords)
    print(f"âœ… æŠ“å–åˆ° {len(realtime_news)} æ¡ç›¸å…³æ–°é—»")
    
    # åˆå¹¶ä¼ å…¥çš„æ–°é—»å’Œå®æ—¶æŠ“å–çš„æ–°é—»
    all_news = list(request.news) if request.news else []
    all_news.extend(realtime_news)
    
    # å»é‡
    seen_titles = set()
    unique_news = []
    for n in all_news:
        title = n.get("title", "")
        if title and title not in seen_titles:
            seen_titles.add(title)
            unique_news.append(n)
    
    # æ„å»ºæ–°é—»æ‘˜è¦ï¼ˆåŒ…å«é“¾æ¥ï¼‰
    news_summary = ""
    if unique_news:
        news_items = []
        for n in unique_news[:30]:
            title = n.get('title', '')
            url = n.get('url', '')
            source = n.get('source', '')
            if url:
                news_items.append(f"- [{title}]({url}) ã€{source}ã€‘")
            else:
                news_items.append(f"- {title} ã€{source}ã€‘")
        news_summary = "\n".join(news_items)
    
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    # ç«äº‰å¯¹æ‰‹åˆ—è¡¨
    competitors = request.competitors if request.competitors else ['æ­Œå°”è‚¡ä»½', 'è“æ€ç§‘æŠ€', 'å·¥ä¸šå¯Œè”', 'é¹é¼æ§è‚¡', 'ä¸œå±±ç²¾å¯†', 'é¢†ç›Šæ™ºé€ ', 'ç‘å£°ç§‘æŠ€']
    upstream = request.upstream if request.upstream else ['äº¬ä¸œæ–¹A', 'èˆœå®‡å…‰å­¦', 'æ¬£æ—ºè¾¾', 'å¾·èµ›ç”µæ± ', 'ä¿¡ç»´é€šä¿¡', 'é•¿ç›ˆç²¾å¯†']
    downstream = request.downstream if request.downstream else ['è‹¹æœ', 'åä¸º', 'Meta', 'å¥‡ç‘æ±½è½¦', 'å°ç±³', 'OPPO/vivo']
    
    prompt = f"""# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä½é¡¶çº§æŠ•è¡Œçš„TMTè¡Œä¸šé¦–å¸­åˆ†æå¸ˆï¼Œæ‹¥æœ‰15å¹´æ¶ˆè´¹ç”µå­äº§ä¸šé“¾ç ”ç©¶ç»éªŒï¼Œæ›¾ä»»èŒäºé«˜ç››ã€æ‘©æ ¹å£«ä¸¹åˆ©ã€‚ä½ çš„åˆ†æä»¥æ•°æ®é©±åŠ¨ã€é€»è¾‘ä¸¥è°¨ã€ç»“è®ºæ˜ç¡®è‘—ç§°ã€‚

# ä»»åŠ¡ç›®æ ‡
ä¸º **{request.company_name}**ï¼ˆ002475.SZï¼‰ç”Ÿæˆä¸€ä»½æœºæ„çº§åˆ«çš„**ç«äº‰æ ¼å±€ä¸ä¾›åº”é“¾æ·±åº¦åˆ†ææŠ¥å‘Š**ã€‚

# åˆ†ææ—¥æœŸ
{today}

# å…¬å¸ç”»åƒ
| ç»´åº¦ | ä¿¡æ¯ |
|------|------|
| å…¬å¸åç§° | {request.company_name} |
| è‚¡ç¥¨ä»£ç  | 002475.SZ |
| æ‰€å±è¡Œä¸š | æ¶ˆè´¹ç”µå­ç²¾å¯†åˆ¶é€  |
| æ ¸å¿ƒä¸šåŠ¡ | iPhone/AirPods/Apple Watch/Vision Proä»£å·¥ã€æ±½è½¦ç”µå­ã€é€šä¿¡è¿æ¥å™¨ |
| ç¬¬ä¸€å¤§å®¢æˆ· | è‹¹æœï¼ˆè¥æ”¶å æ¯”çº¦70-75%ï¼‰ |
| å¸‚å€¼è§„æ¨¡ | çº¦2000äº¿äººæ°‘å¸ï¼ˆAè‚¡æ¶ˆè´¹ç”µå­é¾™å¤´ï¼‰ |
| æ ¸å¿ƒç«äº‰åŠ› | å‚ç›´æ•´åˆèƒ½åŠ›ã€ç²¾å¯†åˆ¶é€ å·¥è‰ºã€å®¢æˆ·ç²˜æ€§ |

# ç«äº‰å¯¹æ‰‹çŸ©é˜µ
{chr(10).join([f'- **{c}**' for c in competitors])}

# ä¾›åº”é“¾å›¾è°±
**ä¸Šæ¸¸ä¾›åº”å•†**: {', '.join(upstream)}
**ä¸‹æ¸¸å®¢æˆ·**: {', '.join(downstream)}

# å®æ—¶æ–°é—»æƒ…æŠ¥ï¼ˆå…±{len(unique_news)}æ¡ï¼ŒæŠ“å–æ—¶é—´ï¼š{today}ï¼‰
{news_summary if news_summary else 'âš ï¸ å½“å‰æ—¶æ®µæœªæŠ“å–åˆ°ç›´æ¥ç›¸å…³æ–°é—»'}

---

# è¾“å‡ºè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºæŠ¥å‘Šï¼Œ**å¿…é¡»åŒ…å«è¡¨æ ¼å’Œæ•°æ®å¯¹æ¯”**ï¼š

## ä¸€ã€æ‰§è¡Œæ‘˜è¦ï¼ˆExecutive Summaryï¼‰
ç”¨3-5ä¸ªè¦ç‚¹æ¦‚æ‹¬æ ¸å¿ƒå‘ç°ï¼Œæ¯ä¸ªè¦ç‚¹ç”¨ âœ… âš ï¸ ğŸ”´ æ ‡æ³¨åˆ©å¥½/ä¸­æ€§/åˆ©ç©ºã€‚

## äºŒã€æ–°é—»äº‹ä»¶æ·±åº¦è§£è¯»
é’ˆå¯¹ä¸Šè¿°æ¯æ¡é‡è¦æ–°é—»ï¼Œè¯·ç”¨è¡¨æ ¼å±•ç¤ºï¼ˆ**å¿…é¡»ä¿ç•™æ–°é—»åŸæ–‡é“¾æ¥**ï¼‰ï¼š

| æ–°é—»æ ‡é¢˜ | æ¥æº | äº‹ä»¶æ¦‚è¿° | å½±å“è·¯å¾„ | å½±å“ç¨‹åº¦ | æ—¶é—´ç»´åº¦ |
|----------|------|----------|----------|----------|----------|
| [æ–°é—»æ ‡é¢˜](åŸæ–‡é“¾æ¥) | æ¥æºç½‘ç«™ | ä¸€å¥è¯æ€»ç»“ | å¦‚ä½•ä¼ å¯¼åˆ°{request.company_name} | é«˜/ä¸­/ä½ + æ­£é¢/è´Ÿé¢ | çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ |

å¦‚æœæ–°é—»è¾ƒå°‘ï¼Œè¯·åˆ†æè¿‘æœŸè¡Œä¸šè¶‹åŠ¿å¯¹å…¬å¸çš„æ½œåœ¨å½±å“ã€‚

## ä¸‰ã€ç«äº‰æ ¼å±€åˆ†æ

### 3.1 å¸‚åœºä»½é¢å¯¹æ¯”è¡¨
è¯·ç”¨Markdownè¡¨æ ¼å±•ç¤ºï¼ˆæ³¨æ„ï¼š{request.company_name}æ˜¯æˆ‘ä»¬çš„ä¸»ä½“å…¬å¸ï¼Œåº”æ˜¾ç¤º"ç»¼åˆç«äº‰åŠ›"ï¼Œå…¶ä»–ç«äº‰å¯¹æ‰‹æ˜¾ç¤º"å¨èƒç­‰çº§"ï¼‰ï¼š

| å…¬å¸ | ä¸»è¥äº§å“ | è‹¹æœä¸šåŠ¡å æ¯” | æ ¸å¿ƒä¼˜åŠ¿ | æ ¸å¿ƒåŠ£åŠ¿ | ç»¼åˆç«äº‰åŠ›/å¨èƒç­‰çº§ |
|------|----------|--------------|----------|----------|----------------------|
| **{request.company_name}** | ... | ... | ... | ... | â­â­â­â­â­ (ç»¼åˆç«äº‰åŠ›) |
| æ­Œå°”è‚¡ä»½ | ... | ... | ... | ... | â­â­â­ (å¨èƒç­‰çº§) |
| ... | ... | ... | ... | ... | ... |

### 3.2 ç«äº‰åŠ›é›·è¾¾å›¾æ•°æ®
è¯·æä¾›ä»¥ä¸‹ç»´åº¦çš„1-10åˆ†è¯„åˆ†ï¼ˆ**å°†è‡ªåŠ¨æ¸²æŸ“ä¸ºé›·è¾¾å›¾**ï¼‰ï¼š

```json:radar-chart
{{
  "type": "radar",
  "title": "ç«äº‰åŠ›å¯¹æ¯”é›·è¾¾å›¾",
  "dimensions": ["æŠ€æœ¯èƒ½åŠ›", "æˆæœ¬æ§åˆ¶", "å®¢æˆ·å…³ç³»", "äº§èƒ½è§„æ¨¡", "å‚ç›´æ•´åˆ", "ç ”å‘æŠ•å…¥"],
  "companies": {{
    "{request.company_name}": [9, 8, 10, 9, 9, 8],
    "æ­Œå°”è‚¡ä»½": [8, 7, 7, 7, 6, 7],
    "å·¥ä¸šå¯Œè”": [8, 9, 8, 10, 7, 7],
    "è“æ€ç§‘æŠ€": [7, 6, 8, 8, 6, 7]
  }}
}}
```

### 3.3 æ³¢ç‰¹äº”åŠ›åˆ†æ
ç”¨è¡¨æ ¼å±•ç¤ºäº”åŠ›è¯„ä¼°ï¼š

| ç«äº‰åŠ›é‡ | å¼ºåº¦ | å…³é”®å› ç´  | å¯¹{request.company_name}å½±å“ |
|----------|------|----------|------------------------------|
| ç°æœ‰ç«äº‰è€… | é«˜/ä¸­/ä½ | ... | ... |
| æ½œåœ¨è¿›å…¥è€… | ... | ... | ... |
| æ›¿ä»£å“å¨èƒ | ... | ... | ... |
| ä¾›åº”å•†è®®ä»· | ... | ... | ... |
| å®¢æˆ·è®®ä»· | ... | ... | ... |

## å››ã€ä¾›åº”é“¾é£é™©è¯„ä¼°

### 4.1 ä¾›åº”é“¾é£é™©çŸ©é˜µ
| é£é™©ç±»å‹ | é£é™©æè¿° | å‘ç”Ÿæ¦‚ç‡ | å½±å“ç¨‹åº¦ | é£é™©ç­‰çº§ | ç¼“è§£æªæ–½ |
|----------|----------|----------|----------|----------|----------|
| å®¢æˆ·é›†ä¸­åº¦ | è‹¹æœå æ¯”è¿‡é«˜ | é«˜ | æé«˜ | ğŸ”´ | æ‹“å±•æ±½è½¦ç”µå­ |
| ... | ... | ... | ... | ... | ... |

### 4.2 å…³é”®ä¾›åº”å•†ä¾èµ–åº¦
| ä¾›åº”å•† | ä¾›åº”ç‰©æ–™ | æ›¿ä»£éš¾åº¦ | æ–­ä¾›å½±å“ | å¤‡é€‰æ–¹æ¡ˆ |
|--------|----------|----------|----------|----------|
| äº¬ä¸œæ–¹A | æ˜¾ç¤ºé¢æ¿ | ä¸­ | é«˜ | ä¸‰æ˜Ÿ/LG |
| ... | ... | ... | ... | ... |

## äº”ã€è´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”ï¼ˆå¦‚æœ‰å…¬å¼€æ•°æ®ï¼‰
| æŒ‡æ ‡ | {request.company_name} | æ­Œå°”è‚¡ä»½ | å·¥ä¸šå¯Œè” | è¡Œä¸šå‡å€¼ |
|------|------------------------|----------|----------|----------|
| æ¯›åˆ©ç‡ | ~18% | ~15% | ~8% | ~12% |
| ROE | ... | ... | ... | ... |
| è¥æ”¶å¢é€Ÿ | ... | ... | ... | ... |

## å…­ã€SWOTåˆ†æ
ç”¨2x2è¡¨æ ¼å±•ç¤ºï¼š

| | æ­£é¢ | è´Ÿé¢ |
|---|------|------|
| **å†…éƒ¨** | **ä¼˜åŠ¿(S)**: 1. xxx 2. xxx | **åŠ£åŠ¿(W)**: 1. xxx 2. xxx |
| **å¤–éƒ¨** | **æœºä¼š(O)**: 1. xxx 2. xxx | **å¨èƒ(T)**: 1. xxx 2. xxx |

## ä¸ƒã€æŠ•èµ„å»ºè®®ä¸ç›®æ ‡ä»·

### 7.1 æŠ•èµ„è¯„çº§
| æ—¶é—´ç»´åº¦ | è¯„çº§ | æ ¸å¿ƒé€»è¾‘ |
|----------|------|----------|
| çŸ­æœŸ(1-3æœˆ) | ä¹°å…¥/æŒæœ‰/å–å‡º | ... |
| ä¸­æœŸ(6-12æœˆ) | ... | ... |
| é•¿æœŸ(1-3å¹´) | ... | ... |

### 7.2 å…³é”®å‚¬åŒ–å‰‚ä¸é£é™©ç‚¹
**ä¸Šè¡Œå‚¬åŒ–å‰‚** ğŸš€ï¼š
1. ...
2. ...

**ä¸‹è¡Œé£é™©** âš ï¸ï¼š
1. ...
2. ...

### 7.3 å…³æ³¨æ—¶é—´èŠ‚ç‚¹
| æ—¥æœŸ | äº‹ä»¶ | é¢„æœŸå½±å“ |
|------|------|----------|
| 2025å¹´1æœˆ | è‹¹æœQ1è´¢æŠ¥ | ... |
| ... | ... | ... |

---

# æ ¼å¼è¦æ±‚
1. å¿…é¡»ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«è¡¨æ ¼ã€åˆ—è¡¨ã€åŠ ç²—ã€emoji
2. è¡¨æ ¼æ•°æ®è¦å®Œæ•´ï¼Œä¸è¦ç”¨çœç•¥å·ä»£æ›¿å®é™…åˆ†æ
3. è¯„åˆ†å’Œè¯„çº§è¦æœ‰æ˜ç¡®ä¾æ®
4. JSONä»£ç å—ç”¨äºå‰ç«¯å›¾è¡¨æ¸²æŸ“ï¼Œæ ¼å¼å¿…é¡»æ­£ç¡®ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸ºé›·è¾¾å›¾
5. **å¿…é¡»ä¿ç•™æ‰€æœ‰æ–°é—»çš„åŸæ–‡é“¾æ¥**ï¼Œä½¿ç”¨ [title](url) æ ¼å¼
6. æŠ¥å‘Šé•¿åº¦ï¼š2000-4000å­—"""

    # å®šä¹‰ API è°ƒç”¨å‡½æ•°
    def call_ai_api(api_base, api_key, model, timeout=180):
        headers = {"Content-Type": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        
        response = req.post(
            f"{api_base.rstrip('/')}/chat/completions",
            headers=headers,
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯é¡¶çº§æŠ•è¡ŒTMTè¡Œä¸šé¦–å¸­åˆ†æå¸ˆï¼Œæ“…é•¿æ¶ˆè´¹ç”µå­äº§ä¸šé“¾ç«äº‰æ ¼å±€åˆ†æã€‚ä½ çš„æŠ¥å‘Šå¿…é¡»åŒ…å«ï¼š1)æ•°æ®è¡¨æ ¼ 2)ç«äº‰åŠ›è¯„åˆ† 3)é£é™©çŸ©é˜µ 4)SWOTåˆ†æ 5)æŠ•èµ„å»ºè®®ã€‚ä½¿ç”¨ä¸“ä¸šçš„Markdownæ ¼å¼ï¼ŒåŒ…å«è¡¨æ ¼å’Œç»“æ„åŒ–æ•°æ®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 8000
            },
            timeout=timeout
        )
        return response
    
    used_model = ""
    used_api = ""
    
    try:
        # ä¼˜å…ˆå°è¯•å†…ç½‘ API
        print(f"ğŸ”„ å°è¯•å†…ç½‘ API: {internal_api_base}")
        response = call_ai_api(internal_api_base, internal_api_key, internal_model, timeout=60)
        
        if response.status_code == 200:
            used_model = internal_model
            used_api = "å†…ç½‘"
            print(f"âœ… å†…ç½‘ API è°ƒç”¨æˆåŠŸ")
        else:
            raise Exception(f"å†…ç½‘ API è¿”å› {response.status_code}")
            
    except Exception as e:
        print(f"âš ï¸ å†…ç½‘ API ä¸å¯ç”¨: {e}")
        print(f"ğŸ”„ åˆ‡æ¢åˆ°å¤–ç½‘ API: {external_api_base}")
        
        if not external_api_key:
            raise HTTPException(
                status_code=400, 
                detail="å†…ç½‘ API ä¸å¯ç”¨ï¼Œä¸”æœªé…ç½®å¤–ç½‘ API Key"
            )
        
        try:
            response = call_ai_api(external_api_base, external_api_key, external_model, timeout=180)
            used_model = external_model
            used_api = "å¤–ç½‘"
            print(f"âœ… å¤–ç½‘ API è°ƒç”¨æˆåŠŸ")
        except Exception as e2:
            raise HTTPException(status_code=500, detail=f"å†…å¤–ç½‘ API å‡ä¸å¯ç”¨: å†…ç½‘({e}), å¤–ç½‘({e2})")
    
    try:
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail=f"AI APIè°ƒç”¨å¤±è´¥: {response.text}")
        
        result = response.json()
        
        # æå–ç”Ÿæˆçš„å†…å®¹ (OpenAI æ ¼å¼)
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
        else:
            raise HTTPException(status_code=500, detail=f"æ— æ³•è§£æAIå“åº”: {result}")
        
        return {
            "status": "success",
            "company": request.company_name,
            "report": content,
            "model": used_model,
            "api_source": used_api,
            "timestamp": datetime.now().isoformat()
        }
        
    except req.exceptions.Timeout:
        raise HTTPException(status_code=504, detail="AI APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
    except req.exceptions.RequestException as e:
        raise HTTPException(status_code=500, detail=f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")


# ==================== é™æ€æ–‡ä»¶æœåŠ¡ ====================

# æ£€æŸ¥ web ç›®å½•æ˜¯å¦å­˜åœ¨
WEB_DIR = BASE_DIR / "web"
if WEB_DIR.exists():
    app.mount("/static", StaticFiles(directory=str(WEB_DIR)), name="static")

@app.get("/ui")
async def serve_ui():
    """è¿”å› Web UI é¡µé¢"""
    from fastapi.responses import FileResponse
    ui_path = WEB_DIR / "index.html"
    if ui_path.exists():
        return FileResponse(str(ui_path))
    return {"error": "Web UI not found"}


# ==================== å¯åŠ¨æœåŠ¡ ====================

@app.on_event("startup")
async def startup_preload():
    """æœåŠ¡å¯åŠ¨æ—¶é¢„åŠ è½½å¸¸ç”¨åˆ†ç±»æ•°æ®"""
    import asyncio
    
    async def preload_category(category):
        try:
            from scrapers.unified import UnifiedDataSource
            ds = UnifiedDataSource()
            data = ds.crawl_category(category, include_custom=True)
            
            sources = {}
            for item in data:
                src = item.get("platform_name", item.get("platform", "unknown"))
                sources[src] = sources.get(src, 0) + 1
            
            result = {
                "category": category,
                "total": len(data),
                "sources": sources,
                "data": data,
                "timestamp": datetime.now().isoformat(),
                "cached": False
            }
            news_cache.set(f"news_{category}_True", result)
            print(f"  âœ… {category}: {len(data)} æ¡")
        except Exception as e:
            print(f"  âŒ {category}: {e}")
    
    print("ğŸ“¦ é¢„åŠ è½½ç¼“å­˜æ•°æ®...")
    # é¢„åŠ è½½å¸¸ç”¨åˆ†ç±»
    for cat in ["finance", "tech", "news", "social"]:
        await preload_category(cat)
    
    # é¢„åŠ è½½ä¾›åº”é“¾æ–°é—»
    keywords = [
        "ç«‹è®¯", "æ­Œå°”", "è“æ€", "å¯Œè”", "å¯Œå£«åº·", "äº¬ä¸œæ–¹",
        "è‹¹æœ", "Apple", "iPhone", "åä¸º", "å°ç±³", "ä¸‰æ˜Ÿ",
        "AI", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡", "åŠå¯¼ä½“", "æ¶ˆè´¹ç”µå­"
    ]
    news = fetch_realtime_news(keywords)
    _supply_chain_news_cache["data"] = news
    _supply_chain_news_cache["timestamp"] = datetime.now()
    print(f"  âœ… supply-chain: {len(news)} æ¡")
    print("âœ… é¢„åŠ è½½å®Œæˆï¼")


if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ TrendRadar API æœåŠ¡...")
    print("ğŸ“ API: http://localhost:8000")
    print("ğŸŒ Web UI: http://localhost:8000/ui")
    print("ğŸ“š API æ–‡æ¡£: http://localhost:8000/docs")
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=True)
