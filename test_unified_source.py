"""
æµ‹è¯•ç»Ÿä¸€æ•°æ®æº - æ¨¡å—3æµ‹è¯•
"""
import sys
sys.path.insert(0, '.')

print("=" * 60)
print("ğŸ§ª æ¨¡å—3æµ‹è¯•ï¼šç»Ÿä¸€æ•°æ®æº + æ¨é€ç³»ç»Ÿ")
print("=" * 60)

from scrapers.unified import UnifiedDataSource

# åˆå§‹åŒ–
ds = UnifiedDataSource()

# æµ‹è¯•1ï¼šçˆ¬å–è´¢ç»åˆ†ç±»ï¼ˆå«è‡ªå®šä¹‰çˆ¬è™«ï¼‰
print("\nğŸ“‹ æµ‹è¯•1ï¼šçˆ¬å–è´¢ç»åˆ†ç±»")
print("-" * 40)

finance_data = ds.crawl_category("finance", include_custom=True)

if finance_data:
    # ç»Ÿè®¡æ•°æ®æ¥æº
    sources = {}
    for item in finance_data:
        src = item.get("source", "unknown")
        sources[src] = sources.get(src, 0) + 1
    
    print(f"\nğŸ“Š æ•°æ®æ¥æºç»Ÿè®¡:")
    for src, count in sources.items():
        print(f"   {src}: {count} æ¡")
    
    # æ˜¾ç¤ºéƒ¨åˆ†æ•°æ®
    print(f"\nğŸ“° éƒ¨åˆ†æ•°æ®é¢„è§ˆ:")
    for item in finance_data[:5]:
        title = item.get("title", "")[:50]
        platform = item.get("platform_name", item.get("platform", ""))
        print(f"   [{platform}] {title}...")
else:
    print("âŒ è·å–å¤±è´¥")

# æµ‹è¯•2ï¼šæ¨é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆå¯é€‰ï¼‰
print("\nğŸ“‹ æµ‹è¯•2ï¼šæ¨é€åˆ°ä¼ä¸šå¾®ä¿¡")
print("-" * 40)

import yaml
with open("config/config.yaml", 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

webhook_url = config.get("notification", {}).get("webhooks", {}).get("wework_url", "")

if webhook_url:
    # åªæ¨é€è‡ªå®šä¹‰æ•°æ®æºçš„æ•°æ®ï¼ˆé¿å…é‡å¤æ¨é€ï¼‰
    custom_data = [item for item in finance_data if item.get("source") == "custom"]
    
    if custom_data:
        print(f"ğŸ“¤ æ¨é€ {len(custom_data)} æ¡è‡ªå®šä¹‰æ•°æ®æºæ•°æ®...")
        ds.push_to_wework(custom_data, "finance", webhook_url)
    else:
        print("æ²¡æœ‰è‡ªå®šä¹‰æ•°æ®æºæ•°æ®")
else:
    print("âš ï¸ æœªé…ç½®ä¼ä¸šå¾®ä¿¡ webhookï¼Œè·³è¿‡æ¨é€æµ‹è¯•")

print("\n" + "=" * 60)
print("ğŸ‰ æ¨¡å—3æµ‹è¯•å®Œæˆï¼")
print("=" * 60)
