"""
ç»Ÿä¸€æ•°æ®æºç®¡ç†å™¨
æ•´åˆ newsnow API å’Œè‡ªå®šä¹‰çˆ¬è™«ï¼Œæä¾›ç»Ÿä¸€çš„çˆ¬å–æ¥å£
"""
import yaml
import time
import random
import requests
from typing import List, Dict, Any, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed


class UnifiedDataSource:
    """ç»Ÿä¸€æ•°æ®æºç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        self.config_path = config_path
        self.config = self._load_config()
        
        # æ³¨å†Œè‡ªå®šä¹‰çˆ¬è™«
        from .finance import register_finance_scrapers
        register_finance_scrapers()
    
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®"""
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def get_platforms_by_category(self, category: str) -> List[Dict]:
        """è·å–æŒ‡å®šåˆ†ç±»çš„å¹³å°åˆ—è¡¨"""
        platforms = self.config.get("platforms", [])
        if category == "all":
            return platforms
        return [p for p in platforms if p.get("category") == category]
    
    def get_categories(self) -> Dict:
        """è·å–æ‰€æœ‰åˆ†ç±»"""
        return self.config.get("categories", {})
    
    def crawl_newsnow(self, platform_id: str) -> List[Dict]:
        """ä» newsnow API çˆ¬å–æ•°æ®ï¼ˆå•å¹³å°ï¼‰"""
        url = f"https://newsnow.busiyi.world/api/s?id={platform_id}&latest"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "application/json, text/plain, */*",
        }
        
        for retry in range(3):
            try:
                resp = requests.get(url, headers=headers, timeout=15)
                resp.raise_for_status()
                data = resp.json()
                
                if data.get("status") in ["success", "cache"]:
                    items = data.get("items", [])
                    return items
            except Exception:
                if retry < 2:
                    time.sleep(random.uniform(0.5, 1.5))
        return []
    
    def crawl_custom(self, scraper_name: str, scraper_config: Dict = None) -> List[Dict]:
        """ä½¿ç”¨è‡ªå®šä¹‰çˆ¬è™«çˆ¬å–ï¼Œè‡ªåŠ¨ä» YAML åŠ è½½é…ç½®"""
        from .factory import ScraperFactory
        
        # å¦‚æœæ²¡ä¼ é…ç½®ï¼Œä» YAML åŠ è½½
        if not scraper_config:
            scraper_config = self._load_scraper_config(scraper_name)
        
        scraper = ScraperFactory.create(scraper_name, scraper_config)
        if scraper:
            return scraper.scrape()
        return []
    
    def _load_scraper_config(self, scraper_name: str) -> Dict:
        """ä» scrapers.yaml åŠ è½½æŒ‡å®šçˆ¬è™«çš„é…ç½®"""
        try:
            yaml_path = "config/scrapers.yaml"
            with open(yaml_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            custom_scrapers = config.get("custom_scrapers", {})
            return custom_scrapers.get(scraper_name, {})
        except Exception as e:
            print(f"âš ï¸ åŠ è½½çˆ¬è™«é…ç½®å¤±è´¥ {scraper_name}: {e}")
            return {}
    
    def crawl_category(self, category: str, include_custom: bool = True) -> List[Dict]:
        """
        çˆ¬å–æŒ‡å®šåˆ†ç±»çš„æ‰€æœ‰æ•°æ®
        
        Args:
            category: åˆ†ç±»åç§° (finance, news, social, tech, all)
            include_custom: æ˜¯å¦åŒ…å«è‡ªå®šä¹‰çˆ¬è™«çš„æ•°æ®
        
        Returns:
            ç»Ÿä¸€æ ¼å¼çš„æ•°æ®åˆ—è¡¨
        """
        all_data = []
        platforms = self.get_platforms_by_category(category)
        category_info = self.get_categories().get(category, {})
        category_name = category_info.get("name", category)
        
        print(f"\nğŸ“‚ æ­£åœ¨çˆ¬å–ã€{category_name}ã€‘åˆ†ç±»")
        print("=" * 50)
        
        # 1. å¹¶å‘çˆ¬å– newsnow å¹³å°
        max_workers = min(8, max(1, len(platforms)))
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_map = {
                executor.submit(self.crawl_newsnow, p["id"]): p for p in platforms
            }

            for future in as_completed(future_map):
                p = future_map[future]
                pid = p["id"]
                pname = p["name"]
                try:
                    items = future.result()
                    if items:
                        for item in items:
                            item["platform"] = pid
                            item["platform_name"] = pname
                            item["category"] = category
                            item["source"] = "newsnow"
                        all_data.extend(items)
                        print(f"  âœ… {pname} ({pid}) {len(items)} æ¡")
                    else:
                        print(f"  âŒ {pname} ({pid}) æ— æ•°æ®")
                except Exception as e:
                    print(f"  âŒ {pname} ({pid}) å¤±è´¥: {e}")
        
        # 2. çˆ¬å–è‡ªå®šä¹‰æ•°æ®æºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if include_custom and category == "finance":
            print(f"\n  ğŸ“Š è‡ªå®šä¹‰è´¢ç»æ•°æ®æº:")
            
            # æ–°æµªå¤–æ±‡
            print(f"  ğŸ”„ æ–°æµªå¤–æ±‡...", end=" ")
            forex_data = self.crawl_custom("sina_forex", {})
            if forex_data:
                for item in forex_data:
                    item["source"] = "custom"
                all_data.extend(forex_data)
                print(f"âœ… {len(forex_data)} æ¡")
            else:
                print("âŒ å¤±è´¥")
            
            # CoinGecko
            print(f"  ğŸ”„ CoinGecko åŠ å¯†è´§å¸...", end=" ")
            crypto_data = self.crawl_custom("coingecko", {})
            if crypto_data:
                for item in crypto_data:
                    item["source"] = "custom"
                all_data.extend(crypto_data)
                print(f"âœ… {len(crypto_data)} æ¡")
            else:
                print("âŒ å¤±è´¥")
            
            # ä¸œæ–¹è´¢å¯Œä¾›åº”é“¾ä¼ä¸šåŠ¨æ€
            print(f"  ğŸ”„ ä¸œæ–¹è´¢å¯Œä¾›åº”é“¾åŠ¨æ€...", end=" ")
            supply_chain_data = self.crawl_custom("eastmoney_supply_chain", {})
            if supply_chain_data:
                for item in supply_chain_data:
                    item["source"] = "custom"
                    item["platform_name"] = "ä¸œæ–¹è´¢å¯Œ"
                all_data.extend(supply_chain_data)
                print(f"âœ… {len(supply_chain_data)} æ¡")
            else:
                print("âŒ å¤±è´¥")
        
        if include_custom and category == "tech":
            print(f"\n  ğŸ“Š è‡ªå®šä¹‰ç§‘æŠ€æ•°æ®æº:")
            
            # Hacker News
            print(f"  ğŸ”„ Hacker News...", end=" ")
            hn_data = self.crawl_custom("hackernews", {})
            if hn_data:
                for item in hn_data:
                    item["source"] = "custom"
                all_data.extend(hn_data)
                print(f"âœ… {len(hn_data)} æ¡")
            else:
                print("âŒ å¤±è´¥")
        
        # 3. çˆ¬å–å¤§å®—å•†å“æ•°æ®æº
        if include_custom and category == "commodity":
            print(f"\n  ğŸ“Š è‡ªå®šä¹‰å¤§å®—å•†å“æ•°æ®æº:")
            
            # ä¸Šæµ·æœ‰è‰²é‡‘å±ç½‘
            print(f"  ğŸ”„ ä¸Šæµ·æœ‰è‰²ç½‘...", end=" ")
            smm_data = self.crawl_custom("smm_news", {})
            if smm_data:
                for item in smm_data:
                    item["source"] = "custom"
                    item["platform"] = "smm"
                    item["platform_name"] = "ä¸Šæµ·æœ‰è‰²ç½‘"
                    item["category"] = "commodity"
                all_data.extend(smm_data)
                print(f"âœ… {len(smm_data)} æ¡")
            else:
                print("âŒ å¤±è´¥")

            # Plasway è¡Œä¸šæ¶ˆæ¯ï¼ˆå¡‘æ–™/å¤§å®—ï¼‰
            print(f"  ğŸ”„ Plaswayè¡Œä¸šæ¶ˆæ¯...", end=" ")
            plasway_data = self.crawl_custom("plasway_industry")
            if plasway_data:
                for item in plasway_data:
                    item["source"] = "custom"
                    item["platform"] = "plasway"
                    item["platform_name"] = "Plasway"
                    item["category"] = "commodity"
                all_data.extend(plasway_data)
                print(f"âœ… {len(plasway_data)} æ¡")
            else:
                print("âŒ å¤±è´¥")
        
        print(f"\nğŸ“Š å…±è·å– {len(all_data)} æ¡æ•°æ®")
        return all_data
    
    def push_to_wework(self, data: List[Dict], category: str, webhook_url):
        """æ¨é€æ•°æ®åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ URLï¼‰"""
        if isinstance(webhook_url, list):
            webhook_urls = webhook_url
        elif isinstance(webhook_url, str) and webhook_url:
            webhook_urls = [webhook_url]
        else:
            print("âŒ æœªé…ç½®ä¼ä¸šå¾®ä¿¡ webhook")
            return

        if not data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯æ¨é€")
            return
        
        category_info = self.get_categories().get(category, {})
        category_name = category_info.get("name", category)
        now = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # æŒ‰å¹³å°/æ¥æºåˆ†ç»„
        by_source = {}
        for item in data:
            source_name = item.get("platform_name", item.get("platform", "æœªçŸ¥"))
            if source_name not in by_source:
                by_source[source_name] = []
            by_source[source_name].append(item)
        
        # åˆ†æ‰¹å‘é€
        print(f"\nğŸ“¤ æ­£åœ¨æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆå…± {len(by_source)} æ‰¹ï¼Œ{len(webhook_urls)} ä¸ª webhookï¼‰...")
        
        batch_num = 1
        
        for source_name, items in by_source.items():
            lines = [f"## ğŸ“Š {category_name}çƒ­ç‚¹ ({now}) [{batch_num}]\n"]
            lines.append(f"### ğŸ“° {source_name}")
            
            for i, item in enumerate(items[:10], 1):
                title = item.get("title", "")
                url = item.get("url", "")
                if url:
                    lines.append(f"{i}. [{title}]({url})")
                else:
                    lines.append(f"{i}. {title}")
            
            message = "\n".join(lines)
            
            for wurl in webhook_urls:
                try:
                    resp = requests.post(wurl, json={
                        "msgtype": "markdown",
                        "markdown": {"content": message}
                    })
                    if resp.status_code != 200 or resp.json().get("errcode") != 0:
                        print(f"  âŒ {source_name} å‘é€å¤±è´¥ ({wurl[:20]}...)")
                except Exception as e:
                    print(f"  âŒ {source_name} å‘é€å¼‚å¸¸: {e}")
            
            batch_num += 1
            time.sleep(1)
